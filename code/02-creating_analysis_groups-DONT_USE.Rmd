---
title: "02- Creating the Grouping Metrics for Sample level and above analyses"
subtitle: "Move to code file 10, this is no longer applicable"
output:
  pdf_document: 
    fig_width: 20
    fig_height: 9
  html_document: 
    toc: true
    toc_float:
        collapsed: false
        smooth_scroll: true
    fig_width: 20
---

# Directory and doc rules

```{r, setup, eval=TRUE, include=TRUE}

# libraries
library(knitr)
library(tidyr)
library(dplyr)
library(vegan)
library(pgirmess)
library(ggplot2)

# global options
knitr::opts_chunk$set(
  root.dir = here::here(),
  echo = TRUE,         # Display code chunks
  eval = TRUE,         # Evaluate code chunks
  warning = FALSE,     # Hide warnings
  message = FALSE,     # Hide messages
  #fig.width = 15,       # Set plot width in inches
  #fig.height = 9,      # Set plot height in inches
  fig.align = "center" # Align plots to the center
)

```

# Load & Check Data
```{r}

# double check where you are
# *NOTE* see 00-data_cleaned for directory issue
getwd()

# load data
# complete df
data<- read.csv("../data/raw_complete_no_groups.csv")
# these have been moved to interim df, updated dfs are in /cleaned
p16<- read.csv("../data/interim_dfs/p16_group.csv")
p42<- read.csv("../data/interim_dfs/p42_group.csv")
phmw<- read.csv("../data/interim_dfs/phmw_group.csv")
plmw<- read.csv("../data/interim_dfs/plmw_group.csv")
pcb<- read.csv("../data/interim_dfs/pcb_group.csv")
# check it out
#str(data) # checking df structure
# note that sample_id and site_number are integers and may need to be adjusted to characters for analysis

#summary(data) #checking df contents

#colnames(data) <- tolower(colnames(data))

```

# Fisher-Jenks Breaks (log transformations)
### p16, p42, plmw, and pcb groups: n= 5, phmw: n=6

## p16
```{r}

library(classInt)  # For Fisher-Jenks breaks
library(cluster)   # For clustering methods
library(factoextra) # For optimal K estimation

p16$log_concentration <- log1p(p16$DryValue)  # log transformation

# Function to compute Goodness of Variance Fit (GVF)
compute_gvf <- function(p16, max_k = 10) {
  gvf_results <- data.frame(k = integer(), gvf = numeric())

  for (k in 2:max_k) {  # Start from 2 to avoid a single category
    breaks <- classIntervals(p16, n = k, style = "fisher")
    total_var <- var(p16)
    within_var <- sum(sapply(1:k, function(i) var(p16[breaks$brks[i] <= p16 & p16 <= breaks$brks[i+1]])))
    
    gvf <- (total_var - within_var) / total_var  # Goodness of Fit
    gvf_results <- rbind(gvf_results, data.frame(k = k, gvf = gvf))
  }

  return(gvf_results)
}

# Compute GVF for different k values
gvf_results <- compute_gvf(p16$log_concentration, max_k = 8)

# Plot GVF to find the "elbow"
ggplot(gvf_results, aes(x = k, y = gvf)) +
  geom_line() +
  geom_point() +
  ggtitle("Goodness of Variance Fit (GVF) for Fisher-Jenks") +
  xlab("Number of Breaks (k)") +
  ylab("GVF (Higher is Better)")


```

## p42
```{r}

library(classInt)  # For Fisher-Jenks breaks
library(cluster)   # For clustering methods
library(factoextra) # For optimal K estimation

p42$log_concentration <- log1p(p42$DryValue)  # log transformation

# Function to compute Goodness of Variance Fit (GVF)
compute_gvf <- function(p42, max_k = 10) {
  gvf_results <- data.frame(k = integer(), gvf = numeric())

  for (k in 2:max_k) {  # Start from 2 to avoid a single category
    breaks <- classIntervals(p42, n = k, style = "fisher")
    total_var <- var(p42)
    within_var <- sum(sapply(1:k, function(i) var(p42[breaks$brks[i] <= p42 & p42 <= breaks$brks[i+1]])))
    
    gvf <- (total_var - within_var) / total_var  # Goodness of Fit
    gvf_results <- rbind(gvf_results, data.frame(k = k, gvf = gvf))
  }

  return(gvf_results)
}

# Compute GVF for different k values
gvf_results <- compute_gvf(p42$log_concentration, max_k = 8)

# Plot GVF to find the "elbow"
ggplot(gvf_results, aes(x = k, y = gvf)) +
  geom_line() +
  geom_point() +
  ggtitle("Goodness of Variance Fit (GVF) for Fisher-Jenks") +
  xlab("Number of Breaks (k)") +
  ylab("GVF (Higher is Better)")


```

## phmw
```{r}

library(classInt)  # For Fisher-Jenks breaks
library(cluster)   # For clustering methods
library(factoextra) # For optimal K estimation

phmw$log_concentration <- log1p(phmw$DryValue)  # log transformation

# Function to compute Goodness of Variance Fit (GVF)
compute_gvf <- function(phmw, max_k = 10) {
  gvf_results <- data.frame(k = integer(), gvf = numeric())

  for (k in 2:max_k) {  # Start from 2 to avoid a single category
    breaks <- classIntervals(phmw, n = k, style = "fisher")
    total_var <- var(phmw)
    within_var <- sum(sapply(1:k, function(i) var(phmw[breaks$brks[i] <= phmw & phmw <= breaks$brks[i+1]])))
    
    gvf <- (total_var - within_var) / total_var  # Goodness of Fit
    gvf_results <- rbind(gvf_results, data.frame(k = k, gvf = gvf))
  }

  return(gvf_results)
}

# Compute GVF for different k values
gvf_results <- compute_gvf(phmw$log_concentration, max_k = 8)

# Plot GVF to find the "elbow"
ggplot(gvf_results, aes(x = k, y = gvf)) +
  geom_line() +
  geom_point() +
  ggtitle("Goodness of Variance Fit (GVF) for Fisher-Jenks") +
  xlab("Number of Breaks (k)") +
  ylab("GVF (Higher is Better)")


```

## plmw
```{r}

library(classInt)  # For Fisher-Jenks breaks
library(cluster)   # For clustering methods
library(factoextra) # For optimal K estimation

plmw$log_concentration <- log1p(plmw$DryValue)  # log transformation

# Function to compute Goodness of Variance Fit (GVF)
compute_gvf <- function(plmw, max_k = 10) {
  gvf_results <- data.frame(k = integer(), gvf = numeric())

  for (k in 2:max_k) {  # Start from 2 to avoid a single category
    breaks <- classIntervals(plmw, n = k, style = "fisher")
    total_var <- var(plmw)
    within_var <- sum(sapply(1:k, function(i) var(plmw[breaks$brks[i] <= plmw & plmw <= breaks$brks[i+1]])))
    
    gvf <- (total_var - within_var) / total_var  # Goodness of Fit
    gvf_results <- rbind(gvf_results, data.frame(k = k, gvf = gvf))
  }

  return(gvf_results)
}

# Compute GVF for different k values
gvf_results <- compute_gvf(plmw$log_concentration, max_k = 8)

# Plot GVF to find the "elbow"
ggplot(gvf_results, aes(x = k, y = gvf)) +
  geom_line() +
  geom_point() +
  ggtitle("Goodness of Variance Fit (GVF) for Fisher-Jenks") +
  xlab("Number of Breaks (k)") +
  ylab("GVF (Higher is Better)")


```

## pcb
```{r}

library(classInt)  # For Fisher-Jenks breaks
library(cluster)   # For clustering methods
library(factoextra) # For optimal K estimation

pcb$log_concentration <- log1p(pcb$DryValue)  # log transformation

# Function to compute Goodness of Variance Fit (GVF)
compute_gvf <- function(pcb, max_k = 10) {
  gvf_results <- data.frame(k = integer(), gvf = numeric())

  for (k in 2:max_k) {  # Start from 2 to avoid a single category
    breaks <- classIntervals(pcb, n = k, style = "fisher")
    total_var <- var(pcb)
    within_var <- sum(sapply(1:k, function(i) var(pcb[breaks$brks[i] <= pcb & pcb <= breaks$brks[i+1]])))
    
    gvf <- (total_var - within_var) / total_var  # Goodness of Fit
    gvf_results <- rbind(gvf_results, data.frame(k = k, gvf = gvf))
  }

  return(gvf_results)
}

# Compute GVF for different k values
gvf_results <- compute_gvf(pcb$log_concentration, max_k = 8)

# Plot GVF to find the "elbow"
ggplot(gvf_results, aes(x = k, y = gvf)) +
  geom_line() +
  geom_point() +
  ggtitle("Goodness of Variance Fit (GVF) for Fisher-Jenks") +
  xlab("Number of Breaks (k)") +
  ylab("GVF (Higher is Better)")


```

# Verifying Breaks
## p16, 5-8 breaks
```{r}

# Fisher-Jenks classifications
breaks_5 <- classIntervals(p16$log_concentration, n = 5, style = "fisher")
breaks_6 <- classIntervals(p16$log_concentration, n = 6, style = "fisher")
breaks_7 <- classIntervals(p16$log_concentration, n = 7, style = "fisher")
breaks_8 <- classIntervals(p16$log_concentration, n = 8, style = "fisher")

# Assign groups
p16$category_5 <- cut(p16$log_concentration, breaks = breaks_5$brks, labels = 1:5, include.lowest = TRUE)
p16$category_6 <- cut(p16$log_concentration, breaks = breaks_6$brks, labels = 1:6, include.lowest = TRUE)
p16$category_7 <- cut(p16$log_concentration, breaks = breaks_7$brks, labels = 1:7, include.lowest = TRUE)
p16$category_8 <- cut(p16$log_concentration, breaks = breaks_8$brks, labels = 1:8, include.lowest = TRUE)

# Check distribution
table(p16$category_5)
table(p16$category_6)
table(p16$category_7)
table(p16$category_8)

```
## p42, 5-8 breaks
```{r}

# Fisher-Jenks classifications
breaks_5 <- classIntervals(p42$log_concentration, n = 5, style = "fisher")
breaks_6 <- classIntervals(p42$log_concentration, n = 6, style = "fisher")
breaks_7 <- classIntervals(p42$log_concentration, n = 7, style = "fisher")
breaks_8 <- classIntervals(p42$log_concentration, n = 8, style = "fisher")

# Assign groups
p42$category_5 <- cut(p42$log_concentration, breaks = breaks_5$brks, labels = 1:5, include.lowest = TRUE)
p42$category_6 <- cut(p42$log_concentration, breaks = breaks_6$brks, labels = 1:6, include.lowest = TRUE)
p42$category_7 <- cut(p42$log_concentration, breaks = breaks_7$brks, labels = 1:7, include.lowest = TRUE)
p42$category_8 <- cut(p42$log_concentration, breaks = breaks_8$brks, labels = 1:8, include.lowest = TRUE)

# Check distribution
table(p42$category_5)
table(p42$category_6)
table(p42$category_7)
table(p42$category_8)

```

## phmw, 6-8 breaks
```{r}

# Fisher-Jenks classifications
breaks_6 <- classIntervals(phmw$log_concentration, n = 6, style = "fisher")
breaks_7 <- classIntervals(phmw$log_concentration, n = 7, style = "fisher")
breaks_8 <- classIntervals(phmw$log_concentration, n = 8, style = "fisher")

# Assign groups
phmw$category_6 <- cut(phmw$log_concentration, breaks = breaks_6$brks, labels = 1:6, include.lowest = TRUE)
phmw$category_7 <- cut(phmw$log_concentration, breaks = breaks_7$brks, labels = 1:7, include.lowest = TRUE)
phmw$category_8 <- cut(phmw$log_concentration, breaks = breaks_8$brks, labels = 1:8, include.lowest = TRUE)

# Check distribution
table(phmw$category_6)
table(phmw$category_7)
table(phmw$category_8)

```

## plmw, 5-6 breaks
```{r}

# Fisher-Jenks classifications
breaks_5 <- classIntervals(plmw$log_concentration, n = 5, style = "fisher")
breaks_6 <- classIntervals(plmw$log_concentration, n = 6, style = "fisher")

# Assign groups
plmw$category_5 <- cut(plmw$log_concentration, breaks = breaks_5$brks, labels = 1:5, include.lowest = TRUE)
plmw$category_6 <- cut(plmw$log_concentration, breaks = breaks_6$brks, labels = 1:6, include.lowest = TRUE)

# Check distribution
table(plmw$category_5)
table(plmw$category_6)

```

## pcb, 5-7 breaks
```{r}

# Fisher-Jenks classifications
breaks_5 <- classIntervals(pcb$log_concentration, n = 5, style = "fisher")
breaks_6 <- classIntervals(pcb$log_concentration, n = 6, style = "fisher")
breaks_7 <- classIntervals(pcb$log_concentration, n = 7, style = "fisher")

# Assign groups
pcb$category_5 <- cut(pcb$log_concentration, breaks = breaks_5$brks, labels = 1:5, include.lowest = TRUE)
pcb$category_6 <- cut(pcb$log_concentration, breaks = breaks_6$brks, labels = 1:6, include.lowest = TRUE)
pcb$category_7 <- cut(pcb$log_concentration, breaks = breaks_7$brks, labels = 1:7, include.lowest = TRUE)

# Check distribution
table(pcb$category_5)
table(pcb$category_6)
table(pcb$category_7)

```

# Fisher-Jenks Breaks (sqrt transformations)
### p16, p42, plmw, and pcb groups: n= 5, phmw: n=6

## p16
```{r}

library(classInt)  # For Fisher-Jenks breaks
library(cluster)   # For clustering methods
library(factoextra) # For optimal K estimation

p16$sqrt_concentration <- sqrt(p16$DryValue)  # log transformation

# Function to compute Goodness of Variance Fit (GVF)
compute_gvf <- function(p16, max_k = 10) {
  gvf_results <- data.frame(k = integer(), gvf = numeric())

  for (k in 2:max_k) {  # Start from 2 to avoid a single category
    breaks <- classIntervals(p16, n = k, style = "fisher")
    total_var <- var(p16)
    within_var <- sum(sapply(1:k, function(i) var(p16[breaks$brks[i] <= p16 & p16 <= breaks$brks[i+1]])))
    
    gvf <- (total_var - within_var) / total_var  # Goodness of Fit
    gvf_results <- rbind(gvf_results, data.frame(k = k, gvf = gvf))
  }

  return(gvf_results)
}

# Compute GVF for different k values
gvf_results <- compute_gvf(p16$sqrt_concentration, max_k = 8)

# Plot GVF to find the "elbow"
ggplot(gvf_results, aes(x = k, y = gvf)) +
  geom_line() +
  geom_point() +
  ggtitle("Goodness of Variance Fit (GVF) for Fisher-Jenks") +
  xlab("Number of Breaks (k)") +
  ylab("GVF (Higher is Better)")


```

## p42
```{r}

library(classInt)  # For Fisher-Jenks breaks
library(cluster)   # For clustering methods
library(factoextra) # For optimal K estimation

p42$sqrt_concentration <- sqrt(p42$DryValue)  # log transformation

# Function to compute Goodness of Variance Fit (GVF)
compute_gvf <- function(p42, max_k = 10) {
  gvf_results <- data.frame(k = integer(), gvf = numeric())

  for (k in 2:max_k) {  # Start from 2 to avoid a single category
    breaks <- classIntervals(p42, n = k, style = "fisher")
    total_var <- var(p42)
    within_var <- sum(sapply(1:k, function(i) var(p42[breaks$brks[i] <= p42 & p42 <= breaks$brks[i+1]])))
    
    gvf <- (total_var - within_var) / total_var  # Goodness of Fit
    gvf_results <- rbind(gvf_results, data.frame(k = k, gvf = gvf))
  }

  return(gvf_results)
}

# Compute GVF for different k values
gvf_results <- compute_gvf(p42$sqrt_concentration, max_k = 8)

# Plot GVF to find the "elbow"
ggplot(gvf_results, aes(x = k, y = gvf)) +
  geom_line() +
  geom_point() +
  ggtitle("Goodness of Variance Fit (GVF) for Fisher-Jenks") +
  xlab("Number of Breaks (k)") +
  ylab("GVF (Higher is Better)")


```

## phmw
```{r}

library(classInt)  # For Fisher-Jenks breaks
library(cluster)   # For clustering methods
library(factoextra) # For optimal K estimation

phmw$sqrt_concentration <- sqrt(phmw$DryValue)  # log transformation

# Function to compute Goodness of Variance Fit (GVF)
compute_gvf <- function(phmw, max_k = 10) {
  gvf_results <- data.frame(k = integer(), gvf = numeric())

  for (k in 2:max_k) {  # Start from 2 to avoid a single category
    breaks <- classIntervals(phmw, n = k, style = "fisher")
    total_var <- var(phmw)
    within_var <- sum(sapply(1:k, function(i) var(phmw[breaks$brks[i] <= phmw & phmw <= breaks$brks[i+1]])))
    
    gvf <- (total_var - within_var) / total_var  # Goodness of Fit
    gvf_results <- rbind(gvf_results, data.frame(k = k, gvf = gvf))
  }

  return(gvf_results)
}

# Compute GVF for different k values
gvf_results <- compute_gvf(phmw$sqrt_concentration, max_k = 8)

# Plot GVF to find the "elbow"
ggplot(gvf_results, aes(x = k, y = gvf)) +
  geom_line() +
  geom_point() +
  ggtitle("Goodness of Variance Fit (GVF) for Fisher-Jenks") +
  xlab("Number of Breaks (k)") +
  ylab("GVF (Higher is Better)")


```

## plmw
```{r}

library(classInt)  # For Fisher-Jenks breaks
library(cluster)   # For clustering methods
library(factoextra) # For optimal K estimation

plmw$sqrt_concentration <- sqrt(plmw$DryValue)  # log transformation

# Function to compute Goodness of Variance Fit (GVF)
compute_gvf <- function(plmw, max_k = 10) {
  gvf_results <- data.frame(k = integer(), gvf = numeric())

  for (k in 2:max_k) {  # Start from 2 to avoid a single category
    breaks <- classIntervals(plmw, n = k, style = "fisher")
    total_var <- var(plmw)
    within_var <- sum(sapply(1:k, function(i) var(plmw[breaks$brks[i] <= plmw & plmw <= breaks$brks[i+1]])))
    
    gvf <- (total_var - within_var) / total_var  # Goodness of Fit
    gvf_results <- rbind(gvf_results, data.frame(k = k, gvf = gvf))
  }

  return(gvf_results)
}

# Compute GVF for different k values
gvf_results <- compute_gvf(plmw$sqrt_concentration, max_k = 8)

# Plot GVF to find the "elbow"
ggplot(gvf_results, aes(x = k, y = gvf)) +
  geom_line() +
  geom_point() +
  ggtitle("Goodness of Variance Fit (GVF) for Fisher-Jenks") +
  xlab("Number of Breaks (k)") +
  ylab("GVF (Higher is Better)")


```

## pcb, n= 4-8
```{r}

library(classInt)  # For Fisher-Jenks breaks
library(cluster)   # For clustering methods
library(factoextra) # For optimal K estimation

pcb$sqrt_concentration <- sqrt(pcb$DryValue)  # log transformation

# Function to compute Goodness of Variance Fit (GVF)
compute_gvf <- function(pcb, max_k = 10) {
  gvf_results <- data.frame(k = integer(), gvf = numeric())

  for (k in 2:max_k) {  # Start from 2 to avoid a single category
    breaks <- classIntervals(pcb, n = k, style = "fisher")
    total_var <- var(pcb)
    within_var <- sum(sapply(1:k, function(i) var(pcb[breaks$brks[i] <= pcb & pcb <= breaks$brks[i+1]])))
    
    gvf <- (total_var - within_var) / total_var  # Goodness of Fit
    gvf_results <- rbind(gvf_results, data.frame(k = k, gvf = gvf))
  }

  return(gvf_results)
}

# Compute GVF for different k values
gvf_results <- compute_gvf(pcb$sqrt_concentration, max_k = 8)

# Plot GVF to find the "elbow"
ggplot(gvf_results, aes(x = k, y = gvf)) +
  geom_line() +
  geom_point() +
  ggtitle("Goodness of Variance Fit (GVF) for Fisher-Jenks") +
  xlab("Number of Breaks (k)") +
  ylab("GVF (Higher is Better)")


```

# Verifying Breaks (Only pcb had a positive result)
## pcb, 4-8 breaks
```{r}

# Fisher-Jenks classifications
breaks_4 <- classIntervals(pcb$sqrt_concentration, n = 4, style = "fisher")
breaks_5 <- classIntervals(pcb$sqrt_concentration, n = 5, style = "fisher")
breaks_6 <- classIntervals(pcb$sqrt_concentration, n = 6, style = "fisher")
breaks_7 <- classIntervals(pcb$sqrt_concentration, n = 7, style = "fisher")
breaks_8 <- classIntervals(pcb$sqrt_concentration, n = 8, style = "fisher")

# Assign groups
pcb$category_4 <- cut(pcb$sqrt_concentration, breaks = breaks_4$brks, labels = 1:4, include.lowest = TRUE)
pcb$category_5 <- cut(pcb$sqrt_concentration, breaks = breaks_5$brks, labels = 1:5, include.lowest = TRUE)
pcb$category_6 <- cut(pcb$sqrt_concentration, breaks = breaks_6$brks, labels = 1:6, include.lowest = TRUE)
pcb$category_7 <- cut(pcb$sqrt_concentration, breaks = breaks_7$brks, labels = 1:7, include.lowest = TRUE)
pcb$category_8 <- cut(pcb$sqrt_concentration, breaks = breaks_8$brks, labels = 1:8, include.lowest = TRUE)

# Check distribution
table(pcb$category_4)
table(pcb$category_5)
table(pcb$category_6)
table(pcb$category_7)
table(pcb$category_8)

```

# KDE Breaks- Not an option
```{r}

library(MASS)

#max_density <- max(density_est$y)  # Get highest density value
#threshold <- 0.1 * max_density  # Set threshold as 10% of peak density


density_est <- density(p16$log_concentration)  # Kernel Density Estimation

breaks_kde <- density_est$x[density_est$y < 0.08]  # Adjust threshold as needed, ID where density is LOW (local minima)
breaks_kde <- unique(c(min(p16$log_concentration), breaks_kde, max(p16$log_concentration))) # Ensure the minimum and maximum values are included
print(breaks_kde) # Print selected breakpoints

# Assign KDE groups based on breakpoints
p16$category_kde <- cut(p16$log_concentration, 
                              breaks = breaks_kde, 
                              labels = 1:(length(breaks_kde)-1), 
                              include.lowest = TRUE)

# View the distribution of KDE-based categories
table(p16$category_kde)

ggplot(p16, aes(x = log_concentration)) +
  geom_density(fill = "blue", alpha = 0.3) +  # KDE density plot
  geom_vline(xintercept = breaks_kde, linetype = "dashed", color = "red") +  # KDE Breaks
  ggtitle("KDE-Based Breaks for Contaminant Data") +
  xlab("Log Concentration") + ylab("Density")


```

# Quantile Breaks
## p16
```{r}

quantile_breaks <- quantile(p16$log_concentration, probs = seq(0, 1, length.out = 6))  # 5 groups = 6 breakpoints
print(quantile_breaks)

p16$quantile_category <- cut(p16$log_concentration, 
                                   breaks = quantile_breaks, 
                                   labels = 1:5, 
                                   include.lowest = TRUE)

table(p16$quantile_category) # Check category distribution


```

## p42
```{r}

quantile_breaks <- quantile(p42$log_concentration, probs = seq(0, 1, length.out = 6))  # 5 groups = 6 breakpoints
print(quantile_breaks)

p42$quantile_category <- cut(p16$log_concentration, 
                                   breaks = quantile_breaks, 
                                   labels = 1:5, 
                                   include.lowest = TRUE)

table(p42$quantile_category) # Check category distribution


```

## phmw
```{r}

quantile_breaks <- quantile(phmw$log_concentration, probs = seq(0, 1, length.out = 7))  # 6 groups = 7 breakpoints
print(quantile_breaks)

phmw$quantile_category <- cut(phmw$log_concentration, 
                                   breaks = quantile_breaks, 
                                   labels = 1:6, 
                                   include.lowest = TRUE)

table(phmw$quantile_category) # Check category distribution


```

## plmw
```{r}

quantile_breaks <- quantile(plmw$log_concentration, probs = seq(0, 1, length.out = 6))  # 5 groups = 6 breakpoints
print(quantile_breaks)

plmw$quantile_category <- cut(plmw$log_concentration, 
                                   breaks = quantile_breaks, 
                                   labels = 1:5, 
                                   include.lowest = TRUE)

table(plmw$quantile_category) # Check category distribution


```

## pcb
```{r}

quantile_breaks <- quantile(pcb$log_concentration, probs = seq(0, 1, length.out = 6))  # 5 groups = 6 breakpoints
print(quantile_breaks)

pcb$quantile_category <- cut(pcb$log_concentration, 
                                   breaks = quantile_breaks, 
                                   labels = 1:5, 
                                   include.lowest = TRUE)

table(pcb$quantile_category) # Check category distribution


```

# Write out CSVs for the FJ breaks & Quantiles for manual manipulation
```{r}
getwd()

write.csv(p16, "/Users/cmantegna/Documents/GitHub/WDFWmussels/data/cleaned/p16_manual_groups.csv")
write.csv(p42, "/Users/cmantegna/Documents/GitHub/WDFWmussels/data/cleaned/p42_manual_groups.csv")
write.csv(phmw, "/Users/cmantegna/Documents/GitHub/WDFWmussels/data/cleaned/phmw_manual_groups.csv")
write.csv(plmw, "/Users/cmantegna/Documents/GitHub/WDFWmussels/data/cleaned/plmw_manual_groups.csv")
write.csv(pcb, "/Users/cmantegna/Documents/GitHub/WDFWmussels/data/cleaned/pcb_manual_groups.csv")

```

# K-Means for Geographic Groups
## 3 clusters is optimal using this method
```{r}

library(factoextra)
library(cluster)

geo_data <- data.frame(lat = data$latitude, lon = data$longitude) # pulling out lat/ long

fviz_nbclust(geo_data, kmeans, method = "wss") +
  ggtitle("Elbow Method for Optimal Geographic Clusters") # Compute within-cluster sum of squares for different k values

fviz_nbclust(geo_data, kmeans, method = "silhouette") +
  ggtitle("Silhouette Method for Geographic Clustering") # visual check cluster quality

set.seed(123)  # Ensure reproducibility

gap_stat <- clusGap(geo_data, FUN = kmeans, K.max = 10, B = 50)
fviz_gap_stat(gap_stat) # statistical test for cluster quality

# plot to see that the optimal cluster count is a reliable metric in real life
set.seed(123)  # Ensure consistent results
k_optimal <- 3  # Choose based on elbow/silhouette/gap methods

# Run k-means
km <- kmeans(geo_data, centers = k_optimal, nstart = 25)

# Add cluster assignments to dataset
data$geo_cluster <- as.factor(km$cluster)

ggplot(data, aes(x = longitude, y = latitude, color = geo_cluster)) +
  geom_point(size = 3) +
  ggtitle("Geographic Clusters of Sampling Sites") +
  xlab("Longitude") + ylab("Latitude")


```

# Verifying K-Means Cluster Counts
```{r}

set.seed(123)
km4 <- kmeans(geo_data, centers = 4, nstart = 25)
km5 <- kmeans(geo_data, centers = 5, nstart = 25)
km6 <- kmeans(geo_data, centers = 6, nstart = 25)
km7 <- kmeans(geo_data, centers = 7, nstart = 25)

# Add new clusters
data$geo_cluster_4 <- as.factor(km4$cluster)
data$geo_cluster_5 <- as.factor(km5$cluster)
data$geo_cluster_6 <- as.factor(km6$cluster)
data$geo_cluster_7 <- as.factor(km7$cluster)

# Plot
ggplot(data, aes(x = longitude, y = latitude, color = geo_cluster_4)) +
  geom_point(size = 3) + ggtitle("Geographic Clusters (k=4)") +
  xlab("Longitude") + ylab("Latitude")

ggplot(data, aes(x = longitude, y = latitude, color = geo_cluster_5)) +
  geom_point(size = 3) + ggtitle("Geographic Clusters (k=5)") +
  xlab("Longitude") + ylab("Latitude")

ggplot(data, aes(x = longitude, y = latitude, color = geo_cluster_6)) +
  geom_point(size = 3) + ggtitle("Geographic Clusters (k=4)") +
  xlab("Longitude") + ylab("Latitude")

ggplot(data, aes(x = longitude, y = latitude, color = geo_cluster_7)) +
  geom_point(size = 3) + ggtitle("Geographic Clusters (k=5)") +
  xlab("Longitude") + ylab("Latitude")


```

# Hierarchical Clustering
```{r}

library(dendextend)

geo_dist <- dist(geo_data) # Compute distance matrix

hc <- hclust(geo_dist, method = "complete") # Perform hierarchical clustering

data$geo_hclust3 <- cutree(hc, k = 3) # Cut into 3 clusters (or adjust)
data$geo_hclust4 <- cutree(hc, k = 4) # Cut into 3 clusters (or adjust)
data$geo_hclust5 <- cutree(hc, k = 5) # Cut into 3 clusters (or adjust)
data$geo_hclust6 <- cutree(hc, k = 6) # Cut into 3 clusters (or adjust)

# Plot hierarchical clusters
ggplot(data, aes(x = longitude, y = latitude, color = as.factor(geo_hclust3))) +
  geom_point(size = 3) +
  ggtitle("Hierarchical Clustering of Sampling Sites") +
  xlab("Longitude") + ylab("Latitude")

ggplot(data, aes(x = longitude, y = latitude, color = as.factor(geo_hclust4))) +
  geom_point(size = 3) +
  ggtitle("Hierarchical Clustering of Sampling Sites") +
  xlab("Longitude") + ylab("Latitude")

ggplot(data, aes(x = longitude, y = latitude, color = as.factor(geo_hclust5))) +
  geom_point(size = 3) +
  ggtitle("Hierarchical Clustering of Sampling Sites") +
  xlab("Longitude") + ylab("Latitude")

ggplot(data, aes(x = longitude, y = latitude, color = as.factor(geo_hclust6))) +
  geom_point(size = 3) +
  ggtitle("Hierarchical Clustering of Sampling Sites") +
  xlab("Longitude") + ylab("Latitude")

```

# Mapping Clusters
## moving forward with K-Means 4 & 5 + Hierarchical 4 & 5
```{r}

library(sf)
library(ggmap, 'maps')
library("cowplot")

usa <- map_data("usa")
gg1 <-ggplot() + geom_polygon(data = usa, aes(x=long, y = lat, group = group)) + 
  coord_fixed(1.3) 

states <- map_data("state")
head(states)

wa_df <- subset(states, region== "washington")
head(wa_df)

counties <- map_data("county")
wa_county <- subset(counties, region== "washington")
head(wa_county)

#### troubleshooting why the combined plot is not working
str(wa_df)      # Ensure 'group' is numeric or factor
summary(wa_df)
str(data)  # Ensure 'longitude', 'latitude', and 'geo_hclust3' exist
summary(data)  # Check for missing values
"group" %in% colnames(data)  # Should return FALSE
class(data)  # Should return "data.frame"

print(wa_base + geom_point(data = data, aes(x = longitude, y = latitude, color = geo_hclust3), size = 3))


#data$geo_hclust3<- as.factor(data$geo_hclust3) 
#### end of troubleshooting

wa_base <- ggplot(data = wa_df, mapping = aes(x = long, y = lat, group = as.factor(group))) + 
  coord_fixed(1.3) + 
  geom_polygon(color = "black", fill = "gray")
wa_base + theme_nothing()

print(wa_base)

#hc 3
wa_base + 
  geom_point(data = data, aes(x = longitude, y = latitude, color = as.factor(geo_hclust3)), size = 3, inherit.aes = FALSE) +
  ggtitle("Geographic Clusters of Sampling Sites")

#hc 4
wa_base + 
  geom_point(data = data, aes(x = longitude, y = latitude, color = as.factor(geo_hclust4)), size = 3, inherit.aes = FALSE) +
  ggtitle("Geographic Clusters of Sampling Sites")

#group 4
wa_base + 
  geom_point(data = data, aes(x = longitude, y = latitude, color = as.factor(geo_cluster_4)), size = 3, inherit.aes = FALSE) +
  ggtitle("Geographic Clusters of Sampling Sites")

#group 5
wa_base + 
  geom_point(data = data, aes(x = longitude, y = latitude, color = as.factor(geo_cluster_5)), size = 3, inherit.aes = FALSE) +
  ggtitle("Geographic Clusters of Sampling Sites")

# group 6
wa_base + 
  geom_point(data = data, aes(x = longitude, y = latitude, color = as.factor(geo_cluster_6)), size = 3, inherit.aes = FALSE) +
  ggtitle("Geographic Clusters of Sampling Sites")

```

# Write out the data df with all of the geo groups
```{r}

getwd()

write.csv(data, "/Users/cmantegna/Documents/GitHub/WDFWmussels/data/cleaned/full_data_all_geo_groups.csv")

```

