---
title: "2- Creating an IBR & Contaminant Concentration Index (CCI)"
output:
  pdf_document: 
    fig_width: 20
    fig_height: 9
  html_document: 
    toc: true
    toc_float:
        collapsed: false
        smooth_scroll: true
    fig_width: 20
---

# Directory and doc rules

```{r, setup, eval=TRUE, include=TRUE, echo=FALSE}

knitr::opts_chunk$set(
  root.dir = here::here(),
  echo = TRUE,         # show code chunks
  eval = TRUE,         # evaluate code chunks
  warning = FALSE,     # hide warnings
  message = FALSE,     # hide messages
  #fig.width = 15,       # set plot width in inches
  #fig.height = 9,      # set plot height in inches
  fig.align = "center" # slign plots to the center in output doc/ slide/ whatever
)

# libraries
library(car) # VERIFY what this is for 
library(cluster) # grouping metrics - VERIFY still needed
library(dplyr) # data wrangling
library(factoextra) # pca/ nmds/ tweaking radars
library(FactoMineR) # pca/ nmds/ tweaking radars
library(fmsb) # polygon calculations for the radars
library(FSA) # post hoc test - Dunn's Test    
library(ggplot2) # plots
library(knitr) # output formatting
library(pgirmess) # stats - KW
library(rcompanion) # KW testing
library(rstatix) # VERIFY what this is for      
library(RVAideMemoire) # post hoc test for permanova
library(scales) # scaling data for IBR - works with data wrangling packages
library(tidyr) # data wrangling
library(tidyverse) # data wrangling
library(vegan) # ecological stats 

```

# Load & Check Data
```{r}

getwd()

site_data<- read.csv("../data/avg_site_level_no_indices.csv")
con_data<- read.csv("../data/all_sites_with_contaminant_indices.csv")

site_data$reporting_area <- as.factor(site_data$reporting_area)
con_data$reporting_area <- as.factor(con_data$reporting_area)

summary(site_data)
summary(con_data)

```

# Creating Mattos' IBRv2i Index with biomarkers and raw morphometrics (no condition indices)

## log2 transform the metrics
```{r}



```


## z-score standardization, absolute sd & IBR scoring
```{r}

# define biomarker and morphometric groups, reference site
biomarker_metrics <- c("p450", "sod")
morphometric_metrics <- c("shell", "length", "height", "width", "weight_initial", "weight_change", "weight_final")
ref_site <- "Penn Cove Reference"

metrics <- c(biomarker_metrics, morphometric_metrics)
scale_num <- function(x) as.numeric(scale(x))

# z-score the metrics. Note- condition indices will need to be done separately
z_data <- site_data %>%
  mutate(across(all_of(metrics), scale_num, .names = "z_{.col}"))

# reference means from reference site z-scored columns 
ref_means <- z_data %>%
  filter(site_name == ref_site) %>%
  summarise(across(all_of(paste0("z_", metrics)), ~ mean(.x, na.rm = TRUE))) %>%
  as.list() %>% unlist()

# calculate absolute deviation from reference (AI) for the same set of columns
ai_data <- z_data %>%
  mutate(across(
    all_of(paste0("z_", metrics)),
    ~ abs(.x - ref_means[cur_column()]),
    .names = "ai_{.col}"
  ))

# assign IBR scores
site_ibr <- ai_data %>%
  mutate(
    ibr_biomarker= rowSums(across(all_of(paste0("ai_z_", biomarker_metrics))), na.rm = TRUE),
    ibr_morphometric = rowSums(across(all_of(paste0("ai_z_", morphometric_metrics))), na.rm = TRUE),
    ibr_combined= ibr_biomarker + ibr_morphometric)

# save
#write.csv(site_ibr, "../data/site_ibr_09262025.csv")

# to scale condition indices
non_metrics<- c("ci1", "ci2", "ci3") # for code at line 109
ref_site <- "Penn Cove Reference"
metrics2<- non_metrics # for code at line 109
scale_num <- function(x) as.numeric(scale(x))

# z-score the metrics. Note- condition indices will need to be done separately
z_data <- site_data %>%
  mutate(across(all_of(metrics2), scale_num, .names = "z_{.col}"))

# reference means from reference site z-scored columns 
ref_means <- z_data %>%
  filter(site_name == ref_site) %>%
  summarise(across(all_of(paste0("z_", metrics2)), ~ mean(.x, na.rm = TRUE))) %>%
  as.list() %>% unlist()

# calculate absolute deviation from reference (AI) for the same set of columns
ai_data <- z_data %>%
  mutate(across(
    all_of(paste0("z_", metrics2)),
    ~ abs(.x - ref_means[cur_column()]),
    .names = "ai_{.col}"
  ))

#save
#write.csv(ai_data, "../data/ci_site_ibr_09262025.csv")

```

## Creating Chemical Contaminant Indices by class
### Not recreated on 9.26.25 - current indices are complete
## chlordane
```{r}

chlordane_df<- chlordane

# define variables
chlordane_analytes <- c("alpha_chlordane", "beta_chlordane", "cis_nonachlor", 
                        "heptachlor", "heptachlor_epoxide", "nonachlor3", 
                        "Oxychlordane", "trans_Nonachlor")

# z-score
chlordane_z <- chlordane_df %>%
  mutate(across(all_of(chlordane_analytes), scale, .names = "z_{.col}"))

# reference
ref_site <- "Penn Cove Baseline"
ref_z_chlordane <- chlordane_z %>%
  filter(site_name == ref_site) %>%
  select(starts_with("z_")) %>%
  slice(1)

# deviation
chlordane_ai <- chlordane_z %>%
  mutate(across(
    starts_with("z_"),
    ~ abs(.x - as.numeric(ref_z_chlordane[[cur_column()]])),
    .names = "ai_{.col}"
  ))

# create index
ai_cols <- names(chlordane_ai)[grepl("^ai_", names(chlordane_ai))] # id ai columns
chlordane_index<- chlordane_ai %>%
  rowwise() %>%
  mutate(chlordane_index = sum(c_across(all_of(ai_cols)), na.rm = TRUE)) %>%
  ungroup()

# view & save
print(chlordane_index)
#write.csv(chlordane_ai, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/chlordane_ai.csv", row.names = FALSE)
#write.csv(chlordane_index, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/chlordane_index.csv", row.names = FALSE)

```

## ddt
```{r}

ddt_df<- ddt
#colnames(ddt_df)

# define variables
ddt_analytes <- c("opDDD", "opDDE", "opDDT", "ppDDD", "ppDDT", "ppDDE")

# z-score
ddt_z <- ddt_df %>%
  mutate(across(all_of(ddt_analytes), scale, .names = "z_{.col}"))

# reference
ref_site <- "Penn Cove Baseline"
ref_z_ddt <- ddt_z %>%
  filter(site_name == ref_site) %>%
  select(starts_with("z_")) %>%
  slice(1)

# deviation
ddt_ai <- ddt_z %>%
  mutate(across(
    starts_with("z_"),
    ~ abs(.x - as.numeric(ref_z_ddt[[cur_column()]])),
    .names = "ai_{.col}"
  ))

# create index
ai_cols <- names(ddt_ai)[grepl("^ai_", names(ddt_ai))] # id ai columns
ddt_index<- ddt_ai %>%
  rowwise() %>%
  mutate(ddt_index = sum(c_across(all_of(ai_cols)), na.rm = TRUE)) %>%
  ungroup()

# view & save
print(ddt_index)
#write.csv(ddt_ai, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/ddt_ai.csv", row.names = FALSE)
#write.csv(ddt_index, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/ddt_index.csv", row.names = FALSE)

```

## hch
```{r}

hch_df<- hch
colnames(hch_df)

# define variables
hch_analytes <- c("alpha_hexachlorocyclohexane", "beta_hexachlorocyclohexane", "gamma_hexachlorocyclohexane")

# z-score
hch_z <- hch_df %>%
  mutate(across(all_of(hch_analytes), scale, .names = "z_{.col}"))

# reference
ref_site <- "Penn Cove Baseline"
ref_z_hch <- hch_z %>%
  filter(site_name == ref_site) %>%
  select(starts_with("z_")) %>%
  slice(1)

# deviation
hch_ai <- hch_z %>%
  mutate(across(
    starts_with("z_"),
    ~ abs(.x - as.numeric(ref_z_hch[[cur_column()]])),
    .names = "ai_{.col}"
  ))

# create index
ai_cols <- names(hch_ai)[grepl("^ai_", names(hch_ai))] # id ai columns
hch_index<- hch_ai %>%
  rowwise() %>%
  mutate(hch_index = sum(c_across(all_of(ai_cols)), na.rm = TRUE)) %>%
  ungroup()

# view & save
print(hch_index)
#write.csv(hch_ai, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/hch_ai.csv", row.names = FALSE)
#write.csv(hch_index, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/hch_index.csv", row.names = FALSE)

```

## metal
```{r}

metal_df<- metal

# define variables
heavy_metals <- c("arsenic", "cadmium", "mercury")
nutrient_metals <- c("copper", "lead", "zinc")

# setup complete metal index
all_metals <- c(heavy_metals, nutrient_metals)

# z-score for each analyte (site-level is not possible based on single site values)
metals_z <- metal_df %>%
  mutate(across(all_of(all_metals), scale, .names = "z_{.col}"))

# pull reference scores
ref_site <- "Penn Cove Baseline"
ref_z <- metals_z %>%
  filter(site_name == ref_site) %>%
  select(starts_with("z_")) %>%
  slice(1)

# absolute deviation from reference z-score for each metal
metals_ai <- metals_z %>%
  mutate(across(
    starts_with("z_"),
    ~ abs(.x - as.numeric(ref_z[[cur_column()]])),  # force scalar extraction
    .names = "ai_{.col}"
  ))

# create indices
ai_cols <- names(metals_ai)[grepl("^ai_z_", names(metals_ai))] # grabbing ai_z columns
metal_names <- gsub("^ai_z_", "", ai_cols) # removing the prefix

# filter columns into heavy and nutrient classes
ai_heavy <- ai_cols[metal_names %in% c("arsenic", "cadmium", "mercury")]
ai_nutrient <- ai_cols[metal_names %in% c("copper", "lead", "zinc")]

# create new index columns
metals_index <- metals_ai %>%
  rowwise() %>%
  mutate(
    heavy_metal_index = sum(c_across(all_of(ai_heavy)), na.rm = TRUE),
    nutrient_metal_index = sum(c_across(all_of(ai_nutrient)), na.rm = TRUE),
    total_metal_index = heavy_metal_index + nutrient_metal_index
  ) %>%
  ungroup()


# view & save
print(metals_index)
#write.csv(metals_ai, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/metals_ai.csv", row.names = FALSE)
#write.csv(metals_index, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/metal_index.csv", row.names = FALSE)

```

## pah, lmw
### data prep
```{r}

pah_lmw<- read.csv("../data/index_df/test_pah_lmw.csv")
# fixing site names, fixing column names, removing white space in the name changes, adjusting undetected values to zero, pivoting for index creation
pah_lmw$site_name[pah_lmw$site_name == "Blair Waterway #2"] <- "Blair Waterway Two"
pah_lmw$site_name[pah_lmw$site_name == "Comm Bay Skookum"] <- "Commencement Bay Skookum"
pah_lmw$site_name[pah_lmw$site_name == "Comm Bay, Dick Gilmur Launch"] <- "Commencement Bay, Dick Gilmur Launch"
pah_lmw$site_name[pah_lmw$site_name == "Comm Bay, Milwaukee Waterway"] <- "Commencement Bay, Milwaukee Waterway"
pah_lmw$site_name[pah_lmw$site_name == "Meyer's Point - Henderson Inlet"] <- "Meyer's Point, Henderson Inlet"
pah_lmw$site_name[pah_lmw$site_name == "Purdy - Dexters"] <- "Purdy, Dexters"
pah_lmw$site_name[pah_lmw$site_name == "S of Skunk Island"] <- "South of Skunk Island"
pah_lmw$site_name[pah_lmw$site_name == "Suquamish, Stormwater Outfall"] <- "Suquamish Stormwater Outfall"

pah_lmw <- pah_lmw %>%
  mutate(across(where(is.character), str_trim))

pah_lmw<- pah_lmw %>%
  mutate(flagged = grepl("U|B|I", qualifier),
         wet_value = ifelse(flagged, 0, wet_value))

head(pah_lmw)

#### changing analyte names with janitor ####
#install.packages("janitor")
#library("janitor")
#pah_lmw <- pah_lmw %>%
#  mutate(analyte_clean = make_clean_names(analyte))
#### end name changing ####

pah_lmw <- pah_lmw %>%
  select(site_name, latitude, longitude, analyte, wet_value)  # keep only what's needed
pah_lmw_wide <- pah_lmw %>%
  pivot_wider(
    names_from = analyte,
    values_from = wet_value
  )

print(pah_lmw_wide)
# Save the cleaned wide-format table
#write.csv(pah_lmw_wide, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/pah_lmw_wide.csv", row.names = FALSE)

```

### index creation
```{r}

pah_lmw_df<- pah_lmw_wide
colnames(pah_lmw_df)

# define variables
pah_lmw_analytes <- names(pah_lmw_df)[4:24]

# z-score
pah_lmw_z <- pah_lmw_df %>%
  mutate(across(all_of(pah_lmw_analytes), scale, .names = "z_{.col}"))

# reference
ref_site <- "Penn Cove Baseline"
ref_z_pah_lmw <- pah_lmw_z %>%
  filter(site_name == ref_site) %>%
  select(starts_with("z_")) %>%
  slice(1)

# deviation
pah_lmw_ai <- pah_lmw_z %>%
  mutate(across(
    starts_with("z_"),
    ~ abs(.x - as.numeric(ref_z_pah_lmw[[cur_column()]])),
    .names = "ai_{.col}"
  ))

# create index
ai_cols <- names(pah_lmw_ai)[grepl("^ai_", names(pah_lmw_ai))] # id ai columns
pah_lmw_index<- pah_lmw_ai %>%
  rowwise() %>%
  mutate(pah_lmw_index = sum(c_across(all_of(ai_cols)), na.rm = TRUE)) %>%
  ungroup()

# view & save
print(pah_lmw_index)
#write.csv(pah_lmw_ai, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/pah_lmw_ai.csv", row.names = FALSE)
#write.csv(pah_lmw_index, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/pah_lmw_index.csv", row.names = FALSE)

```

## pah, hmw
### data prep
```{r}

pah_hmw<- read.csv("../data/index_df/test_pah_hmw.csv")
# fixing site names, fixing column names, removing white space in the name changes, adjusting undetected values to zero, pivoting for index creation
pah_hmw$site_name[pah_hmw$site_name == "Blair Waterway #2"] <- "Blair Waterway Two"
pah_hmw$site_name[pah_hmw$site_name == "Comm Bay Skookum"] <- "Commencement Bay Skookum"
pah_hmw$site_name[pah_hmw$site_name == "Comm Bay, Dick Gilmur Launch"] <- "Commencement Bay, Dick Gilmur Launch"
pah_hmw$site_name[pah_hmw$site_name == "Comm Bay, Milwaukee Waterway"] <- "Commencement Bay, Milwaukee Waterway"
pah_hmw$site_name[pah_hmw$site_name == "Meyer's Point - Henderson Inlet"] <- "Meyer's Point, Henderson Inlet"
pah_hmw$site_name[pah_hmw$site_name == "Purdy - Dexters"] <- "Purdy, Dexters"
pah_hmw$site_name[pah_hmw$site_name == "S of Skunk Island"] <- "South of Skunk Island"
pah_hmw$site_name[pah_hmw$site_name == "Suquamish, Stormwater Outfall"] <- "Suquamish Stormwater Outfall"

pah_hmw <- pah_hmw %>%
  mutate(across(where(is.character), str_trim))

pah_hmw<- pah_hmw %>%
  mutate(flagged = grepl("U|B|I", qualifier),
         wet_value = ifelse(flagged, 0, wet_value))

#### changing analyte names with janitor - see pah_lmw block ####

pah_hmw <- pah_hmw %>%
  select(site_name, latitude, longitude, analyte, wet_value) 
pah_hmw_wide <- pah_hmw %>%
  pivot_wider(
    names_from = analyte,
    values_from = wet_value
  )

# view & save
print(pah_hmw_wide)
#write.csv(pah_hmw_wide, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/pah_hmw_wide.csv", row.names = FALSE)

```

### index creation
```{r}

pah_hmw_df<- pah_hmw_wide
colnames(pah_hmw_df)

# define variables
pah_hmw_analytes <- names(pah_hmw_df)[4:23]

# z-score
pah_hmw_z <- pah_hmw_df %>%
  mutate(across(all_of(pah_hmw_analytes), scale, .names = "z_{.col}"))

# reference
ref_site <- "Penn Cove Baseline"
ref_z_pah_hmw <- pah_hmw_z %>%
  filter(site_name == ref_site) %>%
  select(starts_with("z_")) %>%
  slice(1)

# deviation
pah_hmw_ai <- pah_hmw_z %>%
  mutate(across(
    starts_with("z_"),
    ~ abs(.x - as.numeric(ref_z_pah_hmw[[cur_column()]])),
    .names = "ai_{.col}"
  ))

# create index
ai_cols <- names(pah_hmw_ai)[grepl("^ai_", names(pah_hmw_ai))] # id ai columns
pah_hmw_index<- pah_hmw_ai %>%
  rowwise() %>%
  mutate(pah_hmw_index = sum(c_across(all_of(ai_cols)), na.rm = TRUE)) %>%
  ungroup()

# view & save
print(pah_hmw_index)
#write.csv(pah_hmw_ai, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/pah_hmw_ai.csv", row.names = FALSE)
#write.csv(pah_hmw_index, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/pah_hmw_index.csv", row.names = FALSE)

```

## pah, additional
### data prep
```{r}

pah_add<- read.csv("../data/index_df/test_pah_additional.csv")
# fixing site names, fixing column names, removing white space in the name changes, adjusting undetected values to zero, pivoting for index creation
pah_add$site_name[pah_add$site_name == "Blair Waterway #2"] <- "Blair Waterway Two"
pah_add$site_name[pah_add$site_name == "Comm Bay Skookum"] <- "Commencement Bay Skookum"
pah_add$site_name[pah_add$site_name == "Comm Bay, Dick Gilmur Launch"] <- "Commencement Bay, Dick Gilmur Launch"
pah_add$site_name[pah_add$site_name == "Comm Bay, Milwaukee Waterway"] <- "Commencement Bay, Milwaukee Waterway"
pah_add$site_name[pah_add$site_name == "Meyer's Point - Henderson Inlet"] <- "Meyer's Point, Henderson Inlet"
pah_add$site_name[pah_add$site_name == "Purdy - Dexters"] <- "Purdy, Dexters"
pah_add$site_name[pah_add$site_name == "S of Skunk Island"] <- "South of Skunk Island"
pah_add$site_name[pah_add$site_name == "Suquamish, Stormwater Outfall"] <- "Suquamish Stormwater Outfall"

pah_add <- pah_add %>%
  mutate(across(where(is.character), str_trim))

pah_add<- pah_add %>%
  mutate(flagged = grepl("U|B|I", qualifier),
         wet_value = ifelse(flagged, 0, wet_value))

#### changing analyte names with janitor - see pah_lmw block ####

pah_add <- pah_add %>%
  select(site_name, latitude, longitude, analyte, wet_value)  # keep only what's needed
pah_add_wide <- pah_add %>%
  pivot_wider(
    names_from = analyte,
    values_from = wet_value
  )

# view & save
print(pah_add_wide)
write.csv(pah_add_wide, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/pah_additional_wide.csv", row.names = FALSE)

```

### index creation
```{r}

pah_add_df<- pah_add_wide
colnames(pah_add_df)

# define variables
pah_add_analytes <- names(pah_add_df)[4:12]

# z-score
pah_add_z <- pah_add_df %>%
  mutate(across(all_of(pah_add_analytes), scale, .names = "z_{.col}"))

# reference
ref_site <- "Penn Cove Baseline"
ref_z_pah_add <- pah_add_z %>%
  filter(site_name == ref_site) %>%
  select(starts_with("z_")) %>%
  slice(1)

# deviation
pah_add_ai <- pah_add_z %>%
  mutate(across(
    starts_with("z_"),
    ~ abs(.x - as.numeric(ref_z_pah_add[[cur_column()]])),
    .names = "ai_{.col}"
  ))

# create index
ai_cols <- names(pah_add_ai)[grepl("^ai_", names(pah_add_ai))] # id ai columns
pah_add_index<- pah_add_ai %>%
  rowwise() %>%
  mutate(pah_add_index = sum(c_across(all_of(ai_cols)), na.rm = TRUE)) %>%
  ungroup()

# view & save
print(pah_add_index)
#write.csv(pah_add_ai, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/pah_add_ai.csv", row.names = FALSE)
#write.csv(pah_add_index, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/pah_additional_index.csv", row.names = FALSE)

```

## total pah index creation
```{r}

# read in
pah_df <- read.csv("../data/index_df/combined_pah_index_interim.csv")

# create total pah index
pah_df <- pah_df %>%
  mutate(total_pah_index = pah_lmw_index + pah_hmw_index + pah_add_index)

# view & save
print(pah_df)
#write.csv(pah_df, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/pah_total_index.csv", row.names = FALSE)

```

## pbde
```{r}

pbde_df<- pbde
colnames(pbde_df)

# define variables
pbde_analytes <- names(pbde_df)[4:14]

# z-score
pbde_z <- pbde_df %>%
  mutate(across(all_of(pbde_analytes), scale, .names = "z_{.col}"))

# reference
ref_site <- "Penn Cove Baseline"
ref_z_pbde <- pbde_z %>%
  filter(site_name == ref_site) %>%
  select(starts_with("z_")) %>%
  slice(1)

# deviation
pbde_ai <- pbde_z %>%
  mutate(across(
    starts_with("z_"),
    ~ abs(.x - as.numeric(ref_z_pbde[[cur_column()]])),
    .names = "ai_{.col}"
  ))

# create index
ai_cols <- names(pbde_ai)[grepl("^ai_", names(pbde_ai))] # id ai columns
pbde_index<- pbde_ai %>%
  rowwise() %>%
  mutate(pbde_index = sum(c_across(all_of(ai_cols)), na.rm = TRUE)) %>%
  ungroup()

# view & save
print(pbde_index)
#write.csv(pbde_ai, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/pbde_ai.csv", row.names = FALSE)
#write.csv(pbde_index, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/pbde_index.csv", row.names = FALSE)

```

## pcb
```{r}

pcb_df<- pcb
colnames(pcb_df)

# define variables
pcb_analytes <- names(pcb_df)[4:45]

# z-score
pcb_z <- pcb_df %>%
  mutate(across(all_of(pcb_analytes), scale, .names = "z_{.col}"))

# reference
ref_site <- "Penn Cove Baseline"
ref_z_pcb <- pcb_z %>%
  filter(site_name == ref_site) %>%
  select(starts_with("z_")) %>%
  slice(1)

# deviation
pcb_ai <- pcb_z %>%
  mutate(across(
    starts_with("z_"),
    ~ abs(.x - as.numeric(ref_z_pcb[[cur_column()]])),
    .names = "ai_{.col}"
  ))

# create index
ai_cols <- names(pcb_ai)[grepl("^ai_", names(pcb_ai))] # id ai columns
pcb_index<- pcb_ai %>%
  rowwise() %>%
  mutate(pcb_index = sum(c_across(all_of(ai_cols)), na.rm = TRUE)) %>%
  ungroup()

# view & save
print(pcb_index)
#write.csv(pcb_ai, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/pcb_ai.csv", row.names = FALSE)
#write.csv(pcb_index, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/pcb_index.csv", row.names = FALSE)

```

## pesticide
```{r}

pesticide_wide<- read.csv("../data/index_df/pesticide_wide.csv")

pesticide_df<- pesticide_wide
colnames(pesticide_df)

# define variables
pesticide_analytes <- names(pesticide_df)[4:8]

# z-score
pesticide_z <- pesticide_df %>%
  mutate(across(all_of(pesticide_analytes), scale, .names = "z_{.col}"))

# reference
ref_site <- "Penn Cove Baseline"
ref_z_pesticide <- pesticide_z %>%
  filter(site_name == ref_site) %>%
  select(starts_with("z_")) %>%
  slice(1)

# deviation
pesticide_ai <- pesticide_z %>%
  mutate(across(
    starts_with("z_"),
    ~ abs(.x - as.numeric(ref_z_pesticide[[cur_column()]])),
    .names = "ai_{.col}"
  ))

# create index
ai_cols <- names(pesticide_ai)[grepl("^ai_", names(pesticide_ai))] # id ai columns
pesticide_index<- pesticide_ai %>%
  rowwise() %>%
  mutate(pesticide_index = sum(c_across(all_of(ai_cols)), na.rm = TRUE)) %>%
  ungroup()

# view & save
print(pesticide_index)
#write.csv(pesticide_ai, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/pesticide_ai.csv", row.names = FALSE)
#write.csv(pesticide_index, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/pesticide_index.csv", row.names = FALSE)

```

# Creating Chemical Mixture Indices
# Left off of index creation - may be too much for what we need. Updated 9.26.25
## sum- based, unweighted mixture index
```{r}

colnames(site_data)
# leaving out chlordane, hch and pesticides since they have heavy zeros

# converting metals to match other contaminants - metals are reported in mg/kg and all others are ng/g
# 1 mg/kg = 1,000 ng/g
site_data$heavy_metal_ng <- site_data$heavy_metal * 1000
site_data$nutrient_metal_ng <- site_data$nutrient_metal * 1000

site_data$mixture_index_sum <- rowSums(site_data[, c("ddt", "heavy_metal_ng", "nutrient_metal_ng", "pah_lmw", "pah_hmw", "pah_add", "pbde", "pcb")], na.rm = TRUE)

```

## pca- based, standardized mixture index
```{r}

# leaving out chlordane, hch and pesticides since they have heavy zeros; same as above

# contaminant index matrix
contaminants <- site_data[, c("ddt", "heavy_metal_ng", "nutrient_metal_ng", "pah_lmw", "pah_hmw", "pah_add", "pbde", "pcb")]

# scale with z-score standardization
contaminants_scaled <- scale(contaminants)

# PCA
pca_result <- prcomp(contaminants_scaled, center = TRUE, scale. = TRUE)

# use PC1 scores as the PCA-based mixture index
site_data$mixture_index_pca <- pca_result$x[, 1]

# how much variance is explained by PC1? ~49% of variation
summary(pca_result)$importance[2, 1]  # proportion of variance explained by PC1

#save data for other downstream analyses
#write.csv(site_data, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/site_with_mixture_index.csv", row.names = FALSE)

```

