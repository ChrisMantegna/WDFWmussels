---
title: "2- Creating an IBR & Contaminant Concentration Index (CCI)"
output:
  pdf_document: 
    fig_width: 20
    fig_height: 9
  html_document: 
    toc: true
    toc_float:
        collapsed: false
        smooth_scroll: true
    fig_width: 20
---

# Directory and doc rules

```{r, setup, eval=TRUE, include=TRUE, echo=FALSE}

knitr::opts_chunk$set(
  root.dir = here::here(),
  echo = TRUE,         # show code chunks
  eval = TRUE,         # evaluate code chunks
  warning = FALSE,     # hide warnings
  message = FALSE,     # hide messages
  #fig.width = 15,       # set plot width in inches
  #fig.height = 9,      # set plot height in inches
  fig.align = "center" # slign plots to the center in output doc/ slide/ whatever
)

# libraries
library(car) # VERIFY what this is for 
library(cluster) # grouping metrics - VERIFY still needed
library(dplyr) # data wrangling
library(factoextra) # pca/ nmds/ tweaking radars
library(FactoMineR) # pca/ nmds/ tweaking radars
library(fmsb) # polygon calculations for the radars
library(FSA) # post hoc test - Dunn's Test    
library(ggplot2) # plots
library(knitr) # output formatting
library(pgirmess) # stats - KW
library(purrr) # works with tidy
library(rcompanion) # KW testing
library(rstatix) # VERIFY what this is for
library(rlang) # verify what this is for
library(RVAideMemoire) # post hoc test for permanova
library(scales) # scaling data for IBR - works with data wrangling packages
library(stringr) # helps with tidyverse table manipulation/ name reading
library(tidyr) # data wrangling
library(tidyverse) # data wrangling
library(vegan) # ecological stats 

```

# Load & Check Data
```{r}

getwd()

site_data<- read.csv("../data/start_here/cleaned_sample_level.csv")
sample_data<- read.csv("../data/cleaned/site_level_no_indices.csv")

site_data$reporting_area <- as.factor(site_data$reporting_area)
site_data$site_number<- as.factor(site_data$site_number)

sample_data$reporting_area <- as.factor(sample_data$reporting_area)
sample_data$site_number<- as.factor(sample_data$site_number)
sample_data$sample_number<- as.factor(sample_data$sample_number)

summary(site_data)


```
# 9.29.25 - Restart here with sample_level data if I want to match the Mattos method

# Creating Mattos' IBRv2i Index with biomarkers and raw morphometrics (no condition indices)

## log2 transform the metrics - sample-level used in 3.2
```{r}



```



## log2 transform the metrics - site-level used in 1/3 analysis outputs (3.2)
```{r}

# define our reference
site_col  <- "site_name"
ref_site  <- "Penn Cove Reference"

# columns we want to remain unchanged 
id_cols <- c("site_number","site_name", "reporting_area", "latitude", "longitude")

#  metrics that feed into the IBR 
metric_cols <- c("p450","sod", "shell", "weight_initial", "weight_change", "weight_final", "length","height","width")

# metrics that do not feed into the IBR
condition_cols <- c("ci1","ci2","ci3")

# metrics to center geometrically because they have strong skews, all others will be default (arithmetic)
geom_center_metrics <- c("p450","sod", "ci1", "ci2", "height")

# positive floor for safe log2 (prevents log2(0))
eps <- .Machine$double.eps

# function to complete the transformation
prepare_metrics_for_ibr_tidy <- function(site_data, site_col, ref_site, id_cols, metric_cols, condition_cols, geom_center_metrics, eps = .Machine$double.eps) 
  {

  stopifnot(site_col %in% names(site_data))
  all_metrics <- c(metric_cols, condition_cols)

  # keep only what we need
  keep_cols <- unique(c(id_cols, all_metrics, site_col))
  keep_cols <- keep_cols[keep_cols %in% names(site_data)]
  site_data <- site_data %>% select(all_of(keep_cols))

 metrics_transformed <- site_data %>%
    dplyr::mutate(
      dplyr::across(dplyr::all_of(all_metrics),
                    ~ log2(pmax(.x, eps)),
                    .names = "t_{.col}")
    )

  # add transformed columns to og columns - fix because the naming alteration didn't work
  metrics_transformed <- metrics_transformed %>%
    dplyr::relocate(dplyr::all_of(id_cols), .before = 1) %>%
    dplyr::relocate(dplyr::starts_with("t_"), .after = dplyr::last_col())

  metrics_transformed
}

# save
#write.csv(metrics_transformed, "../data/metrics_transformed_09282025.csv")

```


## z-score standardization, absolute sd (AI)- Scaling
```{r}

# define data, reference site, necessary metrics, which scaling method should be used, and the end output
metrics_transformed<- metrics_transformed
site_col<- "site_name"
ref_site<- "Penn Cove Reference"
biomarker_metrics<- c("p450_t","sod_t")
morphometric_metrics<- c("shell_t","length_t","height_t","width_t","weight_change_t")
condition_metrics<- c("ci1_t","ci2_t","ci3_t")
geom_metrics<- c("p450_t","sod_t","ci1_t","ci2_t","height_t")  
metrics_for_ibr<- c(biomarker_metrics, morphometric_metrics)

resolve_t <- function(metrics_transformed, req) {
  sapply(req, function(m) {
    if (m %in% names(metrics_transformed)) return(m)                             # e.g., "p450_t"
    m2 <- paste0("t_", sub("_t$", "", m))                       # try "t_p450"
    if (m2 %in% names(metrics_transformed)) return(m2)
    stop("Missing transformed column for '", m, "'. Looked for '", m, "' and '", m2, "'.")
  }, USE.NAMES = FALSE)
}
base_from_t <- function(tn) sub("^t_", "", sub("_t$", "", tn))

# columns to scale
t_cols_all_req<- c(metrics_for_ibr, condition_metrics)
t_cols<- resolve_t(metrics_transformed, t_cols_all_req)     
geom_t_cols    <- resolve_t(metrics_transformed, geom_metrics)      

# reference
ref_rows <- metrics_transformed[[site_col]] == ref_site
if (!any(ref_rows)) stop("No rows match the reference site: ", ref_site)

# scaling
centers <- vapply(t_cols, function(tc) {
  t_ref <- metrics_transformed[[tc]][ref_rows]
  if (tc %in% geom_t_cols) {
    mean(t_ref, na.rm = TRUE)                                         
  } else {
    log2(mean(2^t_ref, na.rm = TRUE))                                  
  }
}, numeric(1))
names(centers) <- t_cols

metrics_transformed <- metrics_transformed %>%
  mutate(across(all_of(t_cols),
                ~ .x - centers[cur_column()],
                .names = "{.col}_s")) %>%
  rename_with(~ sub("_t_s$", "_s", .x), ends_with("_t_s")) %>%
  rename_with(~ sub("^t_(.*)_s$", "\\1_s", .x), matches("^t_.*_s$"))

# z-scores of centered for IBR metrics only
ibr_t_cols <- resolve_t(metrics_transformed, metrics_for_ibr)         
ibr_bases  <- base_from_t(ibr_t_cols)
s_cols_ibr <- paste0(ibr_bases, "_s")

metrics_transformed <- metrics_transformed %>%
  mutate(across(all_of(s_cols_ibr),
                ~ as.numeric(scale(.x)),
                .names = "{.col}_zs"))                               
# absolute deviation-ai
metrics_transformed <- metrics_transformed %>%
  mutate(across(all_of(s_cols_ibr),
                ~ abs(.x),
                .names = "ai_{.col}"))

# view
metrics_transformed %>% select(all_of(site_col), ends_with("_s"))  %>% head()
metrics_transformed %>% select(all_of(site_col), ends_with("_zs")) %>% head()
metrics_transformed %>% select(all_of(site_col), starts_with("ai_")) %>% head()

# save
#write.csv(metrics_transformed, "../data/site_level_transform_and_scale_09282025.csv", row.names = FALSE)

```


##  IBR scoring
```{r}




```

## Creating Chemical Contaminant Indices by class
### Not recreated on 9.26.25 - current indices are complete
## chlordane
```{r}

chlordane_df<- chlordane

# define variables
chlordane_analytes <- c("alpha_chlordane", "beta_chlordane", "cis_nonachlor", 
                        "heptachlor", "heptachlor_epoxide", "nonachlor3", 
                        "Oxychlordane", "trans_Nonachlor")

# z-score
chlordane_z <- chlordane_df %>%
  mutate(across(all_of(chlordane_analytes), scale, .names = "z_{.col}"))

# reference
ref_site <- "Penn Cove Baseline"
ref_z_chlordane <- chlordane_z %>%
  filter(site_name == ref_site) %>%
  select(starts_with("z_")) %>%
  slice(1)

# deviation
chlordane_ai <- chlordane_z %>%
  mutate(across(
    starts_with("z_"),
    ~ abs(.x - as.numeric(ref_z_chlordane[[cur_column()]])),
    .names = "ai_{.col}"
  ))

# create index
ai_cols <- names(chlordane_ai)[grepl("^ai_", names(chlordane_ai))] # id ai columns
chlordane_index<- chlordane_ai %>%
  rowwise() %>%
  mutate(chlordane_index = sum(c_across(all_of(ai_cols)), na.rm = TRUE)) %>%
  ungroup()

# view & save
print(chlordane_index)
#write.csv(chlordane_ai, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/chlordane_ai.csv", row.names = FALSE)
#write.csv(chlordane_index, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/chlordane_index.csv", row.names = FALSE)

```

## ddt
```{r}

ddt_df<- ddt
#colnames(ddt_df)

# define variables
ddt_analytes <- c("opDDD", "opDDE", "opDDT", "ppDDD", "ppDDT", "ppDDE")

# z-score
ddt_z <- ddt_df %>%
  mutate(across(all_of(ddt_analytes), scale, .names = "z_{.col}"))

# reference
ref_site <- "Penn Cove Baseline"
ref_z_ddt <- ddt_z %>%
  filter(site_name == ref_site) %>%
  select(starts_with("z_")) %>%
  slice(1)

# deviation
ddt_ai <- ddt_z %>%
  mutate(across(
    starts_with("z_"),
    ~ abs(.x - as.numeric(ref_z_ddt[[cur_column()]])),
    .names = "ai_{.col}"
  ))

# create index
ai_cols <- names(ddt_ai)[grepl("^ai_", names(ddt_ai))] # id ai columns
ddt_index<- ddt_ai %>%
  rowwise() %>%
  mutate(ddt_index = sum(c_across(all_of(ai_cols)), na.rm = TRUE)) %>%
  ungroup()

# view & save
print(ddt_index)
#write.csv(ddt_ai, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/ddt_ai.csv", row.names = FALSE)
#write.csv(ddt_index, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/ddt_index.csv", row.names = FALSE)

```

## hch
```{r}

hch_df<- hch
colnames(hch_df)

# define variables
hch_analytes <- c("alpha_hexachlorocyclohexane", "beta_hexachlorocyclohexane", "gamma_hexachlorocyclohexane")

# z-score
hch_z <- hch_df %>%
  mutate(across(all_of(hch_analytes), scale, .names = "z_{.col}"))

# reference
ref_site <- "Penn Cove Baseline"
ref_z_hch <- hch_z %>%
  filter(site_name == ref_site) %>%
  select(starts_with("z_")) %>%
  slice(1)

# deviation
hch_ai <- hch_z %>%
  mutate(across(
    starts_with("z_"),
    ~ abs(.x - as.numeric(ref_z_hch[[cur_column()]])),
    .names = "ai_{.col}"
  ))

# create index
ai_cols <- names(hch_ai)[grepl("^ai_", names(hch_ai))] # id ai columns
hch_index<- hch_ai %>%
  rowwise() %>%
  mutate(hch_index = sum(c_across(all_of(ai_cols)), na.rm = TRUE)) %>%
  ungroup()

# view & save
print(hch_index)
#write.csv(hch_ai, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/hch_ai.csv", row.names = FALSE)
#write.csv(hch_index, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/hch_index.csv", row.names = FALSE)

```

## metal
```{r}

metal_df<- metal

# define variables
heavy_metals <- c("arsenic", "cadmium", "mercury")
nutrient_metals <- c("copper", "lead", "zinc")

# setup complete metal index
all_metals <- c(heavy_metals, nutrient_metals)

# z-score for each analyte (site-level is not possible based on single site values)
metals_z <- metal_df %>%
  mutate(across(all_of(all_metals), scale, .names = "z_{.col}"))

# pull reference scores
ref_site <- "Penn Cove Baseline"
ref_z <- metals_z %>%
  filter(site_name == ref_site) %>%
  select(starts_with("z_")) %>%
  slice(1)

# absolute deviation from reference z-score for each metal
metals_ai <- metals_z %>%
  mutate(across(
    starts_with("z_"),
    ~ abs(.x - as.numeric(ref_z[[cur_column()]])),  # force scalar extraction
    .names = "ai_{.col}"
  ))

# create indices
ai_cols <- names(metals_ai)[grepl("^ai_z_", names(metals_ai))] # grabbing ai_z columns
metal_names <- gsub("^ai_z_", "", ai_cols) # removing the prefix

# filter columns into heavy and nutrient classes
ai_heavy <- ai_cols[metal_names %in% c("arsenic", "cadmium", "mercury")]
ai_nutrient <- ai_cols[metal_names %in% c("copper", "lead", "zinc")]

# create new index columns
metals_index <- metals_ai %>%
  rowwise() %>%
  mutate(
    heavy_metal_index = sum(c_across(all_of(ai_heavy)), na.rm = TRUE),
    nutrient_metal_index = sum(c_across(all_of(ai_nutrient)), na.rm = TRUE),
    total_metal_index = heavy_metal_index + nutrient_metal_index
  ) %>%
  ungroup()


# view & save
print(metals_index)
#write.csv(metals_ai, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/metals_ai.csv", row.names = FALSE)
#write.csv(metals_index, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/metal_index.csv", row.names = FALSE)

```

## pah, lmw
### data prep
```{r}

pah_lmw<- read.csv("../data/index_df/test_pah_lmw.csv")
# fixing site names, fixing column names, removing white space in the name changes, adjusting undetected values to zero, pivoting for index creation
pah_lmw$site_name[pah_lmw$site_name == "Blair Waterway #2"] <- "Blair Waterway Two"
pah_lmw$site_name[pah_lmw$site_name == "Comm Bay Skookum"] <- "Commencement Bay Skookum"
pah_lmw$site_name[pah_lmw$site_name == "Comm Bay, Dick Gilmur Launch"] <- "Commencement Bay, Dick Gilmur Launch"
pah_lmw$site_name[pah_lmw$site_name == "Comm Bay, Milwaukee Waterway"] <- "Commencement Bay, Milwaukee Waterway"
pah_lmw$site_name[pah_lmw$site_name == "Meyer's Point - Henderson Inlet"] <- "Meyer's Point, Henderson Inlet"
pah_lmw$site_name[pah_lmw$site_name == "Purdy - Dexters"] <- "Purdy, Dexters"
pah_lmw$site_name[pah_lmw$site_name == "S of Skunk Island"] <- "South of Skunk Island"
pah_lmw$site_name[pah_lmw$site_name == "Suquamish, Stormwater Outfall"] <- "Suquamish Stormwater Outfall"

pah_lmw <- pah_lmw %>%
  mutate(across(where(is.character), str_trim))

pah_lmw<- pah_lmw %>%
  mutate(flagged = grepl("U|B|I", qualifier),
         wet_value = ifelse(flagged, 0, wet_value))

head(pah_lmw)

#### changing analyte names with janitor ####
#install.packages("janitor")
#library("janitor")
#pah_lmw <- pah_lmw %>%
#  mutate(analyte_clean = make_clean_names(analyte))
#### end name changing ####

pah_lmw <- pah_lmw %>%
  select(site_name, latitude, longitude, analyte, wet_value)  # keep only what's needed
pah_lmw_wide <- pah_lmw %>%
  pivot_wider(
    names_from = analyte,
    values_from = wet_value
  )

print(pah_lmw_wide)
# Save the cleaned wide-format table
#write.csv(pah_lmw_wide, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/pah_lmw_wide.csv", row.names = FALSE)

```

### index creation
```{r}

pah_lmw_df<- pah_lmw_wide
colnames(pah_lmw_df)

# define variables
pah_lmw_analytes <- names(pah_lmw_df)[4:24]

# z-score
pah_lmw_z <- pah_lmw_df %>%
  mutate(across(all_of(pah_lmw_analytes), scale, .names = "z_{.col}"))

# reference
ref_site <- "Penn Cove Baseline"
ref_z_pah_lmw <- pah_lmw_z %>%
  filter(site_name == ref_site) %>%
  select(starts_with("z_")) %>%
  slice(1)

# deviation
pah_lmw_ai <- pah_lmw_z %>%
  mutate(across(
    starts_with("z_"),
    ~ abs(.x - as.numeric(ref_z_pah_lmw[[cur_column()]])),
    .names = "ai_{.col}"
  ))

# create index
ai_cols <- names(pah_lmw_ai)[grepl("^ai_", names(pah_lmw_ai))] # id ai columns
pah_lmw_index<- pah_lmw_ai %>%
  rowwise() %>%
  mutate(pah_lmw_index = sum(c_across(all_of(ai_cols)), na.rm = TRUE)) %>%
  ungroup()

# view & save
print(pah_lmw_index)
#write.csv(pah_lmw_ai, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/pah_lmw_ai.csv", row.names = FALSE)
#write.csv(pah_lmw_index, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/pah_lmw_index.csv", row.names = FALSE)

```

## pah, hmw
### data prep
```{r}

pah_hmw<- read.csv("../data/index_df/test_pah_hmw.csv")
# fixing site names, fixing column names, removing white space in the name changes, adjusting undetected values to zero, pivoting for index creation
pah_hmw$site_name[pah_hmw$site_name == "Blair Waterway #2"] <- "Blair Waterway Two"
pah_hmw$site_name[pah_hmw$site_name == "Comm Bay Skookum"] <- "Commencement Bay Skookum"
pah_hmw$site_name[pah_hmw$site_name == "Comm Bay, Dick Gilmur Launch"] <- "Commencement Bay, Dick Gilmur Launch"
pah_hmw$site_name[pah_hmw$site_name == "Comm Bay, Milwaukee Waterway"] <- "Commencement Bay, Milwaukee Waterway"
pah_hmw$site_name[pah_hmw$site_name == "Meyer's Point - Henderson Inlet"] <- "Meyer's Point, Henderson Inlet"
pah_hmw$site_name[pah_hmw$site_name == "Purdy - Dexters"] <- "Purdy, Dexters"
pah_hmw$site_name[pah_hmw$site_name == "S of Skunk Island"] <- "South of Skunk Island"
pah_hmw$site_name[pah_hmw$site_name == "Suquamish, Stormwater Outfall"] <- "Suquamish Stormwater Outfall"

pah_hmw <- pah_hmw %>%
  mutate(across(where(is.character), str_trim))

pah_hmw<- pah_hmw %>%
  mutate(flagged = grepl("U|B|I", qualifier),
         wet_value = ifelse(flagged, 0, wet_value))

#### changing analyte names with janitor - see pah_lmw block ####

pah_hmw <- pah_hmw %>%
  select(site_name, latitude, longitude, analyte, wet_value) 
pah_hmw_wide <- pah_hmw %>%
  pivot_wider(
    names_from = analyte,
    values_from = wet_value
  )

# view & save
print(pah_hmw_wide)
#write.csv(pah_hmw_wide, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/pah_hmw_wide.csv", row.names = FALSE)

```

### index creation
```{r}

pah_hmw_df<- pah_hmw_wide
colnames(pah_hmw_df)

# define variables
pah_hmw_analytes <- names(pah_hmw_df)[4:23]

# z-score
pah_hmw_z <- pah_hmw_df %>%
  mutate(across(all_of(pah_hmw_analytes), scale, .names = "z_{.col}"))

# reference
ref_site <- "Penn Cove Baseline"
ref_z_pah_hmw <- pah_hmw_z %>%
  filter(site_name == ref_site) %>%
  select(starts_with("z_")) %>%
  slice(1)

# deviation
pah_hmw_ai <- pah_hmw_z %>%
  mutate(across(
    starts_with("z_"),
    ~ abs(.x - as.numeric(ref_z_pah_hmw[[cur_column()]])),
    .names = "ai_{.col}"
  ))

# create index
ai_cols <- names(pah_hmw_ai)[grepl("^ai_", names(pah_hmw_ai))] # id ai columns
pah_hmw_index<- pah_hmw_ai %>%
  rowwise() %>%
  mutate(pah_hmw_index = sum(c_across(all_of(ai_cols)), na.rm = TRUE)) %>%
  ungroup()

# view & save
print(pah_hmw_index)
#write.csv(pah_hmw_ai, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/pah_hmw_ai.csv", row.names = FALSE)
#write.csv(pah_hmw_index, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/pah_hmw_index.csv", row.names = FALSE)

```

## pah, additional
### data prep
```{r}

pah_add<- read.csv("../data/index_df/test_pah_additional.csv")
# fixing site names, fixing column names, removing white space in the name changes, adjusting undetected values to zero, pivoting for index creation
pah_add$site_name[pah_add$site_name == "Blair Waterway #2"] <- "Blair Waterway Two"
pah_add$site_name[pah_add$site_name == "Comm Bay Skookum"] <- "Commencement Bay Skookum"
pah_add$site_name[pah_add$site_name == "Comm Bay, Dick Gilmur Launch"] <- "Commencement Bay, Dick Gilmur Launch"
pah_add$site_name[pah_add$site_name == "Comm Bay, Milwaukee Waterway"] <- "Commencement Bay, Milwaukee Waterway"
pah_add$site_name[pah_add$site_name == "Meyer's Point - Henderson Inlet"] <- "Meyer's Point, Henderson Inlet"
pah_add$site_name[pah_add$site_name == "Purdy - Dexters"] <- "Purdy, Dexters"
pah_add$site_name[pah_add$site_name == "S of Skunk Island"] <- "South of Skunk Island"
pah_add$site_name[pah_add$site_name == "Suquamish, Stormwater Outfall"] <- "Suquamish Stormwater Outfall"

pah_add <- pah_add %>%
  mutate(across(where(is.character), str_trim))

pah_add<- pah_add %>%
  mutate(flagged = grepl("U|B|I", qualifier),
         wet_value = ifelse(flagged, 0, wet_value))

#### changing analyte names with janitor - see pah_lmw block ####

pah_add <- pah_add %>%
  select(site_name, latitude, longitude, analyte, wet_value)  # keep only what's needed
pah_add_wide <- pah_add %>%
  pivot_wider(
    names_from = analyte,
    values_from = wet_value
  )

# view & save
print(pah_add_wide)
write.csv(pah_add_wide, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/pah_additional_wide.csv", row.names = FALSE)

```

### index creation
```{r}

pah_add_df<- pah_add_wide
colnames(pah_add_df)

# define variables
pah_add_analytes <- names(pah_add_df)[4:12]

# z-score
pah_add_z <- pah_add_df %>%
  mutate(across(all_of(pah_add_analytes), scale, .names = "z_{.col}"))

# reference
ref_site <- "Penn Cove Baseline"
ref_z_pah_add <- pah_add_z %>%
  filter(site_name == ref_site) %>%
  select(starts_with("z_")) %>%
  slice(1)

# deviation
pah_add_ai <- pah_add_z %>%
  mutate(across(
    starts_with("z_"),
    ~ abs(.x - as.numeric(ref_z_pah_add[[cur_column()]])),
    .names = "ai_{.col}"
  ))

# create index
ai_cols <- names(pah_add_ai)[grepl("^ai_", names(pah_add_ai))] # id ai columns
pah_add_index<- pah_add_ai %>%
  rowwise() %>%
  mutate(pah_add_index = sum(c_across(all_of(ai_cols)), na.rm = TRUE)) %>%
  ungroup()

# view & save
print(pah_add_index)
#write.csv(pah_add_ai, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/pah_add_ai.csv", row.names = FALSE)
#write.csv(pah_add_index, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/pah_additional_index.csv", row.names = FALSE)

```

## total pah index creation
```{r}

# read in
pah_df <- read.csv("../data/index_df/combined_pah_index_interim.csv")

# create total pah index
pah_df <- pah_df %>%
  mutate(total_pah_index = pah_lmw_index + pah_hmw_index + pah_add_index)

# view & save
print(pah_df)
#write.csv(pah_df, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/pah_total_index.csv", row.names = FALSE)

```

## pbde
```{r}

pbde_df<- pbde
colnames(pbde_df)

# define variables
pbde_analytes <- names(pbde_df)[4:14]

# z-score
pbde_z <- pbde_df %>%
  mutate(across(all_of(pbde_analytes), scale, .names = "z_{.col}"))

# reference
ref_site <- "Penn Cove Baseline"
ref_z_pbde <- pbde_z %>%
  filter(site_name == ref_site) %>%
  select(starts_with("z_")) %>%
  slice(1)

# deviation
pbde_ai <- pbde_z %>%
  mutate(across(
    starts_with("z_"),
    ~ abs(.x - as.numeric(ref_z_pbde[[cur_column()]])),
    .names = "ai_{.col}"
  ))

# create index
ai_cols <- names(pbde_ai)[grepl("^ai_", names(pbde_ai))] # id ai columns
pbde_index<- pbde_ai %>%
  rowwise() %>%
  mutate(pbde_index = sum(c_across(all_of(ai_cols)), na.rm = TRUE)) %>%
  ungroup()

# view & save
print(pbde_index)
#write.csv(pbde_ai, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/pbde_ai.csv", row.names = FALSE)
#write.csv(pbde_index, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/pbde_index.csv", row.names = FALSE)

```

## pcb
```{r}

pcb_df<- pcb
colnames(pcb_df)

# define variables
pcb_analytes <- names(pcb_df)[4:45]

# z-score
pcb_z <- pcb_df %>%
  mutate(across(all_of(pcb_analytes), scale, .names = "z_{.col}"))

# reference
ref_site <- "Penn Cove Baseline"
ref_z_pcb <- pcb_z %>%
  filter(site_name == ref_site) %>%
  select(starts_with("z_")) %>%
  slice(1)

# deviation
pcb_ai <- pcb_z %>%
  mutate(across(
    starts_with("z_"),
    ~ abs(.x - as.numeric(ref_z_pcb[[cur_column()]])),
    .names = "ai_{.col}"
  ))

# create index
ai_cols <- names(pcb_ai)[grepl("^ai_", names(pcb_ai))] # id ai columns
pcb_index<- pcb_ai %>%
  rowwise() %>%
  mutate(pcb_index = sum(c_across(all_of(ai_cols)), na.rm = TRUE)) %>%
  ungroup()

# view & save
print(pcb_index)
#write.csv(pcb_ai, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/pcb_ai.csv", row.names = FALSE)
#write.csv(pcb_index, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/pcb_index.csv", row.names = FALSE)

```

## pesticide
```{r}

pesticide_wide<- read.csv("../data/index_df/pesticide_wide.csv")

pesticide_df<- pesticide_wide
colnames(pesticide_df)

# define variables
pesticide_analytes <- names(pesticide_df)[4:8]

# z-score
pesticide_z <- pesticide_df %>%
  mutate(across(all_of(pesticide_analytes), scale, .names = "z_{.col}"))

# reference
ref_site <- "Penn Cove Baseline"
ref_z_pesticide <- pesticide_z %>%
  filter(site_name == ref_site) %>%
  select(starts_with("z_")) %>%
  slice(1)

# deviation
pesticide_ai <- pesticide_z %>%
  mutate(across(
    starts_with("z_"),
    ~ abs(.x - as.numeric(ref_z_pesticide[[cur_column()]])),
    .names = "ai_{.col}"
  ))

# create index
ai_cols <- names(pesticide_ai)[grepl("^ai_", names(pesticide_ai))] # id ai columns
pesticide_index<- pesticide_ai %>%
  rowwise() %>%
  mutate(pesticide_index = sum(c_across(all_of(ai_cols)), na.rm = TRUE)) %>%
  ungroup()

# view & save
print(pesticide_index)
#write.csv(pesticide_ai, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/pesticide_ai.csv", row.names = FALSE)
#write.csv(pesticide_index, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/pesticide_index.csv", row.names = FALSE)

```

# Creating Chemical Mixture Indices
# Left off of index creation - may be too much for what we need. Updated 9.26.25
## sum- based, unweighted mixture index
```{r}

colnames(site_data)
# leaving out chlordane, hch and pesticides since they have heavy zeros

# converting metals to match other contaminants - metals are reported in mg/kg and all others are ng/g
# 1 mg/kg = 1,000 ng/g
site_data$heavy_metal_ng <- site_data$heavy_metal * 1000
site_data$nutrient_metal_ng <- site_data$nutrient_metal * 1000

site_data$mixture_index_sum <- rowSums(site_data[, c("ddt", "heavy_metal_ng", "nutrient_metal_ng", "pah_lmw", "pah_hmw", "pah_add", "pbde", "pcb")], na.rm = TRUE)

```

## pca- based, standardized mixture index
```{r}

# leaving out chlordane, hch and pesticides since they have heavy zeros; same as above

# contaminant index matrix
contaminants <- site_data[, c("ddt", "heavy_metal_ng", "nutrient_metal_ng", "pah_lmw", "pah_hmw", "pah_add", "pbde", "pcb")]

# scale with z-score standardization
contaminants_scaled <- scale(contaminants)

# PCA
pca_result <- prcomp(contaminants_scaled, center = TRUE, scale. = TRUE)

# use PC1 scores as the PCA-based mixture index
site_data$mixture_index_pca <- pca_result$x[, 1]

# how much variance is explained by PC1? ~49% of variation
summary(pca_result)$importance[2, 1]  # proportion of variance explained by PC1

#save data for other downstream analyses
#write.csv(site_data, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/site_with_mixture_index.csv", row.names = FALSE)

```

