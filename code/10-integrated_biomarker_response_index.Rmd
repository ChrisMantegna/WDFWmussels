---
title: "10- Creating an IBR Index"
output:
  pdf_document: 
    fig_width: 20
    fig_height: 9
  html_document: 
    toc: true
    toc_float:
        collapsed: false
        smooth_scroll: true
    fig_width: 20
---

# Directory and doc rules

```{r, setup, eval=TRUE, include=TRUE, echo=FALSE}

# libraries
library(knitr) # output
library(tidyr) # data wrangling
library(tidyverse) # data wrangling
library(dplyr) # data wrangling
library(vegan) # ecological stats + permanova
library(cluster) # grouping of metrics
library(pgirmess) # stats - KW
library(ggplot2) # plots
library(factoextra) # pca/ nmds/ tweaking radars
library(FactoMineR) # pca/ nmds/ tweaking radars
library(FSA) # post hoc test - Dunn's Test       
library(rstatix) # VERIFY what this is for      
library(car) # VERIFY what this is for  
library(RVAideMemoire) # post hoc test for permanova
library(rcompanion) # KW testing
library(scales) # scaling data for IBR
library(fmsb) # calculations for the radars

knitr::opts_chunk$set(
  root.dir = here::here(),
  echo = TRUE,         # Display code chunks
  eval = TRUE,         # Evaluate code chunks
  warning = FALSE,     # Hide warnings
  message = FALSE,     # Hide messages
  #fig.width = 15,       # Set plot width in inches
  #fig.height = 9,      # Set plot height in inches
  fig.align = "center" # Align plots to the center
)

```

# Load & Check Data
```{r}

getwd()
#setwd("/Users/cmantegna/Documents/GitHub/WDFWmussels")
# load data
df<- read.csv("../data/all_with_imputation_weights_site_ra.csv")

# check it out
str(df) # checking df structure
summary(df) #checking df contents

```

```{r }

# replace any values below LOQ with imputed LOQ (.5 x LOD), LOD= 0.05
df$sod[df$sod <= 0] <- 0.0025

# check
summary(df)

```

# Creating the Beliaeff and Burgeot IBR Index with biomarkers and morphometrics
### DO NOT RUN Again except for comparison purposes
```{r}

# select and scale biomarkers and raw morphometrics
ibr_vars <- df %>%
  select(p450, sod, weight_change_g, weight_final_g, shell, length_mm, height_mm, width_mm)

ibr_scaled <- scale(ibr_vars) # standardize (Z-score)

ibr_scores <- abs(as.data.frame(ibr_scaled)) # convert to absolute Z-scores (deviation) 

df$IBR <- rowSums(ibr_scores) # calculate IBR Index (sum of absolute scores)

# plot
ibr_box<- ggplot(df, aes(x = site_name, y = IBR)) +
  geom_boxplot() +
  theme_minimal() +
  labs(title = "Integrated Biomarker Response (IBR) by Site",
       y = "IBR Index", x = "Site") +
  theme(axis.text.x= element_text(angle= 45, hjust= 1))

#save and view
ggsave(filename= "/Users/cmantegna/Documents/GitHub/WDFWmussels/output/ibr_box.png", plot= ibr_box, width = 16, height = 14, dpi = 300)

print(ibr_box)

```
# Radar Plots
## Test sample
```{r}

#install.packages("fmsb")
library("fmsb")

# Select and scale
ibr_vars <- df %>%
  select(p450, sod, weight_change_g, weight_final_g, shell, length_mm, height_mm, width_mm, ci1, ci2, ci3)

scaled_df <- scale(ibr_vars)
abs_scores <- abs(as.data.frame(scaled_df))

# Add sample/site identifiers back
abs_scores$site_name <- df$site_name
abs_scores$sample_id <- df$sample_id

# Choose one sample (e.g., row 1)
sample <- abs_scores[1, 1:11]  # only the numeric variables
max_min <- rbind(apply(abs_scores[ ,1:11], 2, max),
                 apply(abs_scores[ ,1:11], 2, min))
radar_data <- rbind(max_min, sample)

radarchart(radar_data,
           axistype = 1,
           pcol = "darkblue", pfcol = rgb(0.2, 0.4, 0.8, 0.4),
           plwd = 2,
           title = paste("IBR Radar Plot for Sample", abs_scores$sample_id[1]))

```

## All individual samples
```{r}

library(fmsb)

# Prepare absolute z-score data
ibr_vars <- df %>%
  select(p450, sod, weight_change_g, weight_final_g, shell, length_mm, height_mm, width_mm, ci1, ci2, ci3)

scaled <- scale(ibr_vars)
abs_scores <- abs(as.data.frame(scaled))

# Add ID columns back
abs_scores$sample_id <- df$sample_id
abs_scores$site_name <- df$site_name

# Loop through each sample and create radar plots
for (i in 1:nrow(abs_scores)) {
  sample_data <- abs_scores[i, 1:11]
  max_min <- rbind(apply(abs_scores[ ,1:11], 2, max),
                   apply(abs_scores[ ,1:11], 2, min))
  radar_data <- rbind(max_min, sample_data)
  
  # Save to file
  png(paste0("radar_sample_", abs_scores$sample_id[i], ".png"), width = 600, height = 600)
  radarchart(radar_data,
             axistype = 1,
             pcol = "darkblue", pfcol = rgb(0.2, 0.8, 0.4, 0.4),
             plwd = 2,
             title = paste("Sample", abs_scores$sample_id[i], "\nSite:", abs_scores$site_name[i]))
  dev.off()
}

```

## Site plots
```{r}

# Calculate site-level mean absolute Z-scores
site_means <- abs_scores %>%
  group_by(site_name) %>%
  summarise(across(1:11, mean, na.rm = TRUE))

# Loop through each site
for (i in 1:nrow(site_means)) {
  site_data <- site_means[i, 2:12]  # skip site_name column
  max_min <- rbind(apply(site_means[ ,2:12], 2, max),
                   apply(site_means[ ,2:12], 2, min))
  radar_data <- rbind(max_min, site_data)
  
  # Save to file
  png(paste0("radar_site_", gsub(" ", "_", site_means$site_name[i]), ".png"), width = 600, height = 600)
  radarchart(radar_data,
             axistype = 1,
             pcol = "darkblue", pfcol = rgb(0.2, 0.4, 0.9, 0.4),
             plwd = 2,
             title = paste("Mean IBR Profile\nSite:", site_means$site_name[i]))
  dev.off()
}

```

# Creating IBRv2i Index with biomarkers and raw morphometrics (no condition indices)
## prepare df for the function to create the ibr scores
```{r}

# make categorical columns factors
df$site_number <- as.factor(df$site_number)
df$sample_id <- as.factor(df$sample_id)
df$reporting_area <- as.factor(df$reporting_area)

```

```{r}

# define variables
biomarkers<- c("p450", "sod")
morphometrics<- c("shell", "weight_initial_g", "weight_change_g", "weight_final_g", "length_mm", "height_mm", "width_mm")

# define the reference groups
# penn cove= site 3, using in index 1 and 2
# hc holly = site 29, using in index 2 and 3
# broad spit = site 30, using in index 2 and 3
#ref_df <- df %>% filter(site_number %in% c(3, 29, 30))


#### Penn Cover only reference site
ref_df <- df %>% filter(site_number == 3)
ref_vars <- ref_df %>%
  select(p450, sod, shell, weight_initial_g, weight_change_g, weight_final_g, length_mm, height_mm, width_mm)

# get reference means & SDs
ref_bio_means <- colMeans(ref_df[, biomarkers], na.rm = TRUE)
ref_bio_sds   <- apply(ref_df[, biomarkers], 2, sd, na.rm = TRUE)

ref_morph_means <- colMeans(ref_df[, morphometrics], na.rm = TRUE)
ref_morph_sds   <- apply(ref_df[, morphometrics], 2, sd, na.rm = TRUE)

# z-scores relative to reference site (preserving sign)
bio_z <- sweep(df[, biomarkers], 2, ref_bio_means, "-")
bio_z <- sweep(bio_z, 2, ref_bio_sds, "/")

morph_z <- sweep(df[, morphometrics], 2, ref_morph_means, "-")
morph_z <- sweep(morph_z, 2, ref_morph_sds, "/")

# combine into final df with signed values
ibr_df <- df %>%
  select(latitude, longitude, sample_id,site_number, site_name, reporting_area) %>%
  bind_cols(bio_z, morph_z) %>%
  mutate(
    ibr1_biomarkers = rowMeans(bio_z, na.rm = TRUE),
    ibr1_morphometrics = rowMeans(morph_z, na.rm = TRUE),
    ibr1_overall = rowMeans(cbind(ibr1_biomarkers, ibr1_morphometrics), na.rm = TRUE))


#### All three reference sites
ref_df <- df %>% filter(site_number %in% c(3, 29, 30))
ref_vars <- ref_df %>%
  select(p450, sod, shell, weight_initial_g, weight_change_g, weight_final_g, length_mm, height_mm, width_mm)

# get reference means & SDs
ref_bio_means <- colMeans(ref_df[, biomarkers], na.rm = TRUE)
ref_bio_sds   <- apply(ref_df[, biomarkers], 2, sd, na.rm = TRUE)

ref_morph_means <- colMeans(ref_df[, morphometrics], na.rm = TRUE)
ref_morph_sds   <- apply(ref_df[, morphometrics], 2, sd, na.rm = TRUE)

# z-scores relative to reference site (preserving sign)
bio_z <- sweep(df[, biomarkers], 2, ref_bio_means, "-")
bio_z <- sweep(bio_z, 2, ref_bio_sds, "/")

morph_z <- sweep(df[, morphometrics], 2, ref_morph_means, "-")
morph_z <- sweep(morph_z, 2, ref_morph_sds, "/")

# combine into final df with signed values
ibr_df <- bind_cols(ibr_df, bio_z, morph_z)
ibr_df <- ibr_df %>%
 mutate(
    ibr3_biomarkers = rowMeans(bio_z, na.rm = TRUE),
    ibr3_morphometrics = rowMeans(morph_z, na.rm = TRUE),
    ibr3_overall = rowMeans(cbind(ibr3_biomarkers, ibr3_morphometrics), na.rm = TRUE))

#### HC reference sites only
ref_df <- df %>% filter(site_number %in% c(29, 30))
ref_vars <- ref_df %>%
  select(p450, sod, shell, weight_initial_g, weight_change_g, weight_final_g, length_mm, height_mm, width_mm)

# get reference means & SDs
ref_bio_means <- colMeans(ref_df[, biomarkers], na.rm = TRUE)
ref_bio_sds   <- apply(ref_df[, biomarkers], 2, sd, na.rm = TRUE)

ref_morph_means <- colMeans(ref_df[, morphometrics], na.rm = TRUE)
ref_morph_sds   <- apply(ref_df[, morphometrics], 2, sd, na.rm = TRUE)

# z-scores relative to reference site (preserving sign)
bio_z <- sweep(df[, biomarkers], 2, ref_bio_means, "-")
bio_z <- sweep(bio_z, 2, ref_bio_sds, "/")

morph_z <- sweep(df[, morphometrics], 2, ref_morph_means, "-")
morph_z <- sweep(morph_z, 2, ref_morph_sds, "/")

# combine into final df with signed values
ibr_df <- bind_cols(ibr_df, bio_z, morph_z)
ibr_df <- ibr_df %>%
 mutate(
    ibr2_biomarkers = rowMeans(bio_z, na.rm = TRUE),
    ibr2_morphometrics = rowMeans(morph_z, na.rm = TRUE),
    ibr2_overall = rowMeans(cbind(ibr2_biomarkers, ibr2_morphometrics), na.rm = TRUE))


```

```{r}

# ID reference site/samples
ref_df <- df %>% filter(site_number == 3)
ref_vars <- ref_df %>%
  select(p450, sod, ci1, ci2, ci3, weight_initial_g, weight_change_g, weight_final_g, shell, length_mm, height_mm, width_mm)

# Calculate reference means and SDs
ref_means <- colMeans(ref_vars, na.rm = TRUE)
ref_sds <- apply(ref_vars, 2, sd, na.rm = TRUE)

# Z-score relative to reference site
z_scores <- sweep(ibr_vars, 2, ref_means, FUN = "-")
z_scores <- sweep(z_scores, 2, ref_sds, FUN = "/")
z_scores <- as.data.frame(z_scores)

# Add back identifying columns
z_scores <- bind_cols(
  df %>% select(latitude, longitude, site_number, site_name, sample_id, reporting_area),
  z_scores
)

# IBRv2i = mean of reference-based Z-scores (preserving sign)
z_scores$IBRv2i <- rowMeans(z_scores %>% select(p450:width_mm, -ci1, -ci2, -ci3), na.rm = TRUE)

# Optional: also store in the original df
df$IBRv2i <- z_scores$IBRv2i


#plot
ibrv2i_box<- ggplot(df, aes(x = site_name, y = IBRv2i)) +
  geom_boxplot() +
  theme_minimal() +
  labs(title = "IBRv2i by Site", y = "IBRv2i Index", x = "Site") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# plot with Penn Cove indicated
df$highlight <- ifelse(df$site_name == "Penn Cove Reference", "Penn Cove Reference", "Other")

ibrv2i_box2 <- ggplot(df, aes(x = site_name, y = IBRv2i, fill = highlight)) +
  geom_boxplot() +
  scale_fill_manual(values = c("Penn Cove Reference" = "red", "Other" = "white")) +
  theme_minimal() +
  labs(title = "IBRv2i by Site", y = "IBRv2i Index", x = "Site") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = "none")  # hides legend if not needed


# save and view
#ggsave(filename= "/Users/cmantegna/Documents/GitHub/WDFWmussels/output/ibrv2i_box_reference_indicated.png", plot= ibrv2i_box2, width = 16, height = 14, dpi = 300)

print(ibrv2i_box)
print(ibrv2i_box2)


```


# Plotting - Only moving forward with IBRv2i indices
## All Sites, Do Not Run
```{r}

z_scores$sample_id <- df$sample_id
z_scores$site_name <- df$site_name

# Site-averaged Z-scores
site_means <- z_scores %>%
  group_by(site_name) %>%
  summarise(across(1:8, mean, na.rm = TRUE))

# Loop through sites
for (i in 1:nrow(site_means)) {
  site_data <- site_means[i, 2:9]
  max_min <- rbind(apply(site_means[ ,2:9], 2, max),
                   apply(site_means[ ,2:9], 2, min))
  radar_data <- rbind(max_min, site_data)

  png(paste0("IBRv2i_radar_site_", gsub(" ", "_", site_means$site_name[i]), ".png"), width = 600, height = 600)
  radarchart(radar_data,
             axistype = 1,
             pcol = "darkblue", pfcol = rgb(0.2, 0.4, 0.9, 0.4),
             plwd = 2,
             title = paste("IBRv2i Radar Plot\nSite:", site_means$site_name[i]))
  dev.off()
}

```

## All Samples,Only run if spot checking
```{r}

library(fmsb)

# Loop through each sample
for (i in 1:nrow(z_scores)) {
  
  # Extract sample data
  sample_data <- z_scores[i, 1:8]
  
  # Get axis limits (min/max across all samples)
  max_min <- rbind(apply(z_scores[, 1:8], 2, max, na.rm = TRUE),
                   apply(z_scores[, 1:8], 2, min, na.rm = TRUE))
  
  # Combine for radar input
  radar_data <- rbind(max_min, sample_data)
  
  # Set output file name (in current directory)
  filename <- paste0("radar_sample_", z_scores$sample_id[i], ".png")
  
  # Save plot
  png(filename, width = 600, height = 600)
  radarchart(radar_data,
             axistype = 1,
             pcol = "darkblue", pfcol = rgb(0.8, 0.2, 0.2, 0.4),
             plwd = 2,
             title = paste("IBRv2i Radar Plot\nSample:", z_scores$sample_id[i],
                           "\nSite:", z_scores$site_name[i]))
  dev.off()
}


```

## All sites w/ reference site overlay
```{r}

# Variables to include in radar plots
vars_to_use <- c("p450", "sod", "weight_initial_g", "weight_change_g", 
                 "weight_final_g", "shell", "length_mm", "height_mm", "width_mm")

# Step 1: Create the reference profile from Penn Cove samples (e.g., sample_id 41:44)
reference_profile <- z_scores %>%
  filter(sample_id %in% 41:44) %>%
  select(all_of(vars_to_use)) %>%
  summarise(across(everything(), mean, na.rm = TRUE))

# Step 2: Create site-level means for the same variables
site_means <- z_scores %>%
  group_by(site_name) %>%
  summarise(across(all_of(vars_to_use), mean, na.rm = TRUE)) %>%
  ungroup()

# Step 3: Define radar axis limits (same across all sites)
max_vals <- apply(site_means[, vars_to_use], 2, max, na.rm = TRUE)
min_vals <- apply(site_means[, vars_to_use], 2, min, na.rm = TRUE)

# Convert reference profile to a named numeric vector
ref_vec <- unlist(reference_profile[1, ], use.names = TRUE)

# Step 4: Loop through each site to create radar plots
for (i in 1:nrow(site_means)) {
  site <- site_means[i, ]
  site_profile <- unlist(site[, vars_to_use], use.names = TRUE)
  
  # Skip if site profile matches reference exactly
  if (isTRUE(all.equal(site_profile, ref_vec))) next
  
  # Combine into radar data
  radar_data <- as.data.frame(rbind(max_vals, min_vals, ref_vec, site_profile))
  rownames(radar_data) <- c("Max", "Min", "Reference", as.character(site$site_name))
  
  # Save radar plot
  filename <- paste0("radar_site_with_ref_", gsub(" ", "_", site$site_name), ".png")
  png(filename, width = 600, height = 600)
  
  radarchart(radar_data,
             axistype = 1,
             pcol = c("gray40", "steelblue"),
             pfcol = c(rgb(0.4, 0.4, 0.4, 0.3), rgb(0.2, 0.5, 0.8, 0.4)),
             plwd = 2,
             plty = 1,
             title = paste("IBRv2i Radar Plot with Reference\nSite:", site$site_name))
  
  legend("topright", legend = c("Penn Cove Reference", site$site_name),
         col = c("gray40", "steelblue"), lty = 1, lwd = 2, bty = "n")
  
  dev.off()
}


```

## Sites by Reporting Areas w/ Reference
```{r}

# Define variables to include (excluding condition indices)
vars_to_use <- c("p450", "sod", "weight_initial_g", "weight_change_g", 
                 "weight_final_g", "shell", "length_mm", "height_mm", "width_mm")

# Prep: site-level means and reporting area info
site_means <- z_scores %>%
  group_by(site_name, reporting_area) %>%
  summarise(across(all_of(vars_to_use), mean, na.rm = TRUE), .groups = "drop")

# Global min/max across all sites
global_max <- apply(site_means[, vars_to_use], 2, max, na.rm = TRUE)
global_min <- apply(site_means[, vars_to_use], 2, min, na.rm = TRUE)

# Reference profile from Penn Cove samples
reference_profile <- z_scores %>%
  filter(sample_id %in% 41:44) %>%
  summarise(across(all_of(vars_to_use), mean, na.rm = TRUE), .groups = "drop") %>%
  unlist(use.names = TRUE)

# Unique reporting areas
reporting_areas <- unique(site_means$reporting_area)

# Loop over each reporting area
for (area in reporting_areas) {
  area_sites <- site_means %>% filter(reporting_area == area)
  n_sites <- nrow(area_sites)
  n_pages <- ceiling(n_sites / 6)

  for (page in 1:n_pages) {
    # Subset to group of up to 6 sites
    start_i <- (page - 1) * 6 + 1
    end_i <- min(start_i + 5, n_sites)
    sites_subset <- area_sites[start_i:end_i, ]

    # Set output
    filename <- paste0("radar_group_", gsub(" ", "_", area), "_page_", page, ".png")
    png(filename, width = 1200, height = 800)
    par(mfrow = c(2, 3), mar = c(2, 2, 4, 2), oma = c(0, 0, 4, 0))  # 2x3 layout

    for (i in 1:nrow(sites_subset)) {
      site_data <- unlist(sites_subset[i, vars_to_use], use.names = TRUE)
      
      # Assemble radar data as data frame
      chart_data <- as.data.frame(rbind(global_max, global_min, reference_profile, site_data))
      rownames(chart_data) <- c("Max", "Min", "Reference", as.character(sites_subset$site_name[i]))

      radarchart(chart_data,
                 axistype = 1,
                 pcol = c("gray40", "steelblue"),
                 pfcol = c(rgb(0.4, 0.4, 0.4, 0.3), rgb(0.2, 0.5, 0.8, 0.4)),
                 plwd = 2,
                 plty = 1,
                 cglcol = "grey80",
                 title = sites_subset$site_name[i])
    }

    # Add group label at the top
    mtext(paste("Reporting Area:", area), side = 3, line = 1, outer = TRUE, cex = 1.5)
    dev.off()
  }
}

```


# Separate the IBRs into biomarker, morphometric and overall
```{r}

# Define variable groups
biomarkers <- c("p450", "sod")
morphometrics <- c("weight_initial_g", "weight_change_g", "weight_final_g",
                   "shell", "length_mm", "height_mm", "width_mm")

# Filter reference site data (Penn Cove)
ref_df <- df %>% filter(site_name == "Penn Cove Reference")

# Get reference means & SDs
ref_bio_means <- colMeans(ref_df[, biomarkers], na.rm = TRUE)
ref_bio_sds   <- apply(ref_df[, biomarkers], 2, sd, na.rm = TRUE)

ref_morph_means <- colMeans(ref_df[, morphometrics], na.rm = TRUE)
ref_morph_sds   <- apply(ref_df[, morphometrics], 2, sd, na.rm = TRUE)

# Z-scores relative to reference site (preserving sign)
bio_z <- sweep(df[, biomarkers], 2, ref_bio_means, "-")
bio_z <- sweep(bio_z, 2, ref_bio_sds, "/")

morph_z <- sweep(df[, morphometrics], 2, ref_morph_means, "-")
morph_z <- sweep(morph_z, 2, ref_morph_sds, "/")

# Combine into final df with signed values
ibrv2i_df <- df %>%
  select(latitude, longitude, sample_id,site_number, site_name, reporting_area) %>%
  bind_cols(bio_z, morph_z) %>%
  mutate(
    IBRv2i_biomarkers = rowMeans(bio_z, na.rm = TRUE),
    IBRv2i_morphometrics = rowMeans(morph_z, na.rm = TRUE),
    IBRv2i_overall = rowMeans(cbind(IBRv2i_biomarkers, IBRv2i_morphometrics), na.rm = TRUE)
  )

```

## Plotting Separate Indices per Site, box plot
```{r}

# Pivot only the IBRv2i index columns
ibr_long <- ibrv2i_df %>%
  pivot_longer(cols = c(IBRv2i_biomarkers, IBRv2i_morphometrics, IBRv2i_overall),
               names_to = "index_type",
               values_to = "index_value") %>%
  mutate(index_type = case_when(
    index_type == "IBRv2i_biomarkers" ~ "Biomarkers",
    index_type == "IBRv2i_morphometrics" ~ "Morphometrics",
    index_type == "IBRv2i_overall" ~ "Overall",
    TRUE ~ index_type  # fallback in case of unexpected names
  ))


all_index<- ggplot(ibr_long, aes(x = site_name, y = index_value,
                     color = site_name == "Penn Cove Reference")) +
  geom_jitter(width = 0.2, alpha = 0.7) +
  geom_boxplot(outlier.shape = NA, alpha = 0.2) +
  facet_wrap(~ index_type, ncol = 1, scales = "free_y") +
  scale_color_manual(values = c("FALSE" = "black", "TRUE" = "red")) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),legend.position = "none") +
  labs(title = "IBRv2i Indices by Site",
       x = "Site", y = "IBRv2i Value")

# save and view
#ggsave(filename= "/Users/cmantegna/Documents/GitHub/WDFWmussels/output/ibrv2i_box_all_index_reference_indicated.png", plot= all_index, width = 16, height = 14, dpi = 300)

print(all_index)

```

# DF prep for statistical analyses

## Add condition indices back
```{r}

# pull out the scaled ci's from the z_score df
ci_scaled <- z_scores %>%
  select(sample_id, ci1, ci2, ci3)

# add them to both the ibrv2i_df and ibr_long
ibrv2i_df <- ibrv2i_df %>%
  left_join(ci_scaled, by = "sample_id")

ibr_long <- ibr_long %>%
  left_join(ci_scaled, by = "sample_id")

ibrv2i_df <- ibrv2i_df %>%
  select(-ci1, -ci3)

ibr_long <- ibr_long %>%
  select(-ci1, -ci3)


# save both df's for future work
write.csv(ibrv2i_df, "/Users/cmantegna/Documents/GitHub/WDFWmussels/data/cleaned/cleaned_ibrv2i_with_all.csv", row.names = FALSE)

write.csv(ibr_long, "/Users/cmantegna/Documents/GitHub/WDFWmussels/data/cleaned/cleaned_ibr_long_with_all.csv", row.names = FALSE)

```

## Double check normality, all remain non- parametric except shell thickness which was always parametric
```{r}

shapiro.test(ibrv2i_df$IBRv2i_biomarkers) # Not Normal
shapiro.test(ibrv2i_df$IBRv2i_morphometrics) # Not Normal
shapiro.test(ibrv2i_df$IBRv2i_overall) # Not Normal
shapiro.test(ibrv2i_df$p450) # Not Normal
shapiro.test(ibrv2i_df$sod) # Not Normal
shapiro.test(ibrv2i_df$shell) # Normal
shapiro.test(ibrv2i_df$ci1) # Not Normal
shapiro.test(ibrv2i_df$ci2) # Not Normal
shapiro.test(ibrv2i_df$ci3) # Not Normal

# checking the condition indices since they are throwing off the downstream process
summary(ibrv2i_df)
```

## Remove Port Angeles from the analyses since the condition indices are completely screwing up the analysis
```{r}

ibrv2i_df <- ibrv2i_df %>%
  filter(site_number != 1)

ibr_long <- ibr_long %>%
  filter(site_number != 1)

summary(ibrv2i_df)

# that didn't seem to clear up my ci1 and ci3 issue - i will move forward with this analysis and just not use them. I removed them in lines 549 - 574.

```

## Create biomarker- driven grouping
```{r}

# Use only rows with non-missing biomarker data
bio_clust_df <- ibrv2i_df %>%
  select(sample_id, p450, sod)

wss <- vector()

# Try values of k from 1 to 10
for (k in 1:10) {
  set.seed(42)
  wss[k] <- kmeans(bio_clust_df, centers = k, nstart = 25)$tot.withinss
}

# Plot the elbow
plot(1:10, wss, type = "b",
     pch = 19, frame = FALSE,
     xlab = "Number of clusters (k)",
     ylab = "Total within-cluster sum of squares",
     main = "Elbow Method for Choosing k")

set.seed(42)
k_opt <- 4  # elbow is distinctly at 2 with 3 close by, I have checked both with no real resolution

kmeans_result <- kmeans(bio_clust_df, centers = k_opt, nstart = 25)

# Add cluster assignment to your working df
bio_clust_df$bio_cluster4 <- as.factor(kmeans_result$cluster)

ibrv2i_df <- ibrv2i_df %>%
  left_join(bio_clust_df[, c("sample_id", "bio_cluster4")], by = "sample_id")

# saving ibrv2i df
#write.csv(ibrv2i_df, "/Users/cmantegna/Documents/GitHub/WDFWmussels/data/cleaned/ibrv2i_all_scaled_indices_groups.csv", row.names = FALSE)

```

## PCA plot to check clusters
```{r}

# Define variables for PCA
pca_vars <- c("p450", "sod", "shell", "ci2")

# Remove rows with any NA in the selected variables
pca_df <- ibrv2i_df %>%
  filter(if_all(all_of(pca_vars), ~ !is.na(.))) %>%
  select(sample_id, bio_cluster4, all_of(pca_vars))

# Keep only the scaled numeric matrix for PCA
pca_matrix <- pca_df %>%
  select(all_of(pca_vars)) %>%
  as.matrix()

pca_res <- prcomp(pca_matrix, center = TRUE, scale. = FALSE)  # already scaled relative to reference

# Create a scores dataframe
scores_df <- as.data.frame(pca_res$x)
scores_df$sample_id <- pca_df$sample_id
scores_df$bio_cluster4 <- pca_df$bio_cluster4

# Plot the first two PCs
ggplot(scores_df, aes(x = PC1, y = PC2, color = bio_cluster4)) +
  geom_point(size = 3, alpha = 0.8) +
  labs(title = "PCA of Scaled Biomarkers + Morphometrics",
       x = paste0("PC1 (", round(summary(pca_res)$importance[2, 1] * 100, 1), "% variance)"),
       y = paste0("PC2 (", round(summary(pca_res)$importance[2, 2] * 100, 1), "% variance)"),
       color = "Cluster") +
  theme_minimal() +
  theme(legend.position = "right")


```

## KW + Dunn Post Hoc, all but shell thickness as it is parametric
```{r}

library(dplyr)
library(FSA)

# Variables to test
variables <- c("p450", "sod", "shell", "ci2")

# Optional: store all significant Dunn's results in a list
all_dunn_results <- list()

for (var in variables) {
  cat("\n\n\n========================================\n")
  cat("### Testing:", var, "\n")
  cat("========================================\n")
  
  # Subset and clean data
  df <- ibrv2i_df %>%
    select(all_of(c(var, "site_name", "reporting_area"))) %>%
    filter(!is.na(.data[[var]]))
  
  y <- df[[var]]

  ## --- Kruskal-Wallis by site_name ---
  cat("\n--- Kruskal-Wallis for", var, "by site_name ---\n")
  kw_site <- kruskal.test(y ~ site_name, data = df)
  print(kw_site)

  ## --- Dunn's post hoc by site_name ---
  if (kw_site$p.value < 0.05) {
    cat("\n>>> Dunn's Test (BH-adjusted) for", var, "by site_name <<<\n")
    dunn_site <- dunnTest(y ~ site_name, data = df, method = "bh")
    sig_site <- dunn_site$res %>% filter(P.adj < 0.05)
    print(sig_site)

    # Store if needed
    all_dunn_results[[paste0(var, "_site")]] <- sig_site
  } else {
    cat("No significant differences by site_name (KW p >= 0.05)\n")
  }

  ## --- Kruskal-Wallis by reporting_area ---
  cat("\n--- Kruskal-Wallis for", var, "by reporting_area ---\n")
  kw_area <- kruskal.test(y ~ reporting_area, data = df)
  print(kw_area)

  ## --- Dunn's post hoc by reporting_area ---
  if (kw_area$p.value < 0.05) {
    cat("\n>>> Dunn's Test (BH-adjusted) for", var, "by reporting_area <<<\n")
    dunn_area <- dunnTest(y ~ reporting_area, data = df, method = "bh")
    sig_area <- dunn_area$res %>% filter(P.adj < 0.05)
    print(sig_area)

    # Store if needed
    all_dunn_results[[paste0(var, "_reporting")]] <- sig_area
  } else {
    cat("No significant differences by reporting_area (KW p >= 0.05)\n")
  }
}

# Save each significant Dunn's test result to file
for (name in names(all_dunn_results)) {
  write.csv(all_dunn_results[[name]], file = paste0("dunn_results_", name, ".csv"), row.names = FALSE)
}


```

## ANOVA for shell
```{r}

library(emmeans)
library(multcomp)
library(multcompView)

# Prepare cleaned dataframe
df <- ibrv2i_df %>%
  select(shell, site_name, reporting_area) %>%
  filter(!is.na(shell))

# Create a list to store results
tukey_group_letters <- list()

# ---------- ANOVA by site_name ----------
cat("=== ANOVA: shell ~ site_name ===\n")
aov_site <- aov(shell ~ site_name, data = df)
summary_site <- summary(aov_site)
print(summary_site)

# Extract p-value safely
p_site <- summary_site[[1]][["Pr(>F)"]][1]

if (!is.na(p_site) && p_site < 0.05) {
  cat("\n>>> Tukey's HSD (site_name) <<<\n")
  tukey_site <- TukeyHSD(aov_site)
  print(tukey_site$site_name)

  # Get group letters
  em_site <- emmeans(aov_site, pairwise ~ site_name)
  cld_site <- multcomp::cld(em_site$emmeans, Letters = letters, sort = FALSE)

  # Clean table
  cld_site_out <- cld_site %>%
    select(site_name, emmean, SE, df, lower.CL, upper.CL, .group) %>%
    rename(group = .group)

  print(cld_site_out)

  # Store in list
  tukey_group_letters$site_name <- cld_site_out
} else {
  cat("No significant differences among sites.\n")
}


# ---------- ANOVA by reporting_area ----------
cat("\n\n=== ANOVA: shell ~ reporting_area ===\n")
aov_area <- aov(shell ~ reporting_area, data = df)
summary_area <- summary(aov_area)
print(summary_area)

# Extract p-value safely
p_area <- summary_area[[1]][["Pr(>F)"]][1]

if (!is.na(p_area) && p_area < 0.05) {
  cat("\n>>> Tukey's HSD (reporting_area) <<<\n")
  tukey_area <- TukeyHSD(aov_area)
  print(tukey_area$reporting_area)

  # Get group letters
  em_area <- emmeans(aov_area, pairwise ~ reporting_area)
  cld_area <- multcomp::cld(em_area$emmeans, Letters = letters, sort = FALSE)

  # Clean table
  cld_area_out <- cld_area %>%
    select(reporting_area, emmean, SE, df, lower.CL, upper.CL, .group) %>%
    rename(group = .group)

  print(cld_area_out)

  # Store in list
  tukey_group_letters$reporting_area <- cld_area_out
} else {
  cat("No significant differences among reporting areas.\n")
}

write.csv(tukey_group_letters$site_name, "/Users/cmantegna/Documents/GitHub/WDFWmussels/output/tukey_shell_site_name.csv", row.names = FALSE)
write.csv(tukey_group_letters$reporting_area, "/Users/cmantegna/Documents/GitHub/WDFWmussels/output/tukey_shell_reporting_area.csv", row.names = FALSE)



```



# Run PCAs/ NMDSs/ Permanova/ Correlations + Heatmaps/ Kendall's Tau
# Visualization
## NWS Poster viz
```{r}

#map
library(sf)
library(readr)
library(patchwork)
library(viridis)
library(rnaturalearth)
library(ggsignif)

df$reporting_area <- as.factor(df$reporting_area)

# Convert to spatial
sites_sf <- st_as_sf(df, coords = c("longitude", "latitude"), crs = 4326)

coast <- ne_states(country = "united states of america", returnclass = "sf") %>%
  filter(name == "Washington")

# Major city coordinates for labels
cities <- data.frame(
  city = c("Seattle", "Tacoma", "Olympia", "Bellingham", "Port Angeles", "Hama Hama"),
  lon = c(-122.33, -122.45, -122.90, -122.48, -123.43, -123.16),
  lat = c(47.61, 47.25, 47.00, 48.73, 48.08, 47.63)
)

# Define color palette
area_colors <- viridis::viridis(length(levels(df$reporting_area)), option = "turbo")

# Map
map_plot <- ggplot() +
  geom_sf(data = coast, fill = "gray90", color = "white") +
  geom_sf(data = sites_sf, aes(color = reporting_area), size = 3, alpha = 0.9) +
  geom_text(data = cities, aes(x = lon, y = lat, label = city),
            color = "black", fontface = "bold", size = 4) +
  scale_color_manual(values = area_colors, name = "Reporting Area") + 
  coord_sf(xlim = c(-124, -121), ylim = c(46.5, 49.0)) +
  theme_void() +
  labs(title = "Sampled Sites by Reporting Area")

# Filter data for IBRv2i < 5
df_filtered <- df %>% filter(IBRv2i < 5)
df_filtered <- df_filtered %>%
  mutate(is_reference = ifelse(site_name == "Penn Cove Reference", "Reference", "Other"))

# Boxplot
box_plot <- ggplot(df_filtered, aes(x = reporting_area, y = IBRv2i, fill = reporting_area)) +
  geom_boxplot(alpha = 0.8, outlier.shape = NA) +
  geom_jitter(width = 0.2, color = "black", size = 1.5) +
  scale_fill_manual(values = area_colors, guide = "none") + 
  coord_cartesian(ylim = c(-3, 5.5)) +
  geom_signif(comparisons = list(
      c("11", "7"),
      c("13", "7"),
      c("6", "7"),
      c("10", "13")
    ),
    annotations = c("p = 0.0093", "p = 0.0013", "p = 0.0487", "p = 0.0199"),
    y_position = c(5.2, 4.8, 4.5, 4.2),
    tip_length = 0.02,
    textsize = 4.5
  ) +
  theme_minimal(base_size = 13) + 
  theme(
    axis.line = element_line(size = 1.2, color = "black"),
    axis.text = element_text(size= 25, face = "bold"),
    axis.title = element_text(size= 30, face = "bold"),
    plot.title = element_text(hjust = 0.5, face = "bold")
  ) +
  labs(x = "Reporting Area", y = "IBRv2i Score")
  
# Combine
combo_plot <- map_plot + box_plot +
  plot_layout(ncol = 2, widths = c(1.3, 1)) +
  plot_annotation(title = "Integrated Biomarker Response Overview")

# Display
print(map_plot)
print(box_plot)

# Export 
ggsave("/Users/cmantegna/Documents/GitHub/WDFWmussels/output/poster_map.png", map_plot, width = 14, height = 8, dpi = 300)

ggsave("/Users/cmantegna/Documents/GitHub/WDFWmussels/output/poster_box.png", box_plot, width = 14, height = 8, dpi = 300)


```
## KW for plotting
```{r}

# Make sure reporting_area is a factor
df$reporting_area <- as.factor(df$reporting_area)

# Run Kruskal-Wallis test
kruskal_result <- kruskal.test(IBRv2i ~ reporting_area, data = df)
print(kruskal_result)

# Run Dunn's post hoc test
dunn_result <- dunnTest(IBRv2i ~ reporting_area, data = df, method = "holm")
print(dunn_result)


```



PCA/ NMDS
Correlation heatmaps
```{r}

```

