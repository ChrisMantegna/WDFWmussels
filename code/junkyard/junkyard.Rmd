# Extra stuff that I used to check







#plot analytes by sites
```{r}
library(ggplot2)
library(gridExtra)

p450<- ggplot(allr, aes(x = site_name, y = p450)) +
  geom_point(color = "blue") +  # Scatter plot with blue color
  labs(x = "Sites", y = "p450 Values", title = "p450 Values by Site") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

SumPAHsHMW<- ggplot(allr, aes(x = site_name, y = SumPAHsHMW)) +
  geom_point(color = "red") +  # Scatter plot with blue color
  labs(x = "Sites", y = "Analyte Values", title = "SumPAHsHMW Values by Site") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

# Arrange the plots side by side
combined_plots <- grid.arrange(p450, SumPAHsHMW, ncol = 2,
                               widths = c(8, 8)) 
```
```{r}
SumPAHsHMW<- ggplot(allr, aes(x = site_name, y = SumPAHsHMW)) +
  geom_point(color = "red") +  # Scatter plot with blue color
  labs(x = "Sites", y = "Analyte Values", title = "SumPAHsHMW Values by Site") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

# Arrange the plots side by side
combined_plots <- grid.arrange(p450, SumPAHsHMW, ncol = 2,
                               widths = c(8, 8)) 
```

```{r}
acenaphthene<- ggplot(allr, aes(x = site_name, y = acenaphthene)) +
  geom_point(color = "red") +  # Scatter plot with blue color
  labs(x = "Sites", y = "Analyte Values", title = "acenaphthene Values by Site") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

# Arrange the plots side by side
combined_plots <- grid.arrange(p450, acenaphthene, ncol = 2,
                               widths=c(8,8))
```


```{r}
anthracene<- ggplot(allr, aes(x = site_name, y = anthracene)) +
  geom_point(color = "red") +  # Scatter plot with blue color
  labs(x = "Sites", y = "Analyte Values", title = "anthracene Values by Site") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

# Arrange the plots side by side
combined_plots <- grid.arrange(p450, anthracene, ncol = 2,
                               widths = c(8, 8)) 
```

```{r}
# Load the ggplot2 package
library(ggplot2)

# Assuming your data frame is named 'allr'
Biomarker <- allr[[4]]  # Biomarker column

# Loop through columns 4 to 54
for (i in 9:54) {
    # Create a temporary data frame for plotting
    temp_data <- data.frame(Biomarker = p450, Value = allr[[i]])

    # Generate the plot
    p <- ggplot(temp_data, aes(x = Value, y = Biomarker)) +
        geom_point() +  # Add points
        geom_smooth(method = "lm", se = FALSE) +  # Add a linear regression line without standard error
        labs(title = paste("Biomarker vs", colnames(allr)[i]),
             x = "Biomarker",
             y = colnames(allr)[i])

    # Print the plot
    print(p)
}

```

```{r}
# Load the ggplot2 package
library(ggplot2)
getwd()
plot_directory<- "/Users/cmantegna/Documents/WDFWmussels/output/individual_plots/"


Sites <- allr[[1]]  # Site name column

# Loop through columns 5 to 58 (or whatever your range is)
for (i in 5:58) {
    # Create a temporary data frame for plotting
    temp_data <- data.frame(Sites = Sites, Value = allr[[i]])

    # Generate the plot
    s <- ggplot(temp_data, aes(x = Sites, y = Value)) +
        geom_point() +  
        geom_smooth(method = "lm", se = FALSE) +  # Add a linear regression line without standard error
        labs(title = paste("Site vs", colnames(allr)[i]),
             x = "Site Name",
             y = colnames(allr)[i])+
      theme(axis.text.x = element_text(angle = 90, hjust = 1))

    # Print the plot
    print(s)
}

# Define the file name
    #file_name <- paste0("/Site_vs_", colnames(allr)[i], ".png")

#ggsave(file_name, plot= s, width=10, height=6)

```

# 0's and negative number management

SOD values that are negative are changed to 0 signifying that the value was undetectable.\
p450 values that are 0 are missing, not actual 0's.


# this code isn't correct for alldata - need to fix
# Detect outliers and plot them - code a combo of stack overflow and chat gpt.

```{r}

detect_outliers_mad <- function(alldata, accuracy = 0.99) {
  # Calculate z-score equivalent for the given accuracy
  z_threshold <- qnorm(accuracy + (1 - accuracy) / 2)

  # Initialize a list to store outlier indices for each numeric column
  outliers_list <- list()

  # Initialize a vector to keep track of rows with outliers
  rows_with_outliers <- rep(FALSE, nrow(alldata))

  # Loop through each column in the dataframe
  for (col_name in names(data)) {
    # Check if the column is numeric
    if (is.numeric(data[[col_name]])) {
      # Calculate MAD and median for the column
      mad_value <- median(abs(data[[col_name]] - median(data[[col_name]])))
      median_value <- median(data[[col_name]])

      # Calculate the deviation scores (using a modified z-score formula)
      deviation_scores <- 0.6745 * (data[[col_name]] - median_value) / mad_value

      # Identify indices of outliers
      outlier_indices <- which(abs(deviation_scores) > z_threshold)

      # Store the indices in the list
      outliers_list[[col_name]] <- outlier_indices

      # Update rows with outliers
      rows_with_outliers[outlier_indices] <- TRUE
    }
  }

  # Return the list of outliers and rows with outliers
  list(outliers_list = outliers_list, rows_with_outliers = rows_with_outliers)
}

outliers_info <- detect_outliers_mad(alldata)

# Convert the list of outliers to a named vector of counts
num_outliers_each_col <- sapply(outliers_info$outliers_list, length)
num_rows_with_outliers <- sum(outliers_info$rows_with_outliers)

# Check if there are any outliers
if (all(num_outliers_each_col == 0)) {
  print("There are no outliers in any columns.")
} else {
  # Create a data frame for plotting
  outliers_data_df <- data.frame(
    Column = names(num_outliers_each_col),
    Outliers = as.integer(num_outliers_each_col),
    OutlierPercentage = (as.integer(num_outliers_each_col) / nrow(data)) * 100
  )

  # Plot the number of outliers for all columns
  outlier_plot <- ggplot(outliers_data_df, aes(x = Column, y = Outliers, fill = Column)) +
    geom_bar(stat = "identity") +
    geom_text(aes(label = sprintf("%.2f%%", OutlierPercentage)), position = position_dodge(width = 0.9), vjust = -0.25) +
    coord_flip() +
    labs(title = "Number of Outliers by Column", x = "Column", y = "Number of Outliers") +
    scale_fill_brewer(palette = "Set3") +
    theme_minimal()

  print(outlier_plot)
}

#ggsave(plot= outlier_plot, filename="/Users/cmantegna/Documents/WDFWmussels/output/outliers.png", width=15, height=8)

```

# Plotting both biomarkers in a box plot

```{r}

all<-plot<- ggplot(alldata) +
  geom_point(aes(x = site_name, y = SOD, color = "SOD")) +
  geom_point(aes(x = site_name, y = p450, color = "P450")) +
  labs(x = "Site Name", y = "Value", color = "Biomarker") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))


print(all)
ggsave(plot=all, filename="/Users/cmantegna/Documents/WDFWmussels/output/allBoxPlot.png", width=15, height=8)

```

# Plotting both biomarkers in a box plot with a free y-axis to fix the sod v p450 values. The SOD values all look the same and are all at 0.

Note that the color for SOD shifts from teal to salmon between the two plots.

```{r}
# First, create a basic ggplot object with SOD data
freey <- ggplot(data, aes(x = site_name)) +
  geom_point(aes(y = SOD, color = "SOD")) +
  labs(x = "Site Name", y = "SOD Value") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

# Then, add p450 using sec.axis
freey + geom_point(aes(y = p450/100, color = "p450")) + # Example scaling factor, adjust as needed
  scale_y_continuous(sec.axis = sec_axis(~.*100, name = "p450 Value")) # Reverse the scaling for the secondary axis label

print(freey)
#ggsave(plot=freey, filename="/Users/cmantegna/Documents/WDFWmussels/output/allBoxPlotFreeY.png", width=15, height=8)
```

# Plotting both biomarkers in their own box plots with a facet wrap to try to show the difference in values for both biomarkers since SOD looks the same.

```{r}

# Reshape data from wide to long format
long_data <- pivot_longer(data, cols = c(SOD, p450), names_to = "Biomarker", values_to = "Value")

# Plotting with faceting
facetp <- ggplot(long_data, aes(x = site_name, y = Value, color = Biomarker)) +
  geom_point() +
  facet_wrap(~Biomarker, scales = "free_y") + # This allows each biomarker to have its own y-axis scale
  labs(x = "Site Name", y = "Value", color = "Biomarker") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

print(facetp)
# Save the plot
ggsave(plot=facetp, filename="/Users/cmantegna/Documents/WDFWmussels/output/allBoxPlotFacet.png", width=15, height=8)

```

# Plotting separate box plots to investigate the facet, the other options still show the sod values the 'same' when everything is plotted together.

```{r}

# Ensure your data is in the correct format.
# Reshape your dataframe if it hasn't been done correctly.
long_data <- pivot_longer(data, cols = c(SOD, p450), names_to = "Biomarker", values_to = "Value")

# Faceted plot with separate scales.
plotf<- ggplot(long_data, aes(x = site_name, y = Value)) +
  geom_point(aes(color = Biomarker)) +
  facet_wrap(~ Biomarker, scales = "free_y") +
  labs(x = "Site Name", y = "Value", color = "Biomarker") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

print(plotf)
ggsave(plot=plotf, filename="/Users/cmantegna/Documents/WDFWmussels/output/allBoxPlotFacetPanels.png", width=40, height=25)

```

# Plotting p450 values ranked from smallest to largest

```{r}

# Order the sites by p450 value
data_ordered <- data[order(data$p450),]

# Create a factor with the ordered site names
data_ordered$site_name <- factor(data_ordered$site_name, levels = unique(data_ordered$site_name))

# Plot the SOD values in a boxplot with ordered site names
rankp<- ggplot(data_ordered, aes(x = site_name, y = p450)) +
  geom_boxplot() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) # Rotate x labels if needed

print(rankp)
ggsave(plot=rankp, filename="/Users/cmantegna/Documents/WDFWmussels/output/p450ranked.png", width=15, height=8)
```

# Plotting SOD values ranked from samllest largest

```{r}

# Order the sites by p450 value
data_ordered <- data[order(data$SOD),]

# Create a factor with the ordered site names
data_ordered$site_name <- factor(data_ordered$site_name, levels = unique(data_ordered$site_name))

# Plot the SOD values in a boxplot with ordered site names
ranks<- ggplot(data_ordered, aes(x = site_name, y = SOD)) +
  geom_boxplot() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) # Rotate x labels if needed

print(ranks)
ggsave(plot=ranks, filename="/Users/cmantegna/Documents/WDFWmussels/output/SODranked.png", width=15, height=8)
```

# histogram with density curve
```{r}
#basic histogram + basic density plot
#hist(data$p450)
#plot(density(data$p450), main="Density Plot", xlab="p450 Value")

#ggplot histogram with density curve
library(scales) # Make sure this package is loaded for label_number()

phist<- ggplot(alldata, aes(x = p450)) +
  geom_histogram(aes(y = after_stat(density)), binwidth = diff(range(data$p450))/30, colour = "black", fill = "white") +
  geom_density(alpha = .2, fill = "#FF6666") +
  labs(x = "P450 Values", y = "Density", title = "Histogram of P450 Values with Density Curve") +
  theme_minimal() +
  scale_x_continuous(labels = label_number()) # This line adjusts the x-axis labels

print(phist)
#ggsave(plot=phist, filename="/Users/cmantegna/Documents/WDFWmussels/output/p450histogram.png", width=15, height=8)

```

## renaming the individual analytes so that entering data into the anova isn't difficult

```{r}
# Generate the first 26 letters of the alphabet
letters_seq <- letters[1:26]

# Generate additional letters if needed
extra_letters_seq <- character(0)
num_cols <- length(22:57)  # Number of columns you want to rename
if (num_cols > length(letters_seq)) {
  repeats_needed <- num_cols - length(letters_seq)
  # Generate double letters like 'aa', 'bb', 'cc', etc.
  extra_letters_seq <- rep(letters[1:repeats_needed], each=1)
  extra_letters_seq <- sapply(extra_letters_seq, function(x) paste0(x, x))
}

# Combine the original and additional sequences
new_colnames <- c(letters_seq, extra_letters_seq)[1:num_cols]


```

```{r}
# Assuming 'alldata' is your dataframe
colnames(alldata)[22:57] <- new_colnames

# View the updated column names to confirm
print(colnames(alldata))

```

# Mapping both biomarkers
```{r}

# Assuming washington_map is your sf object for Washington State
ggplot(data = washington_map) + 
  geom_sf(fill = "lightgrey", color = "white") +
  geom_point(data = data, aes(x = longitude, y = latitude, color = p450, size = SOD), alpha = 0.6) +
  scale_color_viridis(name = "p450", option = "D") +
  scale_size_continuous(name = "SOD", range = c(2, 6)) +
  theme_minimal() +
  labs(title = "Washington State: p450 and SOD")

```

# Mapping with shapes to differenciate the biomarkers - change dataframe to accomodate
```{r}

long_data <- pivot_longer(data, cols = c(SOD, p450), names_to = "type", values_to = "value")

```

# plotting SOD by sites
```{r}
# data adjust to plot the 95%
# remove SOD outside of .0025 and 51.58 & p450 outside of 291641 and 5271798
data$SOD[data$SOD <= .0030] <- NA
data$SOD[data$SOD > 51.53] <- NA

data$SOD[data$p450 <= 291641] <- NA
data$SOD[data$p450 >= 5271798] <- NA

# Plot the SOD values in a boxplot with ordered site names
SODboxplot<- ggplot(data, aes(x = site_name, y = SOD)) +
  geom_boxplot() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) # Rotate x labels if needed

print(SODboxplot)
```

# plotting corrected p450
```{r}
# data adjust to plot the 95%
# remove SOD outside of .0025 and 51.58 & p450 outside of 291641 and 5271798


data$p450[data$p450 < 291641] <- NA
data$p450[data$p450 > 5271800] <- NA

# Plot the SOD values in a boxplot with ordered site names
p450boxplot<- ggplot(data, aes(x = site_name, y = p450)) +
  geom_boxplot() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) # Rotate x labels if needed

print(p450boxplot)
```

# fix data to the 95%
```{r}
#fix data set to use the 95%
alldata$SOD[alldata$SOD <= .0030] <- .0030
alldata$SOD[alldata$SOD > 51.53] <- 51.53

alldata$p450[alldata$p450 < 291641] <- 291641
alldata$p450[alldata$p450 > 5271800] <- 5271800

alldata$condition_factor[is.na(alldata$condition_factor)] <- 0.001
alldata$avg_thickness[is.na(alldata$avg_thickness)] <- 0.001


```




# anova for p450
```{r}

#anova
model1 <- lm(p450 ~ SumBDEs + SumDDTs + SumPAHs16 + SumPAHsHMW + SumPCBs2x17 + Zinc, data = alldata)

#summary(model)
p450anova1<- anova(model1)
print(p450anova1)

model2<- lm(p450~ Zinc + cadmium + copper + lead + mercuryTotal, data = alldata)
p450anova2<- anova(model2)
print(p450anova2)

# Save 
#write.csv(p450anova, "/Users/cmantegna/Documents/WDFWmussels/output/p450anova.csv")

```
#anova for p450 and SOD, condition factor, avg_thickness
```{r}

model <- lm(p450 ~ site_number + SOD + condition_factor + avg_thickness, data = alldata)

#summary(model)
cfanova<- anova(model)
print(cfanova)

# Save 
#write.csv(p450analyteanova, "/Users/cmantegna/Documents/WDFWmussels/output/p450analyteanova.csv")

```
#anova for SOD and p450, condition factor, avg_thickness
```{r}

model <- lm(SOD ~ site_number + p450 + condition_factor + avg_thickness, data = alldata)

thickanova<- anova(model)
print(thickanova)
```
# Kruskal- Wallis Test
```{r}
kruskal.test(p450 ~ SOD, data = alldata)

```

# anova for SOD
```{r}
#fix data set to use the 95%
alldata$SOD[alldata$SOD <= .0030] <- .0030
alldata$SOD[alldata$SOD > 51.53] <- 51.53

alldata$p450[alldata$p450 < 291641] <- 291641
alldata$p450[alldata$p450 > 5271800] <- 5271800

#anova

model <- lm(SOD ~ SumBDEs + SumDDTs + SumPAHs16 + SumPAHsHMW + SumPCBs2x17, data = alldata)

#summary(model)
print(SODanova)
SODanova<- anova(model)

# Save 
write.csv(SODanova, "/Users/cmantegna/Documents/WDFWmussels/output/SODanova.csv")

```
# trying to fix column names so i can run an anova on the individual analytes against the biomarkers.
```{r}

#rename columns with characters in them
colnames(all_pah_df)[colnames(all_pah_df) == "benz[a]anthracene" ] <- "benzaanthracene"
colnames(all_pah_df)[colnames(all_pah_df) == "benzo[a]pyrene" ] <- "benzoapyrene"
colnames(all_pah_df)[colnames(all_pah_df) == "benzo[b]fluoranthene" ] <- "benzobfluoranthene"
colnames(all_pah_df)[colnames(all_pah_df) == "benzo[e]pyrene" ] <- "benzoepyrene"
colnames(all_pah_df)[colnames(all_pah_df) == "benzo[ghi]perylene" ] <- "benzoghiperylene"
colnames(all_pah_df)[colnames(all_pah_df) == "benzo[k]fluoranthene" ] <- "benzokfluoranthene"
colnames(all_pah_df)[colnames(all_pah_df) == "dibenz[a,h]anthracene" ] <- "dibenzahanthracene"
colnames(all_pah_df)[colnames(all_pah_df) == "indeno[1,2,3-cd]pyrene" ] <- "indeno123cdpyrene"
colnames(all_pah_df)[colnames(all_pah_df) == "C1-benzanthracene/schrysenes" ] <- "C1benzanthraceneschrysenes"
colnames(all_pah_df)[colnames(all_pah_df) == "C1-dibenzothiophenes" ] <- "C1dibenzothiophenes"
colnames(all_pah_df)[colnames(all_pah_df) == "C1-fluoranthenes/pyrenes" ] <- "C1fluoranthenespyrenes"
colnames(all_pah_df)[colnames(all_pah_df) == "C1-fluorenes" ] <- "C1fluorenes"
colnames(all_pah_df)[colnames(all_pah_df) == "C1-naphthalenes" ] <- "C1naphthalenes"
colnames(all_pah_df)[colnames(all_pah_df) == "C1-phenanthrenes/anthracenes" ] <- "C1phenanthrenesanthracenes"
colnames(all_pah_df)[colnames(all_pah_df) == "C2-benzanthracenes/chrysenes" ] <- "C2benzanthraceneschrysenes"
colnames(all_pah_df)[colnames(all_pah_df) == "C2-dibenzothiophenes" ] <- "C2dibenzothiophenes"
colnames(all_pah_df)[colnames(all_pah_df) == "C2-fluoranthenes/pyrenes" ] <- "C2fluoranthenespyrenes"
colnames(all_pah_df)[colnames(all_pah_df) == "C2-fluorenes" ] <- "C2fluorenes"
colnames(all_pah_df)[colnames(all_pah_df) == "C2-naphthalenes" ] <- "C2naphthalenes"
colnames(all_pah_df)[colnames(all_pah_df) == "C2-phenanthrenes/anthracenes" ] <- "C2phenanthrenesanthracenes"
colnames(all_pah_df)[colnames(all_pah_df) == "C3-benzanthracenes/chrysenes" ] <- "C3benzanthraceneschrysenes"
colnames(all_pah_df)[colnames(all_pah_df) == "C3-dibenzothiophenes" ] <- "C3dibenzothiophenes"
colnames(all_pah_df)[colnames(all_pah_df) == "C3-fluoranthenes/pyrenes" ] <- "C3fluoranthenespyrenes"
colnames(all_pah_df)[colnames(all_pah_df) == "C3-fluorenes" ] <- "C3fluorenes"
colnames(all_pah_df)[colnames(all_pah_df) == "C3-naphthalenes" ] <- "C3naphthalenes"
colnames(all_pah_df)[colnames(all_pah_df) == "C3-phenanthrenes/anthracenes" ] <- "C3phenanthrenesanthracenes"
colnames(all_pah_df)[colnames(all_pah_df) == "C4-benzanthracenes/chrysenes" ] <- "C4benzanthraceneschrysenes"
colnames(all_pah_df)[colnames(all_pah_df) == "C4-dibenzothiophenes" ] <- "C4dibenzothiophenes"
colnames(all_pah_df)[colnames(all_pah_df) == "C4-fluoranthenes/pyrenes" ] <- "C4fluoranthenespyrenes"
colnames(all_pah_df)[colnames(all_pah_df) == "C4-naphthalenes" ] <- "C4naphthalenes"
colnames(all_pah_df)[colnames(all_pah_df) == "C4-phenanthrenes/anthracenes" ] <- "C4phenanthrenesanthracenes" 

```



```{r}

ggplot(data = washington_map) + 
  geom_sf(fill = "lightgrey", color = "white") +
  geom_point(data = long_data, aes(x = longitude, y = latitude, color = value, shape = type), alpha = 0.6, size = 2) +
  scale_color_viridis(name = "value", option = "C") +
  scale_shape_manual(values = c("SOD" = 16, "p450" = 17)) + # 16: dot, 17: triangle
  theme_minimal() +
  labs(title = "Washington State: SOD & p450")

```

# Mapping with Leaflet instead of ggplot; this is interactive and not helpful
```{r}

if(!require(leaflet)) install.packages("leaflet")
library(leaflet)

leaflet(data) %>% addTiles() %>%
  addCircles(lng = ~longitude, lat = ~latitude, color = ~colorBin(c("red", "yellow", "green"), p450, bins = 3), radius = 500) %>%
  addCircles(lng = ~longitude, lat = ~latitude, color = ~colorBin(c("blue", "white", "black"), SOD, bins = 3), radius = 200)

```

# Mapping with Plotly, also interactive and plotted on a grid that I don't understand
```{r}
if(!require(plotly)) install.packages("plotly")
library(plotly)

# Assuming data is your dataframe with lat, lon, p450, and SOD columns
fig <- plot_ly() %>%
  add_trace(data = data, x = ~longitude, y = ~latitude, type = 'scatter', mode = 'markers',
            marker = list(size = 10, color = ~p450, colorscale = 'Viridis', showscale = TRUE)) %>%
  add_trace(data = data, x = ~longitude, y = ~latitude, type = 'scatter', mode = 'markers',
            marker = list(size = 10, color = ~SOD, colorscale = 'Cividis', showscale = TRUE))

fig

```

## PPM model, 2 of 2

### Interpretation- I need to dig further to see what this means, I am following a GIS/ Geospatial tutorial and wanted to be able to make the process work.

```{r}

# Fit a point process model
ppm_model <- ppm(sites_pp ~ p450)
summary(ppm_model)


#option 2
#sites_pp$marks <- as.factor(cut(sites_pp$marks$p450, breaks = quantile(sites_pp$marks$p450, probs = 0:3/3), include.lowest = TRUE))

# Now run the ppm model
#ppm_model <- ppm(sites_pp ~ marks, covariates = NULL)
#print(summary(ppm_model))

```

# Spatial Autocorrelation Analysis

```{r}
#Load packages & prep dataframe for "sf" package
#install.packages(spdep)
#install.packages("/Users/cmantegna/Downloads/spdep_1.2-8.tar.gz", repos = NULL, type = "source")
library(sf)
library(sp)
library(spdep)

sf_data <- st_as_sf(bdata, coords = c("longitude", "latitude"), crs = 4326)

# Take a look at your sf object
print(sf_data)

```

```{r}

# Create a spatial weights matrix to assess nearest neighbors and distance-based neighbors to define spatial relationships using Moran's I and Geary's C.
# You can extract the matrix of coordinates using st_coordinates
coords <- st_coordinates(sf_data)

# Now use the knearneigh function from the spdep package directly on the coordinates
neighbors <- knn2nb(knearneigh(coords, k = 4))

# Then convert the neighbors into spatial weights with nb2listw
weights <- nb2listw(neighbors, style = "W")

```

#### Moran I and Geary's C statistical analyses tests if we can cluster or not- cluster sites based on the if the distribution of biomarker values is random or non-random. This helps clarify any biomarker patterns that are unclear by visual analysis - at least to me. If it's unclear to me, I assume it will be unclear to those with less familiarity of the data.

## Run Moran's I and Geary's C for p450

```{r}

coords <- st_coordinates(sf_data)

# Now use the knearneigh function from the spdep package directly on the coordinates
neighbors <- knn2nb(knearneigh(coords, k = 4))

# Then convert the neighbors into spatial weights with nb2listw
weights <- nb2listw(neighbors, style = "W")

geary_result <- geary.test(sf_data$p450, weights)
print(geary_result)

```

## Run Moran's I and Geary's C for SOD

```{r}

moran_result <- moran.test(sf_data$SOD, weights)
print(moran_result)

geary_result <- geary.test(sf_data$SOD, weights)
print(geary_result)

```

# Spatial Regression Analysis

```{r}
#library(spdep)
#install.packages("sphet")
library(sphet)

```

## Spatial Lag Model
```{r}
library(spatialreg)
#accounts for spatial dependence in the dependent variable
slm_model <- lagsarlm(p450 ~ SOD, data = sf_data, listw = weights)
print(summary(slm_model))

```
## Spatial Error Model
```{r}
#accounts for the spatial autocorrelation in the error term
sem_model <- errorsarlm(p450 ~ SOD, data = sf_data, listw = weights)
print(summary(sem_model))


```
## Spatial Durbin Model
```{r}
#install.packages("spatialreg")
library(spatialreg)

#combines SLM and SEM
sdm_model <- spatialreg::lagsarlm(p450 ~ SOD, data = sf_data, listw = weights, type="mixed")
print(summary(sdm_model))

```
# Local Indicator of Spatial Association (LISA)
```{r}
#install.packages("spdep")
#install.packages("sf")  # for spatial data handling
#install.packages("tmap")  # for visualization
library(spdep)
library(sf)
library(tmap)

```

```{r}

lisa_values <- localmoran(sf_data$p450, weights)

```

```{r}

# Add LISA values and p-values to your spatial data
sf_data$lisa <- lisa_values[,1]  # Local Moran's I values
sf_data$p.value <- lisa_values[,4]  # p-values for significance

# Use tmap for plotting
library(tmap)

# Define breaks for significance levels, e.g., 0.05 for 95% confidence
sig_breaks <- c(0, 0.05, 1)  # Change according to your significance level

# Create a map
tm_shape(sf_data) +
  tm_dots(col = "lisa", size = 0.5, palette = "-RdBu", title = "LISA Values") +
  tm_layout(legend.position = c("left", "top")) +
  tm_shape(sf_data[sf_data$p.value <= 0.05, ]) +  # Add a layer for significant points only
  tm_dots(col = "red", size = 0.7, title = "Significant Clusters") +
  tm_layout(main.title = "LISA Cluster Map", main.title.position = "center")

```

# Plot the LISA data over the map from the base Washington State map found in file: 03-map.rmd
```{r}
library(sf)
library(viridis)
library(rnaturalearth)
library(rnaturalearthdata)
library(ggplot2)

```

```{r}

world <- ne_states(country = "united states of america", returnclass = "sf")
washington_map <- world[world$name == "Washington", ]

pmap <- ggplot() + 
  geom_sf(data = washington_map, fill = "lightgrey", color = "white") +
  theme_minimal() +
  labs(title = "Washington State Map")

print(pmap)

```


```{r}
# Ensure CRS compatibility
sf_data <- st_transform(sf_data, st_crs(washington_map))

# Prepare the base map
pmap <- ggplot() + 
  geom_sf(data = washington_map, fill = "lightgrey", color = "white") +
  theme_minimal() +
  labs(title = "Washington State Map")

# Add the LISA points layer to the map
complete_map <- pmap + 
  geom_sf(data = sf_data, aes(color = lisa), size = 2) +
  scale_color_viridis_c(option = "D", direction = -1, name = "LISA Values")

# Display the combined map
print(complete_map)

```

```{r}
#zoom in on the puget sound region
# Assuming you know the bounding box coordinates you want to zoom in on
# For example: xmin, xmax, ymin, ymax
xlim <- c(-124, -122)  # longitude bounds
ylim <- c(47, 49)  # latitude bounds

complete_map <- pmap + 
  geom_sf(data = sf_data, aes(color = lisa), size = 2) +
  scale_color_viridis_c(option = "D", direction = -1, name = "LISA Values") +
  coord_sf(xlim = xlim, ylim = ylim, expand = FALSE)

print(complete_map)


```

# Next steps are completing the interpretations and then using this same code path to review the PAH analytes

# Point pattern analysis

#### Exploratory data analysis tool that looks to interpret the distribution of my values across geographic space - this is the first step in geospatial analysis, the Moran and Geary C statistical tests are what follow to support or debate the hypothesis formed from this step.

```{r}
#install.packages("spatstat")
library(spatstat)

#pull out lat, long, site_name, and biomarkers as a dataframe for the following work.

select <- c("latitude", "longitude", "site_name", "p450", "SOD", "condition_factor", "avg_thickness")

# Create a new data frame with only the specified columns
bdata <- data[,select]

# Create the kind of data frame that works in spatstat package
sites_pp <- ppp(x = bdata$longitude, y = bdata$latitude, 
                window = owin(xrange = range(bdata$longitude), 
                              yrange = range(bdata$latitude)))

```

```{r}
#Add biomarker layer to the geographical data
sites_pp$marks <- data.frame(p450 = bdata$p450, 
                             SOD = bdata$SOD)

```

### Two different ways to analyze any spatial clustering

## K test, 1 of 2

### Interpretation- the clustering of the black, red, and green lines (isotropic, and two transformations) lie significanlty above the blue line, the Poisson distribution line. This means that the biomarker data is more clustered than random. The proximity of the black, red and green lines show agreement across the isotropic and transformation analyses.

```{r}

K_result <- Kest(sites_pp)
print(plot(K_result))

```

# shapiro- wilkes test for normality
```{r}
#shapiro.test(apdata$sumPAH)
#shapiro.test(apdata$lmwPAH)
#shapiro.test(apdata$hmwPAH)
#shapiro.test(apdata$PAH16)
#shapiro.test(apdata$sumPCB)
#shapiro.test(apdata$mercury)
#shapiro.test(apdata$arsenic)
#shapiro.test(apdata$cadmium)
#shapiro.test(apdata$copper)
#shapiro.test(apdata$lead)
#shapiro.test(apdata$zinc)
```

# permanova + 2 post hoc methods
```{r}

library(RVAideMemoire)

# PERMANOVA + Dispersion + Post Hoc
dist_matrix_p450 <- vegdist(data_clean_p450$p450, method = "euclidean") # create matrix

permanova_p450_ra <- adonis(dist_matrix_p450 ~ reporting_area, data = data_clean_p450, permutations = 999) # run permanova
print(permanova_p450_ra) # results; p= 0.001

dispersion_p450_ra <- betadisper(dist_matrix_p450, data_clean_p450$reporting_area)
permutest_p450_ra <- permutest(dispersion_p450_ra) # dispersion, p> .05; results are valid
print(permutest_p450_ra)

pairwise_p450_ra <- pairwise.perm.manova(dist_matrix_p450, data_clean_p450$reporting_area, nperm = 999, p.method = "bonferroni")

pairwise_results <- as.data.frame(pairwise_p450_ra$p.value) # convert df
significant_p450_ra <- pairwise_results[pairwise_results$p.value < 0.05, ] #sig only
print(significant_p450_ra) # results - no significant result
```

### Alternative Post Hoc Testing - Don't Run
```{r}

# since we don't know which metric(s) are driving the significance (acting as if we didn't run the post hoc already), we have two choices: 1- run individual PERMANOVAs & post hoc tests, or 2- check which metric is the influence. We're going with option 2 since the code is simple and there are 2 ways to do it to support confirmation. This is extra and 

library(vegan)

# run nmds (extra step to convert the distance matrix - from above- and prep to run a NMDS later with just plot code)
ordination <- metaMDS(dist_matrix, k = 2, trymax = 100)

# fit to ordination to find out influence and significance
envfit_results <- envfit(ordination ~ site_name, data = data, permutations = 999) # r^2 value tells us which metric is influential, p-value gives us significance

# view
print(envfit_results) # r^2= 0.4091, p-value= 0.001 

# contribution to significance (confirmation of the above step since the fit is statistically significant but poor)
simper_results <- simper(metric_matrix, data$site_name, permutations = 999) # each metric will have a percentage contribution to the significance

# view
summary(simper_results)

# OUTCOME: significant results are as follows: avg_thickness and to a lesser significance, sod are driving the result. Both are inconsistent and a posthoc clarifies that none of the significant returns are valid.

```

## Samples minus Outliers by Site
### Running PERMANOVA
```{r}

# we're going to run the same steps without the outliers and see if there is a difference in result. Since each metric has a different number of outliers, we will create a new matrix for each and run a loop for the PERMANOVA

library(vegan)

metric <- c("p450", "sod", "condition_factor", "avg_thickness") # make a metric of our dependent variables

permanova_results <- list() # list for permanova results
pairwise_results <- list() # list for post hoc results
significant_results <- list() # list for any significant results

# loop to remove outliers for each metric, run permanova and post hoc, and reporting of any significant results
for (marker in metric) {
  
  outlier_col <- paste0(marker, "_outlier")  # identify the outlier columns 
  data_filtered <- data[data[[outlier_col]] == FALSE, ] # remove outliers for each biomarker
  biomarker_values <- as.matrix(data_filtered[[marker]]) # make the metric data numeric - just in case anything changed in the manipulations
  dist_matrix <- vegdist(biomarker_values, method = "euclidean") # create distance matrix 
  
  permanova_model <- adonis2(dist_matrix ~ site_name, data = data_filtered, permutations = 999) # run PERMANOVA
  permanova_results[[marker]] <- permanova_model  # store results in list

  pairwise_model <- pairwise.perm.manova(dist_matrix, data_filtered$site_name, nperm = 999, p.method = "bonferroni") # run post hoc 
  pairwise_results[[marker]] <- pairwise_df # store results in list
  
  pairwise_df <- as.data.frame(pairwise_model$p.value) # Extract the results table correctly from `pairwise.htest` object
  colnames(pairwise_df) <- c("p.value")  # Ensure column name is consistent
  
  significant_results[[marker]] <- pairwise_df[pairwise_df$p.value < 0.05, , drop = FALSE]  # filter for significant results only
 
  cat("\n### PERMANOVA results for", marker, "###\n")
  print(permanova_results[[marker]]) # view permanova results

  if (nrow(significant_results[[marker]]) > 0) {
    cat("\n### Significant pairwise post hoc results for", marker, " (p < 0.05) ###\n")
    print(significant_results[[marker]])
  } else {
    cat("\n### No significant pairwise differences for", marker, "###\n")  # view significant post hoc results
  }
}

# PERMANOVA Results using "bray" distance matrix: P450 p= 0.001, SOD p= 0.002, Condition_Factor p= 0.014, Shell Thickness p= 0.001

# OUTCOME: No significant pairwise differences through post hoc confirmation

```

#something about joing df in tidyverse
```{r}

# Assign the lowest group number for each site
df <- df %>%
  group_by(SiteName) %>%
  summarise(pcb_groupA = min(as.numeric(DryValue_Group))) %>%
  ungroup()

df <- df %>%
  rename(site_name = SiteName)

# Check results
print(df)

# Merge while keeping only matching site names
data <- left_join(data, df, by = "site_name")

# Check if each site in data now has a single assigned group
table(data$pcb_groupA)  # Ensure no duplicates within a site

# Check the first few rows
head(data)

```

# PERMANOVA & Post Hoc (using all metrics in a matrix)
## Site (n=74)
### No significant results, p= 0.083
```{r}

# we can proceed with the PERMANOVA based on the analysis of variance above. Let's check if Site has a statistically significant relationship with our metrics. Instead of creating a distance matrix for each individual metric, I am going to create one that housing all metrics of interest (biomarkers & morphometrics). This is not an ideal process with many metrics, but 4 metrics makes an easy test case for the process.

#install.packages("RVAideMemoire") # only need to install once

library(vegan)
library(RVAideMemoire)

dist_matrix_full <- vegdist(as.matrix(data[, c("p450", "sod", "ci_wet_volume", "ci_wet_shell_weight", "ci_pollution", "shell_thickness")]), na.rm= TRUE, method = "euclidean") # create distance matrix

permanova_full <- adonis2(dist_matrix_full ~ site_name, data = data, permutations = 999) # run PERMANOVA

pairwise_results <- list() # list to store post hoc result
significant_results <- list() # list to store only significant post hoc results

pairwise_model <- pairwise.perm.manova(dist_matrix_full, data$site_name, nperm = 999, p.method = "bonferroni") # run post hoc 

pairwise_df <- as.data.frame(pairwise_model$p.value) # Extract the results table correctly from `pairwise.htest` object
colnames(pairwise_df) <- c("p.value")  # Ensure column name is consistent

pairwise_results[["Site"]] <- pairwise_df # Store full results

significant_results[["Site"]] <- pairwise_df[pairwise_df$p.value < 0.05, , drop = FALSE] # filter significant results

cat("\n### PERMANOVA results for All Sites ###\n")
print(permanova_full) # view permanova results

if (nrow(significant_results[["Site"]]) > 0) {
  cat("\n### Significant pairwise post hoc results (p < 0.05) ###\n")
  print(significant_results[["Site"]])
} else {
  cat("\n### No significant pairwise differences found in All Sites ###\n") # view significant post hoc results
}

# write out significant results
#write.csv(significant_results[["Full Data"]], "significant_pairwise_results_full_data.csv", row.names = FALSE)

```

## Reporting Area (n=9)
### No significant results, p= 0.32
```{r}

library(vegan)
library(RVAideMemoire)

# don't need to recreate the matrix, we will use the same matrix created in the first step
#dist_matrix_full <- vegdist(as.matrix(data[, c("p450", "sod", "ci_wet_volume", "ci_wet_shell_weight", "ci_pollution", "shell_thickness")]), na.rm= TRUE, method = "euclidean") # create distance matrix

data$reporting_area <- as.factor(data$reporting_area) # make a factor for analysis

permanova_full <- adonis2(dist_matrix_full ~ reporting_area, data = data, permutations = 999) # run PERMANOVA

pairwise_results <- list() # list to store post hoc result
significant_results <- list() # list to store only significant post hoc results

pairwise_model <- pairwise.perm.manova(dist_matrix_full, data$reporting_area, nperm = 999, p.method = "bonferroni") # run post hoc 

pairwise_df <- as.data.frame(pairwise_model$p.value) # Extract the results table correctly from `pairwise.htest` object
colnames(pairwise_df) <- c("p.value")  # Ensure column name is consistent

pairwise_results[["Reporting Area"]] <- pairwise_df # Store full results

significant_results[["Reporting Area"]] <- pairwise_df[pairwise_df$p.value < 0.05, , drop = FALSE] # filter significant results

cat("\n### PERMANOVA results for All Reporting Areas ###\n")
print(permanova_full) # view permanova results

if (nrow(significant_results[["Reporting Area"]]) > 0) {
  cat("\n### Significant pairwise post hoc results (p < 0.05) ###\n")
  print(significant_results[["Reporting Area"]])
} else {
  cat("\n### No significant pairwise differences found in All Reporting Areas ###\n") # view significant post hoc results
}

# write out significant results
#write.csv(significant_results[["Full Data"]], "significant_pairwise_results_full_data.csv", row.names = FALSE)

```

## PCB Groups (n=8)
### No significant results, p= 0.656
```{r}

library(vegan)
library(RVAideMemoire)

# don't need to recreate the matrix, we will use the same matrix created in the first step
#dist_matrix_full <- vegdist(as.matrix(data[, c("p450", "sod", "ci_wet_volume", "ci_wet_shell_weight", "ci_pollution", "shell_thickness")]), na.rm= TRUE, method = "euclidean") # create distance matrix

data<- read.csv("../data/cleaned/cleaned_with_pcb_groups.csv")
data$pcb_group <- as.factor(data$pcb_group) # make a factor for analysis

permanova_full <- adonis2(dist_matrix_full ~ pcb_group, data = data, permutations = 999) # run PERMANOVA

pairwise_results <- list() # list to store post hoc result
significant_results <- list() # list to store only significant post hoc results

pairwise_model <- pairwise.perm.manova(dist_matrix_full, data$pcb_group, nperm = 999, p.method = "bonferroni") # run post hoc 

pairwise_df <- as.data.frame(pairwise_model$p.value) # Extract the results table correctly from `pairwise.htest` object
colnames(pairwise_df) <- c("p.value")  # Ensure column name is consistent

pairwise_results[["pcb_group"]] <- pairwise_df # Store full results

significant_results[["pcb_group"]] <- pairwise_df[pairwise_df$p.value < 0.05, , drop = FALSE] # filter significant results

cat("\n### PERMANOVA results for All pcb_groups ###\n")
print(permanova_full) # view permanova results

if (nrow(significant_results[["pcb_group"]]) > 0) {
  cat("\n### Significant pairwise post hoc results (p < 0.05) ###\n")
  print(significant_results[["pcb_group"]])
} else {
  cat("\n### No significant pairwise differences found in All pcb_groups ###\n") # view significant post hoc results
}

# write out significant results
#write.csv(significant_results[["Full Data"]], "significant_pairwise_results_full_data.csv", row.names = FALSE)

```

## PAH Group (n=8)
### No significant results, p= 0.854
```{r}

library(vegan)
library(RVAideMemoire)

# don't need to recreate the matrix, we will use the same matrix created in the first step
#dist_matrix_full <- vegdist(as.matrix(data[, c("p450", "sod", "ci_wet_volume", "ci_wet_shell_weight", "ci_pollution", "shell_thickness")]), na.rm= TRUE, method = "euclidean") # create distance matrix

data$pah_group <- as.factor(data$pah_group) # make a factor for analysis

permanova_full <- adonis2(dist_matrix_full ~ pah_group, data = data, permutations = 999) # run PERMANOVA

pairwise_results <- list() # list to store post hoc result
significant_results <- list() # list to store only significant post hoc results

pairwise_model <- pairwise.perm.manova(dist_matrix_full, data$pah_group, nperm = 999, p.method = "bonferroni") # run post hoc 

pairwise_df <- as.data.frame(pairwise_model$p.value) # Extract the results table correctly from `pairwise.htest` object
colnames(pairwise_df) <- c("p.value")  # Ensure column name is consistent

pairwise_results[["pah_group"]] <- pairwise_df # Store full results

significant_results[["pah_group"]] <- pairwise_df[pairwise_df$p.value < 0.05, , drop = FALSE] # filter significant results

cat("\n### PERMANOVA results for All pah_groups ###\n")
print(permanova_full) # view permanova results

if (nrow(significant_results[["pah_group"]]) > 0) {
  cat("\n### Significant pairwise post hoc results (p < 0.05) ###\n")
  print(significant_results[["pah_group"]])
} else {
  cat("\n### No significant pairwise differences found in All pah_groups ###\n") # view significant post hoc results
}

# write out significant results
#write.csv(significant_results[["Full Data"]], "significant_pairwise_results_full_data.csv", row.names = FALSE)

```

## Geo Group (n=5)
### No significant results, p= 0.973
```{r}

library(vegan)
library(RVAideMemoire)

# don't need to recreate the matrix, we will use the same matrix created in the first step
#dist_matrix_full <- vegdist(as.matrix(data[, c("p450", "sod", "ci_wet_volume", "ci_wet_shell_weight", "ci_pollution", "shell_thickness")]), na.rm= TRUE, method = "euclidean") # create distance matrix

data$geo_group <- as.factor(data$geo_group) # make a factor for analysis

permanova_full <- adonis2(dist_matrix_full ~ geo_group, data = data, permutations = 999) # run PERMANOVA

pairwise_results <- list() # list to store post hoc result
significant_results <- list() # list to store only significant post hoc results

pairwise_model <- pairwise.perm.manova(dist_matrix_full, data$geo_group, nperm = 999, p.method = "bonferroni") # run post hoc 

pairwise_df <- as.data.frame(pairwise_model$p.value) # Extract the results table correctly from `pairwise.htest` object
colnames(pairwise_df) <- c("p.value")  # Ensure column name is consistent

pairwise_results[["geo_group"]] <- pairwise_df # Store full results

significant_results[["geo_group"]] <- pairwise_df[pairwise_df$p.value < 0.05, , drop = FALSE] # filter significant results

cat("\n### PERMANOVA results for All geo_groups ###\n")
print(permanova_full) # view permanova results

if (nrow(significant_results[["geo_group"]]) > 0) {
  cat("\n### Significant pairwise post hoc results (p < 0.05) ###\n")
  print(significant_results[["geo_group"]])
} else {
  cat("\n### No significant pairwise differences found in All geo_groups ###\n") # view significant post hoc results
}

# write out significant results
#write.csv(significant_results[["Full Data"]], "significant_pairwise_results_full_data.csv", row.names = FALSE)

```

# Permanova and Post Hoc (individual metrics)
## Site
### No significant results
```{r}

library(vegan)
library(RVAideMemoire)

# Function to run PERMANOVA and post hoc pairwise comparisons
run_permanova_with_posthoc <- function(p450, data) {
  # Remove NAs before creating the distance matrix
  clean_data <- data[!is.na(data[[p450]]), ]
  
  # Ensure the metric is numeric
  clean_data[[p450]] <- as.numeric(clean_data[[p450]])
  
  # Create distance matrix
  dist_matrix <- vegdist(as.matrix(clean_data[[p450]]), method = "euclidean")
  
  # Run PERMANOVA
  permanova_result <- adonis2(dist_matrix ~ site_name, data = clean_data, permutations = 999)

  # Print PERMANOVA results
  cat("\n### PERMANOVA results for", p450, "###\n")
  print(permanova_result)

  # Run post hoc pairwise comparisons
  pairwise_result <- pairwise.perm.manova(dist_matrix, clean_data$site_name, nperm = 999, p.method = "bonferroni")

  # Extract p-values from the results
  pairwise_df <- as.data.frame(pairwise_result$p.value)
  colnames(pairwise_df) <- c("p.value")  # Ensure consistent column naming

  # Store results
  return(list(PERMANOVA = permanova_result, Pairwise = pairwise_df))
}

# Run PERMANOVA and post hoc tests for each metric
metrics <- c("p450", "sod", "ci1", "ci2", "ci3", "shell")
permanova_results <- lapply(metrics, function(metric) run_permanova_with_posthoc(metric, data))
names(permanova_results) <- metrics

# Extract significant post hoc results (p < 0.05)
significant_results <- lapply(permanova_results, function(res) res$Pairwise[res$Pairwise$p.value < 0.05, , drop = FALSE])

# Print significant results
cat("\n### Significant pairwise post hoc results (p < 0.05) ###\n")
print(significant_results)

```

## Reporting Area
### Only Shell is significant, RA 11
```{r}

library(vegan)
library(RVAideMemoire)

data$reporting_area <- as.factor(data$reporting_area)

# Function to run PERMANOVA and post hoc pairwise comparisons
run_permanova_with_posthoc <- function(p450, data) {
  # Remove NAs before creating the distance matrix
  clean_data <- data[!is.na(data[[p450]]), ]
  
  # Ensure the metric is numeric
  clean_data[[p450]] <- as.numeric(clean_data[[p450]])
  
  # Create distance matrix
  dist_matrix <- vegdist(as.matrix(clean_data[[p450]]), method = "euclidean")
  
  # Run PERMANOVA
  permanova_result <- adonis2(dist_matrix ~ reporting_area, data = clean_data, permutations = 999)

  # Print PERMANOVA results
  cat("\n### PERMANOVA results for", p450, "###\n")
  print(permanova_result)

  # Run post hoc pairwise comparisons
  pairwise_result <- pairwise.perm.manova(dist_matrix, clean_data$reporting_area, nperm = 999, p.method = "bonferroni")

  # Extract p-values from the results
  pairwise_df <- as.data.frame(pairwise_result$p.value)
  colnames(pairwise_df) <- c("p.value")  # Ensure consistent column naming

  # Store results
  return(list(PERMANOVA = permanova_result, Pairwise = pairwise_df))
}

# Run PERMANOVA and post hoc tests for each metric
metrics <- c("p450", "sod", "ci1", "ci2", "ci3", "shell")
permanova_results <- lapply(metrics, function(metric) run_permanova_with_posthoc(metric, data))
names(permanova_results) <- metrics

# Extract significant post hoc results (p < 0.05)
significant_results <- lapply(permanova_results, function(res) res$Pairwise[res$Pairwise$p.value < 0.05, , drop = FALSE])

# Print significant results
cat("\n### Significant pairwise post hoc results (p < 0.05) ###\n")
print(significant_results)

```

## PCB Group
### No significant results
```{r}

library(vegan)
library(RVAideMemoire)

data$pcb_group <- as.factor(data$pcb_group) # make a factor for analysis

# Function to run PERMANOVA and post hoc pairwise comparisons
run_permanova_with_posthoc <- function(p450, data) {
  # Remove NAs before creating the distance matrix
  clean_data <- data[!is.na(data[[p450]]), ]
  
  # Ensure the metric is numeric
  clean_data[[p450]] <- as.numeric(clean_data[[p450]])
  
  # Create distance matrix
  dist_matrix <- vegdist(as.matrix(clean_data[[p450]]), method = "euclidean")
  
  # Run PERMANOVA
  permanova_result <- adonis2(dist_matrix ~ pcb_group, data = clean_data, permutations = 999)

  # Print PERMANOVA results
  cat("\n### PERMANOVA results for", p450, "###\n")
  print(permanova_result)

  # Run post hoc pairwise comparisons
  pairwise_result <- pairwise.perm.manova(dist_matrix, clean_data$pcb_group, nperm = 999, p.method = "bonferroni")

  # Extract p-values from the results
  pairwise_df <- as.data.frame(pairwise_result$p.value)
  colnames(pairwise_df) <- c("p.value")  # Ensure consistent column naming

  # Store results
  return(list(PERMANOVA = permanova_result, Pairwise = pairwise_df))
}

# Run PERMANOVA and post hoc tests for each metric
metrics <- c("p450", "sod", "ci_wet_volume", "ci_wet_shell_weight", "ci_pollution", "shell_thickness")
permanova_results <- lapply(metrics, function(metric) run_permanova_with_posthoc(metric, data))
names(permanova_results) <- metrics

# Extract significant post hoc results (p < 0.05)
significant_results <- lapply(permanova_results, function(res) res$Pairwise[res$Pairwise$p.value < 0.05, , drop = FALSE])

# Print significant results
cat("\n### Significant pairwise post hoc results (p < 0.05) ###\n")
print(significant_results)

```

## PAH Group
### No significant results
```{r}

library(vegan)
library(RVAideMemoire)

data$pah_group <- as.factor(data$pah_group) # make a factor for analysis

# Function to run PERMANOVA and post hoc pairwise comparisons
run_permanova_with_posthoc <- function(p450, data) {
  # Remove NAs before creating the distance matrix
  clean_data <- data[!is.na(data[[p450]]), ]
  
  # Ensure the metric is numeric
  clean_data[[p450]] <- as.numeric(clean_data[[p450]])
  
  # Create distance matrix
  dist_matrix <- vegdist(as.matrix(clean_data[[p450]]), method = "euclidean")
  
  # Run PERMANOVA
  permanova_result <- adonis2(dist_matrix ~ pah_group, data = clean_data, permutations = 999)

  # Print PERMANOVA results
  cat("\n### PERMANOVA results for", p450, "###\n")
  print(permanova_result)

  # Run post hoc pairwise comparisons
  pairwise_result <- pairwise.perm.manova(dist_matrix, clean_data$pah_group, nperm = 999, p.method = "bonferroni")

  # Extract p-values from the results
  pairwise_df <- as.data.frame(pairwise_result$p.value)
  colnames(pairwise_df) <- c("p.value")  # Ensure consistent column naming

  # Store results
  return(list(PERMANOVA = permanova_result, Pairwise = pairwise_df))
}

# Run PERMANOVA and post hoc tests for each metric
metrics <- c("p450", "sod", "ci_wet_volume", "ci_wet_shell_weight", "ci_pollution", "shell_thickness")
permanova_results <- lapply(metrics, function(metric) run_permanova_with_posthoc(metric, data))
names(permanova_results) <- metrics

# Extract significant post hoc results (p < 0.05)
significant_results <- lapply(permanova_results, function(res) res$Pairwise[res$Pairwise$p.value < 0.05, , drop = FALSE])

# Print significant results
cat("\n### Significant pairwise post hoc results (p < 0.05) ###\n")
print(significant_results)

```

## Geo Group
### No significant results
```{r}

library(vegan)
library(RVAideMemoire)

data$geo_group <- as.factor(data$geo_group) # make a factor for analysis

# Function to run PERMANOVA and post hoc pairwise comparisons
run_permanova_with_posthoc <- function(p450, data) {
  # Remove NAs before creating the distance matrix
  clean_data <- data[!is.na(data[[p450]]), ]
  
  # Ensure the metric is numeric
  clean_data[[p450]] <- as.numeric(clean_data[[p450]])
  
  # Create distance matrix
  dist_matrix <- vegdist(as.matrix(clean_data[[p450]]), method = "euclidean")
  
  # Run PERMANOVA
  permanova_result <- adonis2(dist_matrix ~ geo_group, data = clean_data, permutations = 999)

  # Print PERMANOVA results
  cat("\n### PERMANOVA results for", p450, "###\n")
  print(permanova_result)

  # Run post hoc pairwise comparisons
  pairwise_result <- pairwise.perm.manova(dist_matrix, clean_data$geo_group, nperm = 999, p.method = "bonferroni")

  # Extract p-values from the results
  pairwise_df <- as.data.frame(pairwise_result$p.value)
  colnames(pairwise_df) <- c("p.value")  # Ensure consistent column naming

  # Store results
  return(list(PERMANOVA = permanova_result, Pairwise = pairwise_df))
}

# Run PERMANOVA and post hoc tests for each metric
metrics <- c("p450", "sod", "ci_wet_volume", "ci_wet_shell_weight", "ci_pollution", "shell_thickness")
permanova_results <- lapply(metrics, function(metric) run_permanova_with_posthoc(metric, data))
names(permanova_results) <- metrics

# Extract significant post hoc results (p < 0.05)
significant_results <- lapply(permanova_results, function(res) res$Pairwise[res$Pairwise$p.value < 0.05, , drop = FALSE])

# Print significant results
cat("\n### Significant pairwise post hoc results (p < 0.05) ###\n")
print(significant_results)

```

# KW & Post Hoc (individual metrics for each group)
## Site
### No significant results
```{r}

library(vegan)
library(FSA)

# P450
kruskal.test(p450 ~ site_name, data = data) # result: p= 8.077e-6
dunn <- dunnTest(data$p450, data$site_name, method = "bonferroni", list = TRUE)
mc <- data.frame(
    Comparison = dunn$comparisons,
    Z = dunn$Z,
    P.adjusted = dunn$P.adjusted
)
print(mc) # NO significance confirmed

# SOD
kruskal.test(sod ~ site_name, data = data) # result: p= 5.669e-6
dunn <- dunnTest(data$sod, data$site_name, method = "bonferroni", list = TRUE)
mc <- data.frame(
    Comparison = dunn$comparisons,
    Z = dunn$Z,
    P.adjusted = dunn$P.adjusted
)
print(mc) # NO significance confirmed

# CI_Wet_Volume
kruskal.test(ci_wet_volume ~ site_name, data = data) # result: p= 0.02581
dunn <- dunnTest(data$ci_wet_volume, data$site_name, method = "bonferroni", list = TRUE)
mc <- data.frame(
    Comparison = dunn$comparisons,
    Z = dunn$Z,
    P.adjusted = dunn$P.adjusted
)
print(mc) # NO significance confirmed

# CI_Wet_Shell_Weight
kruskal.test(ci_wet_shell_weight ~ site_name, data = data) # result: p= 2.832e-8
dunn <- dunnTest(data$ci_wet_shell_weight, data$site_name, method = "bonferroni", list = TRUE)
mc <- data.frame(
    Comparison = dunn$comparisons,
    Z = dunn$Z,
    P.adjusted = dunn$P.adjusted
)
print(mc) # NO significance confirmed

# CI_Pollution
kruskal.test(ci_pollution ~ site_name, data = data) # result: p= 0.05444
dunn <- dunnTest(data$ci_pollution, data$site_name, method = "bonferroni", list = TRUE)
mc <- data.frame(
    Comparison = dunn$comparisons,
    Z = dunn$Z,
    P.adjusted = dunn$P.adjusted
)
print(mc) # NO significance confirmed

```

## Reporting Areas
### No significant results
```{r}

library(vegan)
library(FSA)

data$reporting_area <- as.factor(data$reporting_area) # make a factor for analysis

# P450
kruskal.test(p450 ~ reporting_area, data = data) # result: p= 0.2722
dunn <- dunnTest(data$p450, data$reporting_area, method = "bonferroni", list = TRUE)
mc <- data.frame(
    Comparison = dunn$comparisons,
    Z = dunn$Z,
    P.adjusted = dunn$P.adjusted
)
print(mc) # NO significance confirmed

# SOD
kruskal.test(sod ~ reporting_area, data = data) # result: p= 0.01261
dunn <- dunnTest(data$sod, data$reporting_area, method = "bonferroni", list = TRUE)
mc <- data.frame(
    Comparison = dunn$comparisons,
    Z = dunn$Z,
    P.adjusted = dunn$P.adjusted
)
print(mc) # NO significance confirmed

# CI_Wet_Volume
kruskal.test(ci_wet_volume ~ reporting_area, data = data) # result: p= 0.8026
dunn <- dunnTest(data$ci_wet_volume, data$reporting_area, method = "bonferroni", list = TRUE)
mc <- data.frame(
    Comparison = dunn$comparisons,
    Z = dunn$Z,
    P.adjusted = dunn$P.adjusted
)
print(mc) # NO significance confirmed

# CI_Wet_Shell_Weight
kruskal.test(ci_wet_shell_weight ~ reporting_area, data = data) # result: p= 0.3923
dunn <- dunnTest(data$ci_wet_shell_weight, data$reporting_area, method = "bonferroni", list = TRUE)
mc <- data.frame(
    Comparison = dunn$comparisons,
    Z = dunn$Z,
    P.adjusted = dunn$P.adjusted
)
print(mc) # NO significance confirmed

# CI_Pollution
kruskal.test(ci_pollution ~ reporting_area, data = data) # result: p= 0.454
dunn <- dunnTest(data$ci_pollution, data$reporting_area, method = "bonferroni", list = TRUE)
mc <- data.frame(
    Comparison = dunn$comparisons,
    Z = dunn$Z,
    P.adjusted = dunn$P.adjusted
)
print(mc) # NO significance confirmed

```

## PCB Groups
### No significant results
```{r}

library(vegan)
library(FSA)

data$pcb_group <- as.factor(data$pcb_group) # make a factor for analysis

# P450
kruskal.test(p450 ~ pcb_group, data = data) # result: p= 0.003688
dunn <- dunnTest(data$p450, data$pcb_group, method = "bonferroni", list = TRUE)
mc <- data.frame(
    Comparison = dunn$comparisons,
    Z = dunn$Z,
    P.adjusted = dunn$P.adjusted
)
print(mc) # NO significance confirmed

# SOD
kruskal.test(sod ~ pcb_group, data = data) # result: p= 0.003041
dunn <- dunnTest(data$sod, data$pcb_group, method = "bonferroni", list = TRUE)
mc <- data.frame(
    Comparison = dunn$comparisons,
    Z = dunn$Z,
    P.adjusted = dunn$P.adjusted
)
print(mc) # NO significance confirmed

# CI_Wet_Volume
kruskal.test(ci_wet_volume ~ pcb_group, data = data) # result: p= 0.2901
dunn <- dunnTest(data$ci_wet_volume, data$pcb_group, method = "bonferroni", list = TRUE)
mc <- data.frame(
    Comparison = dunn$comparisons,
    Z = dunn$Z,
    P.adjusted = dunn$P.adjusted
)
print(mc) # NO significance confirmed

# CI_Wet_Shell_Weight
kruskal.test(ci_wet_shell_weight ~ pcb_group, data = data) # result: p= 0.05206
dunn <- dunnTest(data$ci_wet_shell_weight, data$pcb_group, method = "bonferroni", list = TRUE)
mc <- data.frame(
    Comparison = dunn$comparisons,
    Z = dunn$Z,
    P.adjusted = dunn$P.adjusted
)
print(mc) # NO significance confirmed

# CI_Pollution
kruskal.test(ci_pollution ~ pcb_group, data = data) # result: p= 0.8241
dunn <- dunnTest(data$ci_pollution, data$pcb_group, method = "bonferroni", list = TRUE)
mc <- data.frame(
    Comparison = dunn$comparisons,
    Z = dunn$Z,
    P.adjusted = dunn$P.adjusted
)
print(mc) # NO significance confirmed

```

## PAH Group
### No significant results
```{r}

library(vegan)
library(FSA)

data$pah_group <- as.factor(data$pah_group) # make a factor for analysis

# P450
kruskal.test(p450 ~ pah_group, data = data) # result: p= 0.2722
dunn <- dunnTest(data$p450, data$pah_group, method = "bonferroni", list = TRUE)
mc <- data.frame(
    Comparison = dunn$comparisons,
    Z = dunn$Z,
    P.adjusted = dunn$P.adjusted
)
print(mc) # NO significance confirmed

# SOD
kruskal.test(sod ~ pah_group, data = data) # result: p= 0.01261
dunn <- dunnTest(data$sod, data$pah_group, method = "bonferroni", list = TRUE)
mc <- data.frame(
    Comparison = dunn$comparisons,
    Z = dunn$Z,
    P.adjusted = dunn$P.adjusted
)
print(mc) # NO significance confirmed

# CI_Wet_Volume
kruskal.test(ci_wet_volume ~ pah_group, data = data) # result: p= 0.8026
dunn <- dunnTest(data$ci_wet_volume, data$pah_group, method = "bonferroni", list = TRUE)
mc <- data.frame(
    Comparison = dunn$comparisons,
    Z = dunn$Z,
    P.adjusted = dunn$P.adjusted
)
print(mc) # NO significance confirmed

# CI_Wet_Shell_Weight
kruskal.test(ci_wet_shell_weight ~ pah_group, data = data) # result: p= 0.3923
dunn <- dunnTest(data$ci_wet_shell_weight, data$pah_group, method = "bonferroni", list = TRUE)
mc <- data.frame(
    Comparison = dunn$comparisons,
    Z = dunn$Z,
    P.adjusted = dunn$P.adjusted
)
print(mc) # NO significance confirmed

# CI_Pollution
kruskal.test(ci_pollution ~ pah_group, data = data) # result: p= 0.454
dunn <- dunnTest(data$ci_pollution, data$pah_group, method = "bonferroni", list = TRUE)
mc <- data.frame(
    Comparison = dunn$comparisons,
    Z = dunn$Z,
    P.adjusted = dunn$P.adjusted
)
print(mc) # NO significance confirmed

```

## Geo Group
### No significant results
```{r}

library(vegan)
library(FSA)

data$geo_group <- as.factor(data$geo_group) # make a factor for analysis

# P450
kruskal.test(p450 ~ geo_group, data = data) # result: p= 0.0148
dunn <- dunnTest(data$p450, data$geo_group, method = "bonferroni", list = TRUE)
mc <- data.frame(
    Comparison = dunn$comparisons,
    Z = dunn$Z,
    P.adjusted = dunn$P.adjusted
)
print(mc) # NO significance confirmed

# SOD
kruskal.test(sod ~ geo_group, data = data) # result: p= 0.07454
dunn <- dunnTest(data$sod, data$geo_group, method = "bonferroni", list = TRUE)
mc <- data.frame(
    Comparison = dunn$comparisons,
    Z = dunn$Z,
    P.adjusted = dunn$P.adjusted
)
print(mc) # NO significance confirmed

# CI_Wet_Volume
kruskal.test(ci_wet_volume ~ geo_group, data = data) # result: p= 0.8462
dunn <- dunnTest(data$ci_wet_volume, data$geo_group, method = "bonferroni", list = TRUE)
mc <- data.frame(
    Comparison = dunn$comparisons,
    Z = dunn$Z,
    P.adjusted = dunn$P.adjusted
)
print(mc) # NO significance confirmed

# CI_Wet_Shell_Weight
kruskal.test(ci_wet_shell_weight ~ geo_group, data = data) # result: p= 0.09208
dunn <- dunnTest(data$ci_wet_shell_weight, data$geo_group, method = "bonferroni", list = TRUE)
mc <- data.frame(
    Comparison = dunn$comparisons,
    Z = dunn$Z,
    P.adjusted = dunn$P.adjusted
)
print(mc) # NO significance confirmed

# CI_Pollution
kruskal.test(ci_pollution ~ geo_group, data = data) # result: p= 0.3182
dunn <- dunnTest(data$ci_pollution, data$geo_group, method = "bonferroni", list = TRUE)
mc <- data.frame(
    Comparison = dunn$comparisons,
    Z = dunn$Z,
    P.adjusted = dunn$P.adjusted
)
print(mc) # NO significance confirmed

```

# ANOVA - Shell Thickness Only
## All groupings (site, reporting area, pcb group, pah group, geo group)
### Significant results for all groupings, confirmed in post hoc testing
```{r}

library(car)
library(multcomp)

# Define grouping variables
grouping_vars <- c("site_name", "reporting_area", "pcb_group", "pah_group", "geo_group")

# Function to run ANOVA and post hoc test
run_anova_posthoc <- function(group_var, data) {
  # Remove NAs for shell thickness and the grouping variable
  clean_data <- data[!is.na(data$shell_thickness) & !is.na(data[[group_var]]), ]
  
  # Run ANOVA
  anova_model <- aov(shell_thickness ~ get(group_var), data = clean_data)
  anova_summary <- summary(anova_model)

  # Extract p-value from ANOVA table
  p_value <- anova_summary[[1]]["Pr(>F)"][1,1]  

  # Only proceed if ANOVA is significant
  if (p_value < 0.05) {
    cat("\n### Significant ANOVA results for shell thickness by", group_var, "###\n")
    print(anova_summary)

    # Run Tukey's HSD post hoc test
    posthoc_result <- TukeyHSD(anova_model)

    # Convert to data frame for filtering
    posthoc_df <- as.data.frame(posthoc_result[[1]])
    posthoc_df <- cbind(comparison = rownames(posthoc_df), posthoc_df)  # Add comparison column

    # Filter only significant results (p < 0.05)
    significant_posthoc <- posthoc_df[posthoc_df$`p adj` < 0.05, , drop = FALSE]

    if (nrow(significant_posthoc) > 0) {
      cat("\n### Significant Tukey Post Hoc Comparisons for", group_var, "###\n")
      print(significant_posthoc)
    } else {
      cat("\n### No significant post hoc differences for", group_var, "###\n")
    }

    return(list(ANOVA = anova_summary, PostHoc = significant_posthoc))
  } else {
    cat("\n### No significant ANOVA differences for shell thickness by", group_var, "###\n")
    return(NULL)
  }
}

# Run ANOVA + post hoc for each grouping variable and store only significant results
anova_results <- lapply(grouping_vars, function(var) run_anova_posthoc(var, data))
names(anova_results) <- grouping_vars

# Remove NULL results (where ANOVA was not significant)
anova_results <- anova_results[!sapply(anova_results, is.null)]

```

## Write out current df for review
```{r}

write.csv(data, "../data/cleaned/all_individual_data_and_all_groups.csv", row.names = FALSE)

```

