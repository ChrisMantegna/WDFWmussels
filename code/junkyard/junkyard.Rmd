# Extra stuff that I used to check







#plot analytes by sites
```{r}
library(ggplot2)
library(gridExtra)

p450<- ggplot(allr, aes(x = site_name, y = p450)) +
  geom_point(color = "blue") +  # Scatter plot with blue color
  labs(x = "Sites", y = "p450 Values", title = "p450 Values by Site") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

SumPAHsHMW<- ggplot(allr, aes(x = site_name, y = SumPAHsHMW)) +
  geom_point(color = "red") +  # Scatter plot with blue color
  labs(x = "Sites", y = "Analyte Values", title = "SumPAHsHMW Values by Site") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

# Arrange the plots side by side
combined_plots <- grid.arrange(p450, SumPAHsHMW, ncol = 2,
                               widths = c(8, 8)) 
```
```{r}
SumPAHsHMW<- ggplot(allr, aes(x = site_name, y = SumPAHsHMW)) +
  geom_point(color = "red") +  # Scatter plot with blue color
  labs(x = "Sites", y = "Analyte Values", title = "SumPAHsHMW Values by Site") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

# Arrange the plots side by side
combined_plots <- grid.arrange(p450, SumPAHsHMW, ncol = 2,
                               widths = c(8, 8)) 
```

```{r}
acenaphthene<- ggplot(allr, aes(x = site_name, y = acenaphthene)) +
  geom_point(color = "red") +  # Scatter plot with blue color
  labs(x = "Sites", y = "Analyte Values", title = "acenaphthene Values by Site") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

# Arrange the plots side by side
combined_plots <- grid.arrange(p450, acenaphthene, ncol = 2,
                               widths=c(8,8))
```


```{r}
anthracene<- ggplot(allr, aes(x = site_name, y = anthracene)) +
  geom_point(color = "red") +  # Scatter plot with blue color
  labs(x = "Sites", y = "Analyte Values", title = "anthracene Values by Site") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

# Arrange the plots side by side
combined_plots <- grid.arrange(p450, anthracene, ncol = 2,
                               widths = c(8, 8)) 
```

```{r}
# Load the ggplot2 package
library(ggplot2)

# Assuming your data frame is named 'allr'
Biomarker <- allr[[4]]  # Biomarker column

# Loop through columns 4 to 54
for (i in 9:54) {
    # Create a temporary data frame for plotting
    temp_data <- data.frame(Biomarker = p450, Value = allr[[i]])

    # Generate the plot
    p <- ggplot(temp_data, aes(x = Value, y = Biomarker)) +
        geom_point() +  # Add points
        geom_smooth(method = "lm", se = FALSE) +  # Add a linear regression line without standard error
        labs(title = paste("Biomarker vs", colnames(allr)[i]),
             x = "Biomarker",
             y = colnames(allr)[i])

    # Print the plot
    print(p)
}

```

```{r}
# Load the ggplot2 package
library(ggplot2)
getwd()
plot_directory<- "/Users/cmantegna/Documents/WDFWmussels/output/individual_plots/"


Sites <- allr[[1]]  # Site name column

# Loop through columns 5 to 58 (or whatever your range is)
for (i in 5:58) {
    # Create a temporary data frame for plotting
    temp_data <- data.frame(Sites = Sites, Value = allr[[i]])

    # Generate the plot
    s <- ggplot(temp_data, aes(x = Sites, y = Value)) +
        geom_point() +  
        geom_smooth(method = "lm", se = FALSE) +  # Add a linear regression line without standard error
        labs(title = paste("Site vs", colnames(allr)[i]),
             x = "Site Name",
             y = colnames(allr)[i])+
      theme(axis.text.x = element_text(angle = 90, hjust = 1))

    # Print the plot
    print(s)
}

# Define the file name
    #file_name <- paste0("/Site_vs_", colnames(allr)[i], ".png")

#ggsave(file_name, plot= s, width=10, height=6)

```

# 0's and negative number management

SOD values that are negative are changed to 0 signifying that the value was undetectable.\
p450 values that are 0 are missing, not actual 0's.


# this code isn't correct for alldata - need to fix
# Detect outliers and plot them - code a combo of stack overflow and chat gpt.

```{r}

detect_outliers_mad <- function(alldata, accuracy = 0.99) {
  # Calculate z-score equivalent for the given accuracy
  z_threshold <- qnorm(accuracy + (1 - accuracy) / 2)

  # Initialize a list to store outlier indices for each numeric column
  outliers_list <- list()

  # Initialize a vector to keep track of rows with outliers
  rows_with_outliers <- rep(FALSE, nrow(alldata))

  # Loop through each column in the dataframe
  for (col_name in names(data)) {
    # Check if the column is numeric
    if (is.numeric(data[[col_name]])) {
      # Calculate MAD and median for the column
      mad_value <- median(abs(data[[col_name]] - median(data[[col_name]])))
      median_value <- median(data[[col_name]])

      # Calculate the deviation scores (using a modified z-score formula)
      deviation_scores <- 0.6745 * (data[[col_name]] - median_value) / mad_value

      # Identify indices of outliers
      outlier_indices <- which(abs(deviation_scores) > z_threshold)

      # Store the indices in the list
      outliers_list[[col_name]] <- outlier_indices

      # Update rows with outliers
      rows_with_outliers[outlier_indices] <- TRUE
    }
  }

  # Return the list of outliers and rows with outliers
  list(outliers_list = outliers_list, rows_with_outliers = rows_with_outliers)
}

outliers_info <- detect_outliers_mad(alldata)

# Convert the list of outliers to a named vector of counts
num_outliers_each_col <- sapply(outliers_info$outliers_list, length)
num_rows_with_outliers <- sum(outliers_info$rows_with_outliers)

# Check if there are any outliers
if (all(num_outliers_each_col == 0)) {
  print("There are no outliers in any columns.")
} else {
  # Create a data frame for plotting
  outliers_data_df <- data.frame(
    Column = names(num_outliers_each_col),
    Outliers = as.integer(num_outliers_each_col),
    OutlierPercentage = (as.integer(num_outliers_each_col) / nrow(data)) * 100
  )

  # Plot the number of outliers for all columns
  outlier_plot <- ggplot(outliers_data_df, aes(x = Column, y = Outliers, fill = Column)) +
    geom_bar(stat = "identity") +
    geom_text(aes(label = sprintf("%.2f%%", OutlierPercentage)), position = position_dodge(width = 0.9), vjust = -0.25) +
    coord_flip() +
    labs(title = "Number of Outliers by Column", x = "Column", y = "Number of Outliers") +
    scale_fill_brewer(palette = "Set3") +
    theme_minimal()

  print(outlier_plot)
}

#ggsave(plot= outlier_plot, filename="/Users/cmantegna/Documents/WDFWmussels/output/outliers.png", width=15, height=8)

```

# Plotting both biomarkers in a box plot

```{r}

all<-plot<- ggplot(alldata) +
  geom_point(aes(x = site_name, y = SOD, color = "SOD")) +
  geom_point(aes(x = site_name, y = p450, color = "P450")) +
  labs(x = "Site Name", y = "Value", color = "Biomarker") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))


print(all)
ggsave(plot=all, filename="/Users/cmantegna/Documents/WDFWmussels/output/allBoxPlot.png", width=15, height=8)

```

# Plotting both biomarkers in a box plot with a free y-axis to fix the sod v p450 values. The SOD values all look the same and are all at 0.

Note that the color for SOD shifts from teal to salmon between the two plots.

```{r}
# First, create a basic ggplot object with SOD data
freey <- ggplot(data, aes(x = site_name)) +
  geom_point(aes(y = SOD, color = "SOD")) +
  labs(x = "Site Name", y = "SOD Value") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

# Then, add p450 using sec.axis
freey + geom_point(aes(y = p450/100, color = "p450")) + # Example scaling factor, adjust as needed
  scale_y_continuous(sec.axis = sec_axis(~.*100, name = "p450 Value")) # Reverse the scaling for the secondary axis label

print(freey)
#ggsave(plot=freey, filename="/Users/cmantegna/Documents/WDFWmussels/output/allBoxPlotFreeY.png", width=15, height=8)
```

# Plotting both biomarkers in their own box plots with a facet wrap to try to show the difference in values for both biomarkers since SOD looks the same.

```{r}

# Reshape data from wide to long format
long_data <- pivot_longer(data, cols = c(SOD, p450), names_to = "Biomarker", values_to = "Value")

# Plotting with faceting
facetp <- ggplot(long_data, aes(x = site_name, y = Value, color = Biomarker)) +
  geom_point() +
  facet_wrap(~Biomarker, scales = "free_y") + # This allows each biomarker to have its own y-axis scale
  labs(x = "Site Name", y = "Value", color = "Biomarker") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

print(facetp)
# Save the plot
ggsave(plot=facetp, filename="/Users/cmantegna/Documents/WDFWmussels/output/allBoxPlotFacet.png", width=15, height=8)

```

# Plotting separate box plots to investigate the facet, the other options still show the sod values the 'same' when everything is plotted together.

```{r}

# Ensure your data is in the correct format.
# Reshape your dataframe if it hasn't been done correctly.
long_data <- pivot_longer(data, cols = c(SOD, p450), names_to = "Biomarker", values_to = "Value")

# Faceted plot with separate scales.
plotf<- ggplot(long_data, aes(x = site_name, y = Value)) +
  geom_point(aes(color = Biomarker)) +
  facet_wrap(~ Biomarker, scales = "free_y") +
  labs(x = "Site Name", y = "Value", color = "Biomarker") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

print(plotf)
ggsave(plot=plotf, filename="/Users/cmantegna/Documents/WDFWmussels/output/allBoxPlotFacetPanels.png", width=40, height=25)

```

# Plotting p450 values ranked from smallest to largest

```{r}

# Order the sites by p450 value
data_ordered <- data[order(data$p450),]

# Create a factor with the ordered site names
data_ordered$site_name <- factor(data_ordered$site_name, levels = unique(data_ordered$site_name))

# Plot the SOD values in a boxplot with ordered site names
rankp<- ggplot(data_ordered, aes(x = site_name, y = p450)) +
  geom_boxplot() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) # Rotate x labels if needed

print(rankp)
ggsave(plot=rankp, filename="/Users/cmantegna/Documents/WDFWmussels/output/p450ranked.png", width=15, height=8)
```

# Plotting SOD values ranked from samllest largest

```{r}

# Order the sites by p450 value
data_ordered <- data[order(data$SOD),]

# Create a factor with the ordered site names
data_ordered$site_name <- factor(data_ordered$site_name, levels = unique(data_ordered$site_name))

# Plot the SOD values in a boxplot with ordered site names
ranks<- ggplot(data_ordered, aes(x = site_name, y = SOD)) +
  geom_boxplot() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) # Rotate x labels if needed

print(ranks)
ggsave(plot=ranks, filename="/Users/cmantegna/Documents/WDFWmussels/output/SODranked.png", width=15, height=8)
```

# histogram with density curve
```{r}
#basic histogram + basic density plot
#hist(data$p450)
#plot(density(data$p450), main="Density Plot", xlab="p450 Value")

#ggplot histogram with density curve
library(scales) # Make sure this package is loaded for label_number()

phist<- ggplot(alldata, aes(x = p450)) +
  geom_histogram(aes(y = after_stat(density)), binwidth = diff(range(data$p450))/30, colour = "black", fill = "white") +
  geom_density(alpha = .2, fill = "#FF6666") +
  labs(x = "P450 Values", y = "Density", title = "Histogram of P450 Values with Density Curve") +
  theme_minimal() +
  scale_x_continuous(labels = label_number()) # This line adjusts the x-axis labels

print(phist)
#ggsave(plot=phist, filename="/Users/cmantegna/Documents/WDFWmussels/output/p450histogram.png", width=15, height=8)

```

## renaming the individual analytes so that entering data into the anova isn't difficult

```{r}
# Generate the first 26 letters of the alphabet
letters_seq <- letters[1:26]

# Generate additional letters if needed
extra_letters_seq <- character(0)
num_cols <- length(22:57)  # Number of columns you want to rename
if (num_cols > length(letters_seq)) {
  repeats_needed <- num_cols - length(letters_seq)
  # Generate double letters like 'aa', 'bb', 'cc', etc.
  extra_letters_seq <- rep(letters[1:repeats_needed], each=1)
  extra_letters_seq <- sapply(extra_letters_seq, function(x) paste0(x, x))
}

# Combine the original and additional sequences
new_colnames <- c(letters_seq, extra_letters_seq)[1:num_cols]


```

```{r}
# Assuming 'alldata' is your dataframe
colnames(alldata)[22:57] <- new_colnames

# View the updated column names to confirm
print(colnames(alldata))

```

# Mapping both biomarkers
```{r}

# Assuming washington_map is your sf object for Washington State
ggplot(data = washington_map) + 
  geom_sf(fill = "lightgrey", color = "white") +
  geom_point(data = data, aes(x = longitude, y = latitude, color = p450, size = SOD), alpha = 0.6) +
  scale_color_viridis(name = "p450", option = "D") +
  scale_size_continuous(name = "SOD", range = c(2, 6)) +
  theme_minimal() +
  labs(title = "Washington State: p450 and SOD")

```

# Mapping with shapes to differenciate the biomarkers - change dataframe to accomodate
```{r}

long_data <- pivot_longer(data, cols = c(SOD, p450), names_to = "type", values_to = "value")

```

# plotting SOD by sites
```{r}
# data adjust to plot the 95%
# remove SOD outside of .0025 and 51.58 & p450 outside of 291641 and 5271798
data$SOD[data$SOD <= .0030] <- NA
data$SOD[data$SOD > 51.53] <- NA

data$SOD[data$p450 <= 291641] <- NA
data$SOD[data$p450 >= 5271798] <- NA

# Plot the SOD values in a boxplot with ordered site names
SODboxplot<- ggplot(data, aes(x = site_name, y = SOD)) +
  geom_boxplot() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) # Rotate x labels if needed

print(SODboxplot)
```

# plotting corrected p450
```{r}
# data adjust to plot the 95%
# remove SOD outside of .0025 and 51.58 & p450 outside of 291641 and 5271798


data$p450[data$p450 < 291641] <- NA
data$p450[data$p450 > 5271800] <- NA

# Plot the SOD values in a boxplot with ordered site names
p450boxplot<- ggplot(data, aes(x = site_name, y = p450)) +
  geom_boxplot() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) # Rotate x labels if needed

print(p450boxplot)
```

# fix data to the 95%
```{r}
#fix data set to use the 95%
alldata$SOD[alldata$SOD <= .0030] <- .0030
alldata$SOD[alldata$SOD > 51.53] <- 51.53

alldata$p450[alldata$p450 < 291641] <- 291641
alldata$p450[alldata$p450 > 5271800] <- 5271800

alldata$condition_factor[is.na(alldata$condition_factor)] <- 0.001
alldata$avg_thickness[is.na(alldata$avg_thickness)] <- 0.001


```




# anova for p450
```{r}

#anova
model1 <- lm(p450 ~ SumBDEs + SumDDTs + SumPAHs16 + SumPAHsHMW + SumPCBs2x17 + Zinc, data = alldata)

#summary(model)
p450anova1<- anova(model1)
print(p450anova1)

model2<- lm(p450~ Zinc + cadmium + copper + lead + mercuryTotal, data = alldata)
p450anova2<- anova(model2)
print(p450anova2)

# Save 
#write.csv(p450anova, "/Users/cmantegna/Documents/WDFWmussels/output/p450anova.csv")

```
#anova for p450 and SOD, condition factor, avg_thickness
```{r}

model <- lm(p450 ~ site_number + SOD + condition_factor + avg_thickness, data = alldata)

#summary(model)
cfanova<- anova(model)
print(cfanova)

# Save 
#write.csv(p450analyteanova, "/Users/cmantegna/Documents/WDFWmussels/output/p450analyteanova.csv")

```
#anova for SOD and p450, condition factor, avg_thickness
```{r}

model <- lm(SOD ~ site_number + p450 + condition_factor + avg_thickness, data = alldata)

thickanova<- anova(model)
print(thickanova)
```
# Kruskal- Wallis Test
```{r}
kruskal.test(p450 ~ SOD, data = alldata)

```

# anova for SOD
```{r}
#fix data set to use the 95%
alldata$SOD[alldata$SOD <= .0030] <- .0030
alldata$SOD[alldata$SOD > 51.53] <- 51.53

alldata$p450[alldata$p450 < 291641] <- 291641
alldata$p450[alldata$p450 > 5271800] <- 5271800

#anova

model <- lm(SOD ~ SumBDEs + SumDDTs + SumPAHs16 + SumPAHsHMW + SumPCBs2x17, data = alldata)

#summary(model)
print(SODanova)
SODanova<- anova(model)

# Save 
write.csv(SODanova, "/Users/cmantegna/Documents/WDFWmussels/output/SODanova.csv")

```
# trying to fix column names so i can run an anova on the individual analytes against the biomarkers.
```{r}

#rename columns with characters in them
colnames(all_pah_df)[colnames(all_pah_df) == "benz[a]anthracene" ] <- "benzaanthracene"
colnames(all_pah_df)[colnames(all_pah_df) == "benzo[a]pyrene" ] <- "benzoapyrene"
colnames(all_pah_df)[colnames(all_pah_df) == "benzo[b]fluoranthene" ] <- "benzobfluoranthene"
colnames(all_pah_df)[colnames(all_pah_df) == "benzo[e]pyrene" ] <- "benzoepyrene"
colnames(all_pah_df)[colnames(all_pah_df) == "benzo[ghi]perylene" ] <- "benzoghiperylene"
colnames(all_pah_df)[colnames(all_pah_df) == "benzo[k]fluoranthene" ] <- "benzokfluoranthene"
colnames(all_pah_df)[colnames(all_pah_df) == "dibenz[a,h]anthracene" ] <- "dibenzahanthracene"
colnames(all_pah_df)[colnames(all_pah_df) == "indeno[1,2,3-cd]pyrene" ] <- "indeno123cdpyrene"
colnames(all_pah_df)[colnames(all_pah_df) == "C1-benzanthracene/schrysenes" ] <- "C1benzanthraceneschrysenes"
colnames(all_pah_df)[colnames(all_pah_df) == "C1-dibenzothiophenes" ] <- "C1dibenzothiophenes"
colnames(all_pah_df)[colnames(all_pah_df) == "C1-fluoranthenes/pyrenes" ] <- "C1fluoranthenespyrenes"
colnames(all_pah_df)[colnames(all_pah_df) == "C1-fluorenes" ] <- "C1fluorenes"
colnames(all_pah_df)[colnames(all_pah_df) == "C1-naphthalenes" ] <- "C1naphthalenes"
colnames(all_pah_df)[colnames(all_pah_df) == "C1-phenanthrenes/anthracenes" ] <- "C1phenanthrenesanthracenes"
colnames(all_pah_df)[colnames(all_pah_df) == "C2-benzanthracenes/chrysenes" ] <- "C2benzanthraceneschrysenes"
colnames(all_pah_df)[colnames(all_pah_df) == "C2-dibenzothiophenes" ] <- "C2dibenzothiophenes"
colnames(all_pah_df)[colnames(all_pah_df) == "C2-fluoranthenes/pyrenes" ] <- "C2fluoranthenespyrenes"
colnames(all_pah_df)[colnames(all_pah_df) == "C2-fluorenes" ] <- "C2fluorenes"
colnames(all_pah_df)[colnames(all_pah_df) == "C2-naphthalenes" ] <- "C2naphthalenes"
colnames(all_pah_df)[colnames(all_pah_df) == "C2-phenanthrenes/anthracenes" ] <- "C2phenanthrenesanthracenes"
colnames(all_pah_df)[colnames(all_pah_df) == "C3-benzanthracenes/chrysenes" ] <- "C3benzanthraceneschrysenes"
colnames(all_pah_df)[colnames(all_pah_df) == "C3-dibenzothiophenes" ] <- "C3dibenzothiophenes"
colnames(all_pah_df)[colnames(all_pah_df) == "C3-fluoranthenes/pyrenes" ] <- "C3fluoranthenespyrenes"
colnames(all_pah_df)[colnames(all_pah_df) == "C3-fluorenes" ] <- "C3fluorenes"
colnames(all_pah_df)[colnames(all_pah_df) == "C3-naphthalenes" ] <- "C3naphthalenes"
colnames(all_pah_df)[colnames(all_pah_df) == "C3-phenanthrenes/anthracenes" ] <- "C3phenanthrenesanthracenes"
colnames(all_pah_df)[colnames(all_pah_df) == "C4-benzanthracenes/chrysenes" ] <- "C4benzanthraceneschrysenes"
colnames(all_pah_df)[colnames(all_pah_df) == "C4-dibenzothiophenes" ] <- "C4dibenzothiophenes"
colnames(all_pah_df)[colnames(all_pah_df) == "C4-fluoranthenes/pyrenes" ] <- "C4fluoranthenespyrenes"
colnames(all_pah_df)[colnames(all_pah_df) == "C4-naphthalenes" ] <- "C4naphthalenes"
colnames(all_pah_df)[colnames(all_pah_df) == "C4-phenanthrenes/anthracenes" ] <- "C4phenanthrenesanthracenes" 

```



```{r}

ggplot(data = washington_map) + 
  geom_sf(fill = "lightgrey", color = "white") +
  geom_point(data = long_data, aes(x = longitude, y = latitude, color = value, shape = type), alpha = 0.6, size = 2) +
  scale_color_viridis(name = "value", option = "C") +
  scale_shape_manual(values = c("SOD" = 16, "p450" = 17)) + # 16: dot, 17: triangle
  theme_minimal() +
  labs(title = "Washington State: SOD & p450")

```

# Mapping with Leaflet instead of ggplot; this is interactive and not helpful
```{r}

if(!require(leaflet)) install.packages("leaflet")
library(leaflet)

leaflet(data) %>% addTiles() %>%
  addCircles(lng = ~longitude, lat = ~latitude, color = ~colorBin(c("red", "yellow", "green"), p450, bins = 3), radius = 500) %>%
  addCircles(lng = ~longitude, lat = ~latitude, color = ~colorBin(c("blue", "white", "black"), SOD, bins = 3), radius = 200)

```

# Mapping with Plotly, also interactive and plotted on a grid that I don't understand
```{r}
if(!require(plotly)) install.packages("plotly")
library(plotly)

# Assuming data is your dataframe with lat, lon, p450, and SOD columns
fig <- plot_ly() %>%
  add_trace(data = data, x = ~longitude, y = ~latitude, type = 'scatter', mode = 'markers',
            marker = list(size = 10, color = ~p450, colorscale = 'Viridis', showscale = TRUE)) %>%
  add_trace(data = data, x = ~longitude, y = ~latitude, type = 'scatter', mode = 'markers',
            marker = list(size = 10, color = ~SOD, colorscale = 'Cividis', showscale = TRUE))

fig

```

## PPM model, 2 of 2

### Interpretation- I need to dig further to see what this means, I am following a GIS/ Geospatial tutorial and wanted to be able to make the process work.

```{r}

# Fit a point process model
ppm_model <- ppm(sites_pp ~ p450)
summary(ppm_model)


#option 2
#sites_pp$marks <- as.factor(cut(sites_pp$marks$p450, breaks = quantile(sites_pp$marks$p450, probs = 0:3/3), include.lowest = TRUE))

# Now run the ppm model
#ppm_model <- ppm(sites_pp ~ marks, covariates = NULL)
#print(summary(ppm_model))

```

# Spatial Autocorrelation Analysis

```{r}
#Load packages & prep dataframe for "sf" package
#install.packages(spdep)
#install.packages("/Users/cmantegna/Downloads/spdep_1.2-8.tar.gz", repos = NULL, type = "source")
library(sf)
library(sp)
library(spdep)

sf_data <- st_as_sf(bdata, coords = c("longitude", "latitude"), crs = 4326)

# Take a look at your sf object
print(sf_data)

```

```{r}

# Create a spatial weights matrix to assess nearest neighbors and distance-based neighbors to define spatial relationships using Moran's I and Geary's C.
# You can extract the matrix of coordinates using st_coordinates
coords <- st_coordinates(sf_data)

# Now use the knearneigh function from the spdep package directly on the coordinates
neighbors <- knn2nb(knearneigh(coords, k = 4))

# Then convert the neighbors into spatial weights with nb2listw
weights <- nb2listw(neighbors, style = "W")

```

#### Moran I and Geary's C statistical analyses tests if we can cluster or not- cluster sites based on the if the distribution of biomarker values is random or non-random. This helps clarify any biomarker patterns that are unclear by visual analysis - at least to me. If it's unclear to me, I assume it will be unclear to those with less familiarity of the data.

## Run Moran's I and Geary's C for p450

```{r}

coords <- st_coordinates(sf_data)

# Now use the knearneigh function from the spdep package directly on the coordinates
neighbors <- knn2nb(knearneigh(coords, k = 4))

# Then convert the neighbors into spatial weights with nb2listw
weights <- nb2listw(neighbors, style = "W")

geary_result <- geary.test(sf_data$p450, weights)
print(geary_result)

```

## Run Moran's I and Geary's C for SOD

```{r}

moran_result <- moran.test(sf_data$SOD, weights)
print(moran_result)

geary_result <- geary.test(sf_data$SOD, weights)
print(geary_result)

```

# Spatial Regression Analysis

```{r}
#library(spdep)
#install.packages("sphet")
library(sphet)

```

## Spatial Lag Model
```{r}
library(spatialreg)
#accounts for spatial dependence in the dependent variable
slm_model <- lagsarlm(p450 ~ SOD, data = sf_data, listw = weights)
print(summary(slm_model))

```
## Spatial Error Model
```{r}
#accounts for the spatial autocorrelation in the error term
sem_model <- errorsarlm(p450 ~ SOD, data = sf_data, listw = weights)
print(summary(sem_model))


```
## Spatial Durbin Model
```{r}
#install.packages("spatialreg")
library(spatialreg)

#combines SLM and SEM
sdm_model <- spatialreg::lagsarlm(p450 ~ SOD, data = sf_data, listw = weights, type="mixed")
print(summary(sdm_model))

```
# Local Indicator of Spatial Association (LISA)
```{r}
#install.packages("spdep")
#install.packages("sf")  # for spatial data handling
#install.packages("tmap")  # for visualization
library(spdep)
library(sf)
library(tmap)

```

```{r}

lisa_values <- localmoran(sf_data$p450, weights)

```

```{r}

# Add LISA values and p-values to your spatial data
sf_data$lisa <- lisa_values[,1]  # Local Moran's I values
sf_data$p.value <- lisa_values[,4]  # p-values for significance

# Use tmap for plotting
library(tmap)

# Define breaks for significance levels, e.g., 0.05 for 95% confidence
sig_breaks <- c(0, 0.05, 1)  # Change according to your significance level

# Create a map
tm_shape(sf_data) +
  tm_dots(col = "lisa", size = 0.5, palette = "-RdBu", title = "LISA Values") +
  tm_layout(legend.position = c("left", "top")) +
  tm_shape(sf_data[sf_data$p.value <= 0.05, ]) +  # Add a layer for significant points only
  tm_dots(col = "red", size = 0.7, title = "Significant Clusters") +
  tm_layout(main.title = "LISA Cluster Map", main.title.position = "center")

```

# Plot the LISA data over the map from the base Washington State map found in file: 03-map.rmd
```{r}
library(sf)
library(viridis)
library(rnaturalearth)
library(rnaturalearthdata)
library(ggplot2)

```

```{r}

world <- ne_states(country = "united states of america", returnclass = "sf")
washington_map <- world[world$name == "Washington", ]

pmap <- ggplot() + 
  geom_sf(data = washington_map, fill = "lightgrey", color = "white") +
  theme_minimal() +
  labs(title = "Washington State Map")

print(pmap)

```


```{r}
# Ensure CRS compatibility
sf_data <- st_transform(sf_data, st_crs(washington_map))

# Prepare the base map
pmap <- ggplot() + 
  geom_sf(data = washington_map, fill = "lightgrey", color = "white") +
  theme_minimal() +
  labs(title = "Washington State Map")

# Add the LISA points layer to the map
complete_map <- pmap + 
  geom_sf(data = sf_data, aes(color = lisa), size = 2) +
  scale_color_viridis_c(option = "D", direction = -1, name = "LISA Values")

# Display the combined map
print(complete_map)

```

```{r}
#zoom in on the puget sound region
# Assuming you know the bounding box coordinates you want to zoom in on
# For example: xmin, xmax, ymin, ymax
xlim <- c(-124, -122)  # longitude bounds
ylim <- c(47, 49)  # latitude bounds

complete_map <- pmap + 
  geom_sf(data = sf_data, aes(color = lisa), size = 2) +
  scale_color_viridis_c(option = "D", direction = -1, name = "LISA Values") +
  coord_sf(xlim = xlim, ylim = ylim, expand = FALSE)

print(complete_map)


```

# Next steps are completing the interpretations and then using this same code path to review the PAH analytes

# Point pattern analysis

#### Exploratory data analysis tool that looks to interpret the distribution of my values across geographic space - this is the first step in geospatial analysis, the Moran and Geary C statistical tests are what follow to support or debate the hypothesis formed from this step.

```{r}
#install.packages("spatstat")
library(spatstat)

#pull out lat, long, site_name, and biomarkers as a dataframe for the following work.

select <- c("latitude", "longitude", "site_name", "p450", "SOD", "condition_factor", "avg_thickness")

# Create a new data frame with only the specified columns
bdata <- data[,select]

# Create the kind of data frame that works in spatstat package
sites_pp <- ppp(x = bdata$longitude, y = bdata$latitude, 
                window = owin(xrange = range(bdata$longitude), 
                              yrange = range(bdata$latitude)))

```

```{r}
#Add biomarker layer to the geographical data
sites_pp$marks <- data.frame(p450 = bdata$p450, 
                             SOD = bdata$SOD)

```

### Two different ways to analyze any spatial clustering

## K test, 1 of 2

### Interpretation- the clustering of the black, red, and green lines (isotropic, and two transformations) lie significanlty above the blue line, the Poisson distribution line. This means that the biomarker data is more clustered than random. The proximity of the black, red and green lines show agreement across the isotropic and transformation analyses.

```{r}

K_result <- Kest(sites_pp)
print(plot(K_result))

```

# shapiro- wilkes test for normality
```{r}
#shapiro.test(apdata$sumPAH)
#shapiro.test(apdata$lmwPAH)
#shapiro.test(apdata$hmwPAH)
#shapiro.test(apdata$PAH16)
#shapiro.test(apdata$sumPCB)
#shapiro.test(apdata$mercury)
#shapiro.test(apdata$arsenic)
#shapiro.test(apdata$cadmium)
#shapiro.test(apdata$copper)
#shapiro.test(apdata$lead)
#shapiro.test(apdata$zinc)
```

