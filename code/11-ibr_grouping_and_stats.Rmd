---
title: "11- Creating Analysis Groups and Running Stats"
output:
  pdf_document: 
    fig_width: 20
    fig_height: 9
  html_document: 
    toc: true
    toc_float:
        collapsed: false
        smooth_scroll: true
    fig_width: 20
---

# Directory and doc rules

```{r, setup, eval=TRUE, include=TRUE, echo=FALSE}

# libraries
library(knitr) # output fotmatting
library(tidyr) # data wrangling
library(tidyverse) # data wrangling
library(dplyr) # data wrangling
library(vegan) # ecological stats 
library(cluster) # grouping metrics - VERIFY still needed
library(pgirmess) # stats - KW
library(ggplot2) # plots
library(factoextra) # pca/ nmds/ tweaking radars
library(FactoMineR) # pca/ nmds/ tweaking radars
library(FSA) # post hoc test - Dunn's Test       
library(rstatix) # VERIFY what this is for      
library(car) # VERIFY what this is for  
library(RVAideMemoire) # post hoc test for permanova
library(rcompanion) # for annotation of permanova
library(scales) # scaling data for IBR - works with data wrangling packages
library(fmsb) # polygon calculations for the radars
library(devtools)

knitr::opts_chunk$set(
  root.dir = here::here(),
  echo = TRUE,         # show code chunks
  eval = TRUE,         # evaluate code chunks
  warning = FALSE,     # hide warnings
  message = FALSE,     # hide messages
  #fig.width = 15,       # set plot width in inches
  #fig.height = 9,      # set plot height in inches
  fig.align = "center" # slign plots to the center in output doc/ slide/ whatever
)

```

# Load & Check Data
```{r}

getwd()
#setwd("/Users/cmantegna/Documents/GitHub/WDFWmussels") # something here isn't working right - check out why

df1<- read.csv("../data/cleaned/ibr_1.csv") # penn cove reference site only
df2<- read.csv("../data/cleaned/ibr_2.csv")
#df3<- read.csv("../data/cleaned/ibr_3.csv")
df4<- read.csv("../data/cleaned/analytes_long.csv")
#df5<- read.csv("../data/cleaned/metals_long.csv")
df6<- read.csv("../data/cleaned/avg_ibr1_metals.csv")

# clean up names if needed
#df1 <- df1 %>%
#  mutate(across(where(is.character), trimws))


```

```{r}

# make categorical columns factors
df1$site_number <- as.factor(df1$site_number)
df1$sample_id <- as.factor(df1$sample_id)
df1$reporting_area <- as.factor(df1$reporting_area)

```

# Normality - Shapiro-Wilkes
```{r}

shapiro.test(df1$p450) # Not Normal
shapiro.test(df1$sod) # Not Normal
shapiro.test(df1$shell) # Normal - ANOVA for this one
shapiro.test(df1$ci1) # Not Normal
shapiro.test(df1$ci2) # Not Normal
shapiro.test(df1$ci3) # Not Normal
shapiro.test(df1$ibr1bio) # Not Normal
shapiro.test(df1$ibr1morph) # Not Normal
shapiro.test(df1$ibr1overall) # Not Normal

```

# Add groups to match WDFW reporting style
Groups
1. Biomarker- driven grouping - K-means clustering
2. Impervious Surface Percentage (0-10, 10-20, 20-40, 40-100)
3. Concentration Thresholds by contaminant - sketch this out to see if this is something I really need
4. Quantiles - same comment as above

## Create biomarker- driven grouping
### DO NOT rerun
```{r}

# Use only rows with non-missing biomarker data
bio_clust_df <- df1 %>%
  select(sample_id, p450, sod)

wss <- vector()

# Try values of k from 1 to 10
for (k in 1:10) {
  set.seed(42)
  wss[k] <- kmeans(bio_clust_df, centers = k, nstart = 25)$tot.withinss
}

# Plot the elbow
plot(1:10, wss, type = "b",
     pch = 19, frame = FALSE,
     xlab = "Number of clusters (k)",
     ylab = "Total within-cluster sum of squares",
     main = "Elbow Method for Choosing k")

set.seed(42)
k_opt <- 3  # elbow is distinctly at 2 with 3 close by, I have checked both with no real resolution

kmeans_result <- kmeans(bio_clust_df, centers = k_opt, nstart = 25)

# Add cluster assignment to your working df
bio_clust_df$cluster3 <- as.factor(kmeans_result$cluster)

df1 <- df1 %>%
  left_join(bio_clust_df[, c("sample_id", "cluster3")], by = "sample_id")

# saving ibrv2i df
#write.csv(ibrv2i_df, "/Users/cmantegna/Documents/GitHub/WDFWmussels/data/cleaned/ibrv2i_all_scaled_indices_groups.csv", row.names = FALSE)

```

## PCA plot to check clusters
```{r}

# Define variables for PCA
pca_vars <- c("p450", "sod", "shell", "ci1")

# Remove rows with any NA in the selected variables
pca_df <- df1 %>%
  filter(if_all(all_of(pca_vars), ~ !is.na(.))) %>%
  select(sample_id, cluster3, all_of(pca_vars))

# Keep only the scaled numeric matrix for PCA
pca_matrix <- pca_df %>%
  select(all_of(pca_vars)) %>%
  as.matrix()

pca_res <- prcomp(pca_matrix, center = TRUE, scale. = FALSE)  # already scaled relative to reference

# Create a scores dataframe
scores_df <- as.data.frame(pca_res$x)
scores_df$sample_id <- pca_df$sample_id
scores_df$cluster3 <- pca_df$cluster3

# Plot the first two PCs
ggplot(scores_df, aes(x = PC1, y = PC2, color = cluster3)) +
  geom_point(size = 3, alpha = 0.8) +
  labs(title = "PCA of Scaled Biomarkers + Morphometrics",
       x = paste0("PC1 (", round(summary(pca_res)$importance[2, 1] * 100, 1), "% variance)"),
       y = paste0("PC2 (", round(summary(pca_res)$importance[2, 2] * 100, 1), "% variance)"),
       color = "Cluster") +
  theme_minimal() +
  theme(legend.position = "right")

```

# KW + post hoc
```{r}

#KW
kruskal.test(p450 ~ site_name, data = df1) # p-value = 4.219e-06
kruskal.test(p450 ~ reporting_area, data = df1) # p-value = 4.09e-05

kruskal.test(sod ~ site_name, data = df1) # p-value = 0.002259
kruskal.test(sod ~ reporting_area, data = df1) # p-value = 0.3136

kruskal.test(ci1 ~ site_name, data = df1) # p-value = 0.0006876
kruskal.test(ci1 ~ reporting_area, data = df1) # p-value = 0.7855

kruskal.test(ci2 ~ site_name, data = df1) # p-value = 3.173e-08
kruskal.test(ci2 ~ reporting_area, data = df1) # p-value = 0.3396

kruskal.test(ci3 ~ site_name, data = df1) # p-value = 0.0001327
kruskal.test(ci3 ~ reporting_area, data = df1) # p-value = 0.02201

kruskal.test(ibr1bio ~ site_name, data = df1) # p-value = 0.002612
kruskal.test(ibr1bio ~ reporting_area, data = df1) # p-value = 0.0001853

kruskal.test(ibr1morph ~ site_name, data = df1) # p-value = 0.08877
kruskal.test(ibr1morph ~ reporting_area, data = df1) # p-value = 0.02514

kruskal.test(ibr1overall ~ site_name, data = df1) # p-value = 0.0134
kruskal.test(ibr1overall ~ reporting_area, data = df1) # p-value = 0.001949

```
## p450
```{r}

#p450 - site is not significant
dunn_result <- dunnTest(p450 ~ site_name, data = df1, method = "bh") 
dunn_df <- dunn_result$res %>%
  dplyr::select(Comparison, Z, P.unadj, P.adj) %>%
  tidyr::separate(Comparison, into = c("Group1", "Group2"), sep = " - ") %>%
  dplyr::mutate(Significant = ifelse(P.adj < 0.05, "Yes", "No"))

dunn_table <- dunn_df %>%
  dplyr::mutate(across(c(P.unadj, P.adj), round, digits = 4)) %>%
  dplyr::arrange(P.adj)

print(dunn_table) # view
write.csv(dunn_table, "/Users/cmantegna/Documents/Github/WDFWmussels/output/p450site.csv", row.names = FALSE) # write it out

#p450 - reporting area is significant
dunn_result <- dunnTest(p450 ~ reporting_area, data = df1, method = "bh") 
dunn_df <- dunn_result$res %>%
  dplyr::select(Comparison, Z, P.unadj, P.adj) %>%
  tidyr::separate(Comparison, into = c("Group1", "Group2"), sep = " - ") %>%
  dplyr::mutate(Significant = ifelse(P.adj < 0.05, "Yes", "No"))

dunn_table <- dunn_df %>%
  dplyr::mutate(across(c(P.unadj, P.adj), round, digits = 4)) %>%
  dplyr::arrange(P.adj)

print(dunn_table) # view
#write.csv(dunn_table_with_cld, "/Users/cmantegna/Documents/Github/WDFWmussels/output/p450ra.csv", row.names = FALSE) # write it out

groups <- unique(c(dunn_df$Group1, dunn_df$Group2))

pval_matrix <- matrix(1, nrow = length(groups), ncol = length(groups),
                      dimnames = list(groups, groups))

for (i in 1:nrow(dunn_df)) {
  g1 <- dunn_df$Group1[i]
  g2 <- dunn_df$Group2[i]
  p <- dunn_df$P.adj[i]
  pval_matrix[g1, g2] <- p
  pval_matrix[g2, g1] <- p
}

cld_letters <- multcompLetters(pval_matrix < 0.05)$Letters
cld_df <- data.frame(
  Group = names(cld_letters),
  CLD = cld_letters,
  stringsAsFactors = FALSE
)

dunn_table_with_cld <- dunn_table %>%
  left_join(cld_df, by = c("Group1" = "Group")) %>%
  rename(Group1_CLD = CLD) %>%
  left_join(cld_df, by = c("Group2" = "Group")) %>%
  rename(Group2_CLD = CLD)

```

## sod
```{r}

#sod - site is not significant
dunn_result <- dunnTest(sod ~ site_name, data = df1, method = "bh") 
dunn_df <- dunn_result$res %>%
  dplyr::select(Comparison, Z, P.unadj, P.adj) %>%
  tidyr::separate(Comparison, into = c("Group1", "Group2"), sep = " - ") %>%
  dplyr::mutate(Significant = ifelse(P.adj < 0.05, "Yes", "No"))

dunn_table <- dunn_df %>%
  dplyr::mutate(across(c(P.unadj, P.adj), round, digits = 4)) %>%
  dplyr::arrange(P.adj)

print(dunn_table) # view
#write.csv(dunn_table, "/Users/cmantegna/Documents/Github/WDFWmussels/output/sodsite.csv", row.names = FALSE) # write it out

```

## ci1
```{r}

#ci1 - site is significant
dunn_result <- dunnTest(ci1 ~ site_name, data = df1, method = "bh") 
dunn_df <- dunn_result$res %>%
  dplyr::select(Comparison, Z, P.unadj, P.adj) %>%
  tidyr::separate(Comparison, into = c("Group1", "Group2"), sep = " - ") %>%
  dplyr::mutate(Significant = ifelse(P.adj < 0.05, "Yes", "No"))

dunn_table <- dunn_df %>%
  dplyr::mutate(across(c(P.unadj, P.adj), round, digits = 4)) %>%
  dplyr::arrange(P.adj)

print(dunn_table) # view
write.csv(dunn_table, "/Users/cmantegna/Documents/Github/WDFWmussels/output/ci1site.csv", row.names = FALSE) # write it out

```

## ci2
```{r}

#ci2 - site is not significant
dunn_result <- dunnTest(ci2 ~ site_name, data = df1, method = "bh") 
dunn_df <- dunn_result$res %>%
  dplyr::select(Comparison, Z, P.unadj, P.adj) %>%
  tidyr::separate(Comparison, into = c("Group1", "Group2"), sep = " - ") %>%
  dplyr::mutate(Significant = ifelse(P.adj < 0.05, "Yes", "No"))

dunn_table <- dunn_df %>%
  dplyr::mutate(across(c(P.unadj, P.adj), round, digits = 4)) %>%
  dplyr::arrange(P.adj)

print(dunn_table) # view
#write.csv(dunn_table, "/Users/cmantegna/Documents/Github/WDFWmussels/output/sodsite.csv", row.names = FALSE) # write it out


```

## ci3
```{r}

#ci3 - site is not significant
dunn_result <- dunnTest(ci3 ~ site_name, data = df1, method = "bh") 
dunn_df <- dunn_result$res %>%
  dplyr::select(Comparison, Z, P.unadj, P.adj) %>%
  tidyr::separate(Comparison, into = c("Group1", "Group2"), sep = " - ") %>%
  dplyr::mutate(Significant = ifelse(P.adj < 0.05, "Yes", "No"))

dunn_table <- dunn_df %>%
  dplyr::mutate(across(c(P.unadj, P.adj), round, digits = 4)) %>%
  dplyr::arrange(P.adj)

print(dunn_table) # view
#write.csv(dunn_table, "/Users/cmantegna/Documents/Github/WDFWmussels/output/sodsite.csv", row.names = FALSE) # write it out

#ci3 - reporting area is significant
dunn_result <- dunnTest(ci3 ~ reporting_area, data = df1, method = "bh") 
dunn_df <- dunn_result$res %>%
  dplyr::select(Comparison, Z, P.unadj, P.adj) %>%
  tidyr::separate(Comparison, into = c("Group1", "Group2"), sep = " - ") %>%
  dplyr::mutate(Significant = ifelse(P.adj < 0.05, "Yes", "No"))

dunn_table <- dunn_df %>%
  dplyr::mutate(across(c(P.unadj, P.adj), round, digits = 4)) %>%
  dplyr::arrange(P.adj)

print(dunn_table) # view

groups <- unique(c(dunn_df$Group1, dunn_df$Group2)) # add letter designation

pval_matrix <- matrix(1, nrow = length(groups), ncol = length(groups),
                      dimnames = list(groups, groups))

for (i in 1:nrow(dunn_df)) {
  g1 <- dunn_df$Group1[i]
  g2 <- dunn_df$Group2[i]
  p <- dunn_df$P.adj[i]
  pval_matrix[g1, g2] <- p
  pval_matrix[g2, g1] <- p
}

cld_letters <- multcompLetters(pval_matrix < 0.05)$Letters
cld_df <- data.frame(
  Group = names(cld_letters),
  CLD = cld_letters,
  stringsAsFactors = FALSE
)

dunn_table_with_cld <- dunn_table %>%
  left_join(cld_df, by = c("Group1" = "Group")) %>%
  rename(Group1_CLD = CLD) %>%
  left_join(cld_df, by = c("Group2" = "Group")) %>%
  rename(Group2_CLD = CLD)

#write.csv(dunn_table_with_cld, "/Users/cmantegna/Documents/Github/WDFWmussels/output/ci3ra.csv", row.names = FALSE) # write it out
```

## ibr_bio both
```{r}

#ibrbio - site is not significant
dunn_result <- dunnTest(ibr1bio ~ site_name, data = df1, method = "bh") 
dunn_df <- dunn_result$res %>%
  dplyr::select(Comparison, Z, P.unadj, P.adj) %>%
  tidyr::separate(Comparison, into = c("Group1", "Group2"), sep = " - ") %>%
  dplyr::mutate(Significant = ifelse(P.adj < 0.05, "Yes", "No"))

dunn_table <- dunn_df %>%
  dplyr::mutate(across(c(P.unadj, P.adj), round, digits = 4)) %>%
  dplyr::arrange(P.adj)

print(dunn_table) # view
#write.csv(dunn_table, "/Users/cmantegna/Documents/Github/WDFWmussels/output/sodsite.csv", row.names = FALSE) # write it out

#ibrbio - reporting area is significant
dunn_result <- dunnTest(ibr1bio ~ reporting_area, data = df1, method = "bh") 
dunn_df <- dunn_result$res %>%
  dplyr::select(Comparison, Z, P.unadj, P.adj) %>%
  tidyr::separate(Comparison, into = c("Group1", "Group2"), sep = " - ") %>%
  dplyr::mutate(Significant = ifelse(P.adj < 0.05, "Yes", "No"))

dunn_table <- dunn_df %>%
  dplyr::mutate(across(c(P.unadj, P.adj), round, digits = 4)) %>%
  dplyr::arrange(P.adj)

print(dunn_table) # view

groups <- unique(c(dunn_df$Group1, dunn_df$Group2)) # add letters

pval_matrix <- matrix(1, nrow = length(groups), ncol = length(groups),
                      dimnames = list(groups, groups))

for (i in 1:nrow(dunn_df)) {
  g1 <- dunn_df$Group1[i]
  g2 <- dunn_df$Group2[i]
  p <- dunn_df$P.adj[i]
  pval_matrix[g1, g2] <- p
  pval_matrix[g2, g1] <- p
}

cld_letters <- multcompLetters(pval_matrix < 0.05)$Letters
cld_df <- data.frame(
  Group = names(cld_letters),
  CLD = cld_letters,
  stringsAsFactors = FALSE
)

dunn_table_with_cld <- dunn_table %>%
  left_join(cld_df, by = c("Group1" = "Group")) %>%
  rename(Group1_CLD = CLD) %>%
  left_join(cld_df, by = c("Group2" = "Group")) %>%
  rename(Group2_CLD = CLD)

#write.csv(dunn_table_with_cld, "/Users/cmantegna/Documents/Github/WDFWmussels/output/ibr1biora.csv", row.names = FALSE) # write it out

```

## ibr_morph reporting area
```{r}

#ibrmorph - reporting area
dunn_result <- dunnTest(ibr1morph ~ reporting_area, data = df1, method = "bh") 
dunn_df <- dunn_result$res %>%
  dplyr::select(Comparison, Z, P.unadj, P.adj) %>%
  tidyr::separate(Comparison, into = c("Group1", "Group2"), sep = " - ") %>%
  dplyr::mutate(Significant = ifelse(P.adj < 0.05, "Yes", "No"))

dunn_table <- dunn_df %>%
  dplyr::mutate(across(c(P.unadj, P.adj), round, digits = 4)) %>%
  dplyr::arrange(P.adj)

print(dunn_table) # view

groups <- unique(c(dunn_df$Group1, dunn_df$Group2)) # add letters

pval_matrix <- matrix(1, nrow = length(groups), ncol = length(groups),
                      dimnames = list(groups, groups))

for (i in 1:nrow(dunn_df)) {
  g1 <- dunn_df$Group1[i]
  g2 <- dunn_df$Group2[i]
  p <- dunn_df$P.adj[i]
  pval_matrix[g1, g2] <- p
  pval_matrix[g2, g1] <- p
}

cld_letters <- multcompLetters(pval_matrix < 0.05)$Letters
cld_df <- data.frame(
  Group = names(cld_letters),
  CLD = cld_letters,
  stringsAsFactors = FALSE
)

dunn_table_with_cld <- dunn_table %>%
  left_join(cld_df, by = c("Group1" = "Group")) %>%
  rename(Group1_CLD = CLD) %>%
  left_join(cld_df, by = c("Group2" = "Group")) %>%
  rename(Group2_CLD = CLD)

write.csv(dunn_table_with_cld, "/Users/cmantegna/Documents/Github/WDFWmussels/output/morphra.csv", row.names = FALSE) # write it out

```

## ibr_overall both
```{r}

#ibroverall - site
dunn_result <- dunnTest(ibr1overall ~ site_name, data = df1, method = "bh") 
dunn_df <- dunn_result$res %>%
  dplyr::select(Comparison, Z, P.unadj, P.adj) %>%
  tidyr::separate(Comparison, into = c("Group1", "Group2"), sep = " - ") %>%
  dplyr::mutate(Significant = ifelse(P.adj < 0.05, "Yes", "No"))

dunn_table <- dunn_df %>%
  dplyr::mutate(across(c(P.unadj, P.adj), round, digits = 4)) %>%
  dplyr::arrange(P.adj)

print(dunn_table) # view
#write.csv(dunn_table, "/Users/cmantegna/Documents/Github/WDFWmussels/output/sodsite.csv", row.names = FALSE) # write it out

dunn_result <- dunnTest(ibr1overall ~ reporting_area, data = df1, method = "bh") 
dunn_df <- dunn_result$res %>%
  dplyr::select(Comparison, Z, P.unadj, P.adj) %>%
  tidyr::separate(Comparison, into = c("Group1", "Group2"), sep = " - ") %>%
  dplyr::mutate(Significant = ifelse(P.adj < 0.05, "Yes", "No"))

dunn_table <- dunn_df %>%
  dplyr::mutate(across(c(P.unadj, P.adj), round, digits = 4)) %>%
  dplyr::arrange(P.adj)

print(dunn_table) # view

groups <- unique(c(dunn_df$Group1, dunn_df$Group2)) # add letters

pval_matrix <- matrix(1, nrow = length(groups), ncol = length(groups),
                      dimnames = list(groups, groups))

for (i in 1:nrow(dunn_df)) {
  g1 <- dunn_df$Group1[i]
  g2 <- dunn_df$Group2[i]
  p <- dunn_df$P.adj[i]
  pval_matrix[g1, g2] <- p
  pval_matrix[g2, g1] <- p
}

cld_letters <- multcompLetters(pval_matrix < 0.05)$Letters
cld_df <- data.frame(
  Group = names(cld_letters),
  CLD = cld_letters,
  stringsAsFactors = FALSE
)

dunn_table_with_cld <- dunn_table %>%
  left_join(cld_df, by = c("Group1" = "Group")) %>%
  rename(Group1_CLD = CLD) %>%
  left_join(cld_df, by = c("Group2" = "Group")) %>%
  rename(Group2_CLD = CLD)

#write.csv(dunn_table_with_cld, "/Users/cmantegna/Documents/Github/WDFWmussels/output/ibroverallra.csv", row.names = FALSE) # write it out

```

# ANOVA + post hoc
## shell
```{r}

anova_site <- aov(shell ~ site_name, data = df1) # p=5.84e-16 ***
anova_ra <- aov(shell ~ reporting_area, data = df1) # p= 1.09e-06 ***
summary(anova_site)
summary(anova_ra)

#post - site is significant
tukey_site <- TukeyHSD(anova_site, "site_name")
tukey_df <- as.data.frame(tukey_site$site_name)

tukey_df <- tukey_df %>%
  tibble::rownames_to_column("Comparison") %>%
  tidyr::separate(Comparison, into = c("Group1", "Group2"), sep = "-") %>%
  rename(Diff = diff, Lower = lwr, Upper = upr, P.adj = `p adj`) %>%
  mutate(across(everything(), ~trimws(as.character(.)))) %>%  
  mutate(Significant = ifelse(P.adj < 0.05, "Yes", "No"))

groups <- unique(c(tukey_df$Group1, tukey_df$Group2))
pval_matrix <- matrix(1, nrow = length(groups), ncol = length(groups),
                      dimnames = list(groups, groups))

for (i in 1:nrow(tukey_df)) {
  g1 <- tukey_df$Group1[i]
  g2 <- tukey_df$Group2[i]
  pval <- as.numeric(tukey_df$P.adj[i])
  pval_matrix[g1, g2] <- pval
  pval_matrix[g2, g1] <- pval
}

cld_letters <- multcompLetters(pval_matrix < 0.05)$Letters

cld_df <- data.frame(
  Group = names(cld_letters),
  CLD = cld_letters,
  stringsAsFactors = FALSE
)

tukey_table_with_cld <- tukey_df %>%
  left_join(cld_df, by = c("Group1" = "Group")) %>%
  rename(Group1_CLD = CLD) %>%
  left_join(cld_df, by = c("Group2" = "Group")) %>%
  rename(Group2_CLD = CLD)

view(tukey_table_with_cld) #view
write.csv(tukey_table_with_cld, "/Users/cmantegna/Documents/Github/WDFWmussels/output/shellsite.csv", row.names = FALSE) #save

#post - reporting area
tukey_ra <- TukeyHSD(anova_ra, "reporting_area")
tukey_df <- as.data.frame(tukey_ra$reporting_area)

tukey_df <- tukey_df %>%
  tibble::rownames_to_column("Comparison") %>%
  tidyr::separate(Comparison, into = c("Group1", "Group2"), sep = "-") %>%
  rename(Diff = diff, Lower = lwr, Upper = upr, P.adj = `p adj`) %>%
  mutate(across(everything(), ~trimws(as.character(.)))) %>%  
  mutate(Significant = ifelse(P.adj < 0.05, "Yes", "No"))

groups <- unique(c(tukey_df$Group1, tukey_df$Group2))
pval_matrix <- matrix(1, nrow = length(groups), ncol = length(groups),
                      dimnames = list(groups, groups))

for (i in 1:nrow(tukey_df)) {
  g1 <- tukey_df$Group1[i]
  g2 <- tukey_df$Group2[i]
  pval <- as.numeric(tukey_df$P.adj[i])
  pval_matrix[g1, g2] <- pval
  pval_matrix[g2, g1] <- pval
}

cld_letters <- multcompLetters(pval_matrix < 0.05)$Letters

cld_df <- data.frame(
  Group = names(cld_letters),
  CLD = cld_letters,
  stringsAsFactors = FALSE
)

tukey_table_with_cld <- tukey_df %>%
  left_join(cld_df, by = c("Group1" = "Group")) %>%
  rename(Group1_CLD = CLD) %>%
  left_join(cld_df, by = c("Group2" = "Group")) %>%
  rename(Group2_CLD = CLD)

view(tukey_table_with_cld) #view
write.csv(tukey_table_with_cld, "/Users/cmantegna/Documents/Github/WDFWmussels/output/shellra.csv", row.names = FALSE) #save

```

# NMDS - not useful at all
```{r}

df_metrics <- df1 %>%
  select(p450, sod, shell, ci1, ci2, ci3) %>%
  scale()

nmds <- metaMDS(df_metrics_all[, 1:6], distance = "euclidean", k = 2, trymax = 100)
fit <- envfit(nmds, df_metrics_all[, 1:6], permutations = 999)
plot(nmds)
plot(fit, col = "blue")

nmds$stress #w/o condition indices the stress= 0.1122892, w/ condition the stress= 0.1467835

# trying to scale again
df_metrics_all <- df1 %>%
  select(p450, sod, shell, ci1, ci2, ci3) %>%
  scale() %>%
  as.data.frame()

# Add IDs or sites for reference
df_metrics_all$site_name <- df1$site_name

# Look for rows with extreme values
apply(df_metrics_all, 2, function(x) range(x, na.rm = TRUE))

summary(df_metrics_all)

# Identify rows with extreme scaled values
which(apply(df_metrics_all[, 1:6], 1, function(x) any(abs(x) > 5)))
df_filtered <- df_metrics_all %>%
  filter(apply(select(., -site_name), 1, function(x) all(abs(x) < 5)))

pca <- prcomp(df_metrics_all[, 1:6], center = TRUE, scale. = FALSE)
biplot(pca)


```

# Heatmap - equally unuseful
```{r}

library(pheatmap)

# Make sure data is numeric and scaled
heat_data <- df1 %>%
  select(p450, sod, shell, ci1, ci2, ci3) %>%
  scale()

rownames(heat_data) <- df1$site_name  # optional: use site names as row labels

pheatmap(heat_data,
         clustering_distance_rows = "euclidean",
         clustering_distance_cols = "euclidean",
         clustering_method = "average",
         scale = "none",
         show_rownames = FALSE)

```

# Correlations
## data prep
```{r}

# cleaning up site names and then averaging by site for new df
df1$site_name <- trimws(df1$site_name)
df1 <- df1 %>%
  filter(!is.na(site_name), site_name != "")

df_sites <- df1 %>%
  group_by(site_name, reporting_area) %>% 
  summarise(
    latitude= first(latitude),
    longitude= first(longitude),
    p450 = mean(p450, na.rm = TRUE),
    sod = mean(sod, na.rm = TRUE),
    shell = mean(shell, na.rm = TRUE),
    ci1 = mean(ci1, na.rm = TRUE),
    ci2 = mean(ci2, na.rm = TRUE),
    ci3 = mean(ci3, na.rm = TRUE),
    ibr1bio = mean(ibr1bio, na.rm = TRUE),  # or whatever your IBR column is called
    ibr1morph = mean(ibr1morph, na.rm = TRUE),
    ibr1overall = mean(ibr1overall, na.rm = TRUE),
    n_samples = n()
  ) %>%
  ungroup()

head(df_sites)
#write.csv(df_sites, "/Users/cmantegna/Documents/Github/WDFWmussels/data/cleaned/avg_ibr1.csv", row.names = FALSE)

# pivoting analyte and metal table to match the format of the biomarker table
# remove trailing white spaces from the site names before pivoting
df4$analyte <- as.character(df4$analyte)
df4$analyte <- trimws(df4$analyte)
df4 <- df4 %>%
  filter(!is.na(analyte), analyte != "")

analytes <- df4 %>%
  select(site_name, analyte, dry_value) %>%
  pivot_wider(
    names_from = analyte,
    values_from = dry_value
  )

# join to df1
df1_analytes <- df_sites %>%
  left_join(analytes, by = c("site_name"))

# metals
metals <- df5 %>%
  select(site_name, latitude, longitude, analyte, dry_value) %>%
  pivot_wider(
    names_from = analyte,
    values_from = dry_value
  )

# join to df1
df1_metal <- df_sites %>%
  left_join(metals, by = c("site_name"))

#write.csv(df1_analytes, "/Users/cmantegna/Documents/Github/WDFWmussels/data/cleaned/avg_ibr1_analytess.csv", row.names = FALSE)

```

## metals
```{r}

#df1_metal<- read.csv("../data/cleaned/avg_ibr1_metals.csv")

metrics_vars <- df1_analytes %>%
  select(p450, sod, shell, ci1, ci2, ci3,
         ibr1bio, ibr1morph, ibr1overall)

analyte_vars <- df1_analytes[, 14:ncol(df1_analytes)]

# Create empty list to store results
results_list <- list()

# Loop through all metric–analyte pairs
for (metric in colnames(metrics_vars)) {
  for (analyte in colnames(analyte_vars)) {
    
    # Extract the vectors
    x <- metrics_vars[[metric]]
    y <- analyte_vars[[analyte]]
    
    # Drop NA pairs
    valid_idx <- complete.cases(x, y)
    x_valid <- x[valid_idx]
    y_valid <- y[valid_idx]
    
    # Run Spearman
    spearman <- cor.test(x_valid, y_valid, method = "spearman")
    
    # Run Kendall
    kendall <- cor.test(x_valid, y_valid, method = "kendall")
    
    # Store results
    results_list[[paste(metric, analyte, sep = "_")]] <- data.frame(
      Metric = metric,
      Analyte = analyte,
      Spearman_r = spearman$estimate,
      Spearman_p = spearman$p.value,
      Kendall_tau = kendall$estimate,
      Kendall_p = kendall$p.value
    )
  }
}

library(dplyr)

corr_full <- bind_rows(results_list)

# Optional: Add significance stars
corr_full <- corr_full %>%
  mutate(
    Spearman_sig = case_when(
      Spearman_p <= 0.001 ~ "***",
      Spearman_p <= 0.01  ~ "**",
      Spearman_p <= 0.05  ~ "*",
      TRUE ~ ""
    ),
    Kendall_sig = case_when(
      Kendall_p <= 0.001 ~ "***",
      Kendall_p <= 0.01  ~ "**",
      Kendall_p <= 0.05  ~ "*",
      TRUE ~ ""
    )
  )

View(corr_full)
write.csv(corr_full, "/Users/cmantegna/Documents/Github/WDFWmussels/output/correlation_analytes.csv", row.names = FALSE)

```

## metals
```{r}

#df1_metal<- read.csv("../data/cleaned/avg_ibr1_metals.csv")

metrics_vars <- df1_metal %>%
  select(p450, sod, shell, ci1, ci2, ci3,
         ibr1bio, ibr1morph, ibr1overall)

analyte_vars <- df1_metal[, 14:ncol(df1_metal)]

# Create empty list to store results
results_list <- list()

# Loop through all metric–analyte pairs
for (metric in colnames(metrics_vars)) {
  for (analyte in colnames(analyte_vars)) {
    
    # Extract the vectors
    x <- metrics_vars[[metric]]
    y <- analyte_vars[[analyte]]
    
    # Drop NA pairs
    valid_idx <- complete.cases(x, y)
    x_valid <- x[valid_idx]
    y_valid <- y[valid_idx]
    
    # Run Spearman
    spearman <- cor.test(x_valid, y_valid, method = "spearman")
    
    # Run Kendall
    kendall <- cor.test(x_valid, y_valid, method = "kendall")
    
    # Store results
    results_list[[paste(metric, analyte, sep = "_")]] <- data.frame(
      Metric = metric,
      Analyte = analyte,
      Spearman_r = spearman$estimate,
      Spearman_p = spearman$p.value,
      Kendall_tau = kendall$estimate,
      Kendall_p = kendall$p.value
    )
  }
}

library(dplyr)

corr_full <- bind_rows(results_list)

# Optional: Add significance stars
corr_full <- corr_full %>%
  mutate(
    Spearman_sig = case_when(
      Spearman_p <= 0.001 ~ "***",
      Spearman_p <= 0.01  ~ "**",
      Spearman_p <= 0.05  ~ "*",
      TRUE ~ ""
    ),
    Kendall_sig = case_when(
      Kendall_p <= 0.001 ~ "***",
      Kendall_p <= 0.01  ~ "**",
      Kendall_p <= 0.05  ~ "*",
      TRUE ~ ""
    )
  )

View(corr_full)
#write.csv(corr_full, "/Users/cmantegna/Documents/Github/WDFWmussels/output/correlation_metals.csv", row.names = FALSE)

```

# Run  Correlations +  Kendall's Tau - correlate ibroverall with metrics too
```{r}



```

# Visualization
## NWS Poster viz
```{r}

#map
library(sf)
library(readr)
library(patchwork)
library(viridis)
library(rnaturalearth)
library(ggsignif)

df$reporting_area <- as.factor(df$reporting_area)

# Convert to spatial
sites_sf <- st_as_sf(df, coords = c("longitude", "latitude"), crs = 4326)

coast <- ne_states(country = "united states of america", returnclass = "sf") %>%
  filter(name == "Washington")

# Major city coordinates for labels
cities <- data.frame(
  city = c("Seattle", "Tacoma", "Olympia", "Bellingham", "Port Angeles", "Hama Hama"),
  lon = c(-122.33, -122.45, -122.90, -122.48, -123.43, -123.16),
  lat = c(47.61, 47.25, 47.00, 48.73, 48.08, 47.63)
)

# Define color palette
area_colors <- viridis::viridis(length(levels(df$reporting_area)), option = "turbo")

# Map
map_plot <- ggplot() +
  geom_sf(data = coast, fill = "gray90", color = "white") +
  geom_sf(data = sites_sf, aes(color = reporting_area), size = 3, alpha = 0.9) +
  geom_text(data = cities, aes(x = lon, y = lat, label = city),
            color = "black", fontface = "bold", size = 4) +
  scale_color_manual(values = area_colors, name = "Reporting Area") + 
  coord_sf(xlim = c(-124, -121), ylim = c(46.5, 49.0)) +
  theme_void() +
  labs(title = "Sampled Sites by Reporting Area")

# Filter data for IBRv2i < 5
df_filtered <- df %>% filter(IBRv2i < 5)
df_filtered <- df_filtered %>%
  mutate(is_reference = ifelse(site_name == "Penn Cove Reference", "Reference", "Other"))

# Boxplot
box_plot <- ggplot(df_filtered, aes(x = reporting_area, y = IBRv2i, fill = reporting_area)) +
  geom_boxplot(alpha = 0.8, outlier.shape = NA) +
  geom_jitter(width = 0.2, color = "black", size = 1.5) +
  scale_fill_manual(values = area_colors, guide = "none") + 
  coord_cartesian(ylim = c(-3, 5.5)) +
  geom_signif(comparisons = list(
      c("11", "7"),
      c("13", "7"),
      c("6", "7"),
      c("10", "13")
    ),
    annotations = c("p = 0.0093", "p = 0.0013", "p = 0.0487", "p = 0.0199"),
    y_position = c(5.2, 4.8, 4.5, 4.2),
    tip_length = 0.02,
    textsize = 4.5
  ) +
  theme_minimal(base_size = 13) + 
  theme(
    axis.line = element_line(size = 1.2, color = "black"),
    axis.text = element_text(size= 25, face = "bold"),
    axis.title = element_text(size= 30, face = "bold"),
    plot.title = element_text(hjust = 0.5, face = "bold")
  ) +
  labs(x = "Reporting Area", y = "IBRv2i Score")
  
# Combine
combo_plot <- map_plot + box_plot +
  plot_layout(ncol = 2, widths = c(1.3, 1)) +
  plot_annotation(title = "Integrated Biomarker Response Overview")

# Display
print(map_plot)
print(box_plot)

# Export 
ggsave("/Users/cmantegna/Documents/GitHub/WDFWmussels/output/poster_map.png", map_plot, width = 14, height = 8, dpi = 300)

ggsave("/Users/cmantegna/Documents/GitHub/WDFWmussels/output/poster_box.png", box_plot, width = 14, height = 8, dpi = 300)


```
## KW for plotting
```{r}

# Make sure reporting_area is a factor
df$reporting_area <- as.factor(df$reporting_area)

# Run Kruskal-Wallis test
kruskal_result <- kruskal.test(IBRv2i ~ reporting_area, data = df)
print(kruskal_result)

# Run Dunn's post hoc test
dunn_result <- dunnTest(IBRv2i ~ reporting_area, data = df, method = "holm")
print(dunn_result)


```



PCA/ NMDS
Correlation heatmaps
```{r}

```

