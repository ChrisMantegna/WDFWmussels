---
title: "3.2- Data Analysis with transformed and scaled metrics, IBRs and contaminant indices"
output:
  pdf_document: 
    fig_width: 20
    fig_height: 9
  html_document: 
    toc: true
    toc_float:
        collapsed: false
        smooth_scroll: true
    fig_width: 20
---

# Directory and doc rules

```{r, setup, eval=TRUE, include=TRUE, echo=FALSE}

knitr::opts_chunk$set(
  root.dir = here::here(),
  echo = TRUE,         # show code chunks
  eval = TRUE,         # evaluate code chunks
  warning = FALSE,     # hide warnings
  message = FALSE,     # hide messages
  #fig.width = 15,       # set plot width in inches
  #fig.height = 9,      # set plot height in inches
  fig.align = "center" # slign plots to the center in output doc/ slide/ whatever
)

# libraries
library("adespatial")
library(broom) # converting output tables to tidy tables for saving or easy view
library(classInt) # creating univariate variables for mapping
library(cluster) # grouping metrics - VERIFY still needed
library(devtools) # installing bespoke packages
library(dplyr) # data wrangling
library(factoextra) # pca/ nmds/ tweaking radars
library(FactoMineR) # pca/ nmds/ tweaking radars
library(fmsb) # polygon calculations for the radars
library(FSA) # post hoc test - Dunn's Test   
library(ggplot2) # plots
library("gstat")
library("GWmodel")
library(knitr) # output formatting
library(multcompView) # used for the letter assignment
library(pgirmess) # stats - KW
library(rcompanion) # for annotation of permanova
library(rstatix) # VERIFY what this is for      
library(RVAideMemoire) # post hoc test for permanova
library(scales) # scaling data for IBR - works with data wrangling packages
library(sf) # mapping - needed for converting to spatial data
library(spdep) # building spatial geometric components for analysis
library(spatialreg) # spatial regression analysis
library(tidyr) # data wrangling
library(tidyverse) # data wrangling
library(tmap) #mapping themes
library(vegan) # ecological stats 

```

# Load & Check Data
```{r}

# working from the clean data folder
getwd()

site_data<- read.csv("../data/site_with_indices_identifiers_analytes_10042025.csv") # for reporting area comparisons
#sample_data<- read.csv("../data/interim_df/sample_level_scaling_09292025.csv") # for site comparisons for the metrics
#sample_ibr<- read.csv("../data/interim_df/sample_level_ibr_09292025.csv") # for the reporting area comparisons for the ibrs

```

# Data prep
```{r}

# make ID columns factors 
site_data$reporting_area <- as.factor(site_data$reporting_area)
site_data$site_name <- as.factor(site_data$site_name)
site_data$site_number <- as.factor(site_data$site_number)

sample_data$reporting_area <- as.factor(sample_data$reporting_area)
sample_data$site_name <- as.factor(sample_data$site_name)
sample_data$site_number <- as.factor(sample_data$site_number)

sample_ibr$reporting_area <- as.factor(sample_ibr$reporting_area)
sample_ibr$site_name <- as.factor(sample_ibr$site_name)
sample_ibr$site_number <- as.factor(sample_ibr$site_number)

```

# Asking: What is the distribution of my transformed and scaled metrics, my created IBRs, and the scaled contaminant indices?
## Shapiro- Wilks 
```{r}

# shapiro-wilks on scaled metrics and indices

shapiro_results <- site_data %>%
  select(6:34) %>%
  map_df(~ broom::tidy(shapiro.test(.x)), .id = "variable")

shapiro_results

# save
#write.csv(shapiro_results, "../output/tables/shapiro_scaled_and_indices_10042025.csv", row.names = FALSE)

```

# Asking: Are there differences between these values at the site and reporting area level?
## ANOVA 
### p450, weight_change, ci3, ibr_morph, length, width, height, weight_initial, weight_final
```{r}

#NOTE: RA comparisons using site_data, Site comparisons using sample_data for non-ibr metrics, the tc value since it is the transformed and scaled value

#p450 - significant p-value for both 
p450_anova_site <- aov(tc_p450 ~ site_number, data = sample_data) # p-value= 1.25e-7
p450_anova_ra <- aov(p450 ~ reporting_area, data = site_data) # p-value= 0.0116
summary(p450_anova_site)
summary(p450_anova_ra)

#weight_change - non-significant p-value for both
wc_anova_site <- aov(tc_weight_change ~ site_number, data = sample_data) # p-value= 0.0674
wc_anova_ra <- aov(weight_change ~ reporting_area, data = site_data) # p-value= 0.177
summary(wc_anova_site)
summary(wc_anova_ra)

#ci3 - non-significant p-value for both. Note significance for site is at the edge, will posthoc for piece of mind
ci3_anova_site <- aov(tc_ci3 ~ site_number, data = sample_data) # p-value= 0.0507
ci3_anova_ra <- aov(ci3 ~ reporting_area, data = site_data) # p-value= 0.422
summary(ci3_anova_site)
summary(ci3_anova_ra)

#ibr_morph - significant p-value for both
morph_anova_site <- aov(ibr_morphometric ~ site_number, data = sample_ibr) # p-value= 2.65e-10
morph_anova_ra <- aov(ibr_morph ~ reporting_area, data = site_data) # p-value= 0.048
summary(morph_anova_site)
summary(morph_anova_ra)

# these may not be consequential in what I need, but running just in case
#length - significant p-value for site, non-significant p=value for reporting area
len_anova_site <- aov(tc_length ~ site_number, data = sample_data) # p-value= 0.0128
len_anova_ra <- aov(length ~ reporting_area, data = site_data) # p-value= 0.594
summary(len_anova_site)
summary(len_anova_ra)

#width - significant p-value for site, non-significant p=value for reporting area
wid_anova_site <- aov(tc_width ~ site_number, data = sample_data) # p-value= 0.000336
wid_anova_ra <- aov(width ~ reporting_area, data = site_data) # p-value= 0.214
summary(wid_anova_site)
summary(wid_anova_ra)

#height - significant p-value for site, non-significant p=value for reporting area
hei_anova_site <- aov(tc_height ~ site_number, data = sample_data) # p-value= 0.00987
hei_anova_ra <- aov(height ~ reporting_area, data = site_data) # p-value= 0.22
summary(hei_anova_site)
summary(hei_anova_ra)

#weight initial - non-significant p-value for both.
wi_anova_site <- aov(tc_weight_initial ~ site_number, data = sample_data) # p-value= 0.0954
wi_anova_ra <- aov(weight_initial ~ reporting_area, data = site_data) # p-value= 0.0519
summary(wi_anova_site)
summary(wi_anova_ra)

#weight final - significant p-value for site, non-significant p=value for reporting area
wf_anova_site <- aov(tc_weight_final ~ site_number, data = sample_data) # p-value= 0.00101
wf_anova_ra <- aov(weight_final ~ reporting_area, data = site_data) # p-value= 0.0767
summary(wf_anova_site)
summary(wf_anova_ra)

```

## Tukey's
### p450   
```{r}

#### p450, site: significant values returned
tuk <- TukeyHSD(p450_anova_site, "site_number")
tuk_df <- broom::tidy(tuk) %>%
  filter(term == "site_number") %>%
  separate(contrast, into = c("Group1", "Group2"), sep = "-") %>%
  mutate(Significant = ifelse(adj.p.value < 0.05, "Yes", "No"))
# cld letters
groups <- sort(unique(c(tuk_df$Group1, tuk_df$Group2)))
pval_matrix <- matrix(1, nrow = length(groups), ncol = length(groups),
                      dimnames = list(groups, groups))

for (i in seq_len(nrow(tuk_df))) {
  g1 <- tuk_df$Group1[i]; g2 <- tuk_df$Group2[i]
  p  <- as.numeric(tuk_df$adj.p.value[i])
  pval_matrix[g1, g2] <- p
  pval_matrix[g2, g1] <- p
}
cld_letters <- multcompLetters(pval_matrix < 0.05)$Letters
cld_df <- data.frame(Group = names(cld_letters), CLD = cld_letters, 
                     stringsAsFactors = FALSE)

tukey_table_with_cld <- tuk_df %>%
  left_join(cld_df, by = c("Group1" = "Group")) %>%
  rename(Group1_CLD = CLD) %>%
  left_join(cld_df, by = c("Group2" = "Group")) %>%
  rename(Group2_CLD = CLD)

view(tukey_table_with_cld)
#write.csv(tukey_table_with_cld, "../output/tukey_p450_site_10012025.csv", row.names = FALSE) 

#### p450 - reporting area: significant values returned
tuk <- TukeyHSD(p450_anova_ra, "reporting_area")
tuk_df <- broom::tidy(tuk) %>%
  filter(term == "reporting_area") %>%
  separate(contrast, into = c("Group1", "Group2"), sep = "-") %>%
  mutate(Significant = ifelse(adj.p.value < 0.05, "Yes", "No"))
# cld letters
groups <- sort(unique(c(tuk_df$Group1, tuk_df$Group2)))
pval_matrix <- matrix(1, nrow = length(groups), ncol = length(groups),
                      dimnames = list(groups, groups))

for (i in seq_len(nrow(tuk_df))) {
  g1 <- tuk_df$Group1[i]; g2 <- tuk_df$Group2[i]
  p  <- as.numeric(tuk_df$adj.p.value[i])
  pval_matrix[g1, g2] <- p
  pval_matrix[g2, g1] <- p
}
cld_letters <- multcompLetters(pval_matrix < 0.05)$Letters
cld_df <- data.frame(Group = names(cld_letters), CLD = cld_letters, 
                     stringsAsFactors = FALSE)

tukey_table_with_cld <- tuk_df %>%
  left_join(cld_df, by = c("Group1" = "Group")) %>%
  rename(Group1_CLD = CLD) %>%
  left_join(cld_df, by = c("Group2" = "Group")) %>%
  rename(Group2_CLD = CLD)

view(tukey_table_with_cld)
#write.csv(tukey_table_with_cld, "../output/tables/anova_kw_results/tukey_p450_ra_10012025.csv", row.names = FALSE) 

```

### ci3
```{r}

# ci3, site: no significant values returned
tuk <- TukeyHSD(ci3_anova_site, "site_number")
tuk_df <- broom::tidy(tuk) %>%
  filter(term == "site_number") %>%
  separate(contrast, into = c("Group1", "Group2"), sep = "-") %>%
  mutate(Significant = ifelse(adj.p.value < 0.05, "Yes", "No"))
# cld letters
groups <- sort(unique(c(tuk_df$Group1, tuk_df$Group2)))
pval_matrix <- matrix(1, nrow = length(groups), ncol = length(groups),
                      dimnames = list(groups, groups))

for (i in seq_len(nrow(tuk_df))) {
  g1 <- tuk_df$Group1[i]; g2 <- tuk_df$Group2[i]
  p  <- as.numeric(tuk_df$adj.p.value[i])
  pval_matrix[g1, g2] <- p
  pval_matrix[g2, g1] <- p
}
cld_letters <- multcompLetters(pval_matrix < 0.05)$Letters
cld_df <- data.frame(Group = names(cld_letters), CLD = cld_letters, 
                     stringsAsFactors = FALSE)

tukey_table_with_cld <- tuk_df %>%
  left_join(cld_df, by = c("Group1" = "Group")) %>%
  rename(Group1_CLD = CLD) %>%
  left_join(cld_df, by = c("Group2" = "Group")) %>%
  rename(Group2_CLD = CLD)

view(tukey_table_with_cld)
#write.csv(tukey_table_with_cld, "../output/tables/anova_kw_results/tukey_ci3_site_10032025.csv", row.names = FALSE) 

```

### ibr_morph
```{r}

#### ibr_morph, site: significant values returned
tuk <- TukeyHSD(morph_anova_site, "site_number")
tuk_df <- broom::tidy(tuk) %>%
  filter(term == "site_number") %>%
  separate(contrast, into = c("Group1", "Group2"), sep = "-") %>%
  mutate(Significant = ifelse(adj.p.value < 0.05, "Yes", "No"))
# cld letters
groups <- sort(unique(c(tuk_df$Group1, tuk_df$Group2)))
pval_matrix <- matrix(1, nrow = length(groups), ncol = length(groups),
                      dimnames = list(groups, groups))

for (i in seq_len(nrow(tuk_df))) {
  g1 <- tuk_df$Group1[i]; g2 <- tuk_df$Group2[i]
  p  <- as.numeric(tuk_df$adj.p.value[i])
  pval_matrix[g1, g2] <- p
  pval_matrix[g2, g1] <- p
}
cld_letters <- multcompLetters(pval_matrix < 0.05)$Letters
cld_df <- data.frame(Group = names(cld_letters), CLD = cld_letters, 
                     stringsAsFactors = FALSE)

tukey_table_with_cld <- tuk_df %>%
  left_join(cld_df, by = c("Group1" = "Group")) %>%
  rename(Group1_CLD = CLD) %>%
  left_join(cld_df, by = c("Group2" = "Group")) %>%
  rename(Group2_CLD = CLD)

view(tukey_table_with_cld)
#write.csv(tukey_table_with_cld, "../output/tables/anova_kw_results/tukey_morph_site_10022025.csv", row.names = FALSE) 

#### ibr_morphometrics, reporting area: no significant result
tuk <- TukeyHSD(morph_anova_ra, "reporting_area")
tuk_df <- broom::tidy(tuk) %>%
  filter(term == "reporting_area") %>%
  separate(contrast, into = c("Group1", "Group2"), sep = "-") %>%
  mutate(Significant = ifelse(adj.p.value < 0.05, "Yes", "No"))
# cld letters
groups <- sort(unique(c(tuk_df$Group1, tuk_df$Group2)))
pval_matrix <- matrix(1, nrow = length(groups), ncol = length(groups),
                      dimnames = list(groups, groups))

for (i in seq_len(nrow(tuk_df))) {
  g1 <- tuk_df$Group1[i]; g2 <- tuk_df$Group2[i]
  p  <- as.numeric(tuk_df$adj.p.value[i])
  pval_matrix[g1, g2] <- p
  pval_matrix[g2, g1] <- p
}
cld_letters <- multcompLetters(pval_matrix < 0.05)$Letters
cld_df <- data.frame(Group = names(cld_letters), CLD = cld_letters, 
                     stringsAsFactors = FALSE)

tukey_table_with_cld <- tuk_df %>%
  left_join(cld_df, by = c("Group1" = "Group")) %>%
  rename(Group1_CLD = CLD) %>%
  left_join(cld_df, by = c("Group2" = "Group")) %>%
  rename(Group2_CLD = CLD)

view(tukey_table_with_cld)
#write.csv(tukey_table_with_cld, "../output/tables/anova_kw_results/tukey_ibr_morph_ra_10012025.csv", row.names = FALSE)

```

### length
```{r}

# length, site: no significant result
tuk <- TukeyHSD(len_anova_site, "site_number")
tuk_df <- broom::tidy(tuk) %>%
  filter(term == "site_number") %>%
  separate(contrast, into = c("Group1", "Group2"), sep = "-") %>%
  mutate(Significant = ifelse(adj.p.value < 0.05, "Yes", "No"))
# cld letters
groups <- sort(unique(c(tuk_df$Group1, tuk_df$Group2)))
pval_matrix <- matrix(1, nrow = length(groups), ncol = length(groups),
                      dimnames = list(groups, groups))

for (i in seq_len(nrow(tuk_df))) {
  g1 <- tuk_df$Group1[i]; g2 <- tuk_df$Group2[i]
  p  <- as.numeric(tuk_df$adj.p.value[i])
  pval_matrix[g1, g2] <- p
  pval_matrix[g2, g1] <- p
}
cld_letters <- multcompLetters(pval_matrix < 0.05)$Letters
cld_df <- data.frame(Group = names(cld_letters), CLD = cld_letters, 
                     stringsAsFactors = FALSE)

tukey_table_with_cld <- tuk_df %>%
  left_join(cld_df, by = c("Group1" = "Group")) %>%
  rename(Group1_CLD = CLD) %>%
  left_join(cld_df, by = c("Group2" = "Group")) %>%
  rename(Group2_CLD = CLD)

view(tukey_table_with_cld)
#write.csv(tukey_table_with_cld, "../output/tables/anova_kw_results/tukey_length_site_10012025.csv", row.names = FALSE) 

```

### width
```{r}

# width, site: significant results returned
tuk <- TukeyHSD(wid_anova_site, "site_number")
tuk_df <- broom::tidy(tuk) %>%
  filter(term == "site_number") %>%
  separate(contrast, into = c("Group1", "Group2"), sep = "-") %>%
  mutate(Significant = ifelse(adj.p.value < 0.05, "Yes", "No"))
# cld letters
groups <- sort(unique(c(tuk_df$Group1, tuk_df$Group2)))
pval_matrix <- matrix(1, nrow = length(groups), ncol = length(groups),
                      dimnames = list(groups, groups))

for (i in seq_len(nrow(tuk_df))) {
  g1 <- tuk_df$Group1[i]; g2 <- tuk_df$Group2[i]
  p  <- as.numeric(tuk_df$adj.p.value[i])
  pval_matrix[g1, g2] <- p
  pval_matrix[g2, g1] <- p
}
cld_letters <- multcompLetters(pval_matrix < 0.05)$Letters
cld_df <- data.frame(Group = names(cld_letters), CLD = cld_letters, 
                     stringsAsFactors = FALSE)

tukey_table_with_cld <- tuk_df %>%
  left_join(cld_df, by = c("Group1" = "Group")) %>%
  rename(Group1_CLD = CLD) %>%
  left_join(cld_df, by = c("Group2" = "Group")) %>%
  rename(Group2_CLD = CLD)

view(tukey_table_with_cld)
#write.csv(tukey_table_with_cld, "../output/tables/anova_kw_results/tukey_width_site_10012025.csv", row.names = FALSE) 

```

### height
```{r}

# height, site: significant result returned
tuk <- TukeyHSD(hei_anova_site, "site_number")
tuk_df <- broom::tidy(tuk) %>%
  filter(term == "site_number") %>%
  separate(contrast, into = c("Group1", "Group2"), sep = "-") %>%
  mutate(Significant = ifelse(adj.p.value < 0.05, "Yes", "No"))
# cld letters
groups <- sort(unique(c(tuk_df$Group1, tuk_df$Group2)))
pval_matrix <- matrix(1, nrow = length(groups), ncol = length(groups),
                      dimnames = list(groups, groups))

for (i in seq_len(nrow(tuk_df))) {
  g1 <- tuk_df$Group1[i]; g2 <- tuk_df$Group2[i]
  p  <- as.numeric(tuk_df$adj.p.value[i])
  pval_matrix[g1, g2] <- p
  pval_matrix[g2, g1] <- p
}
cld_letters <- multcompLetters(pval_matrix < 0.05)$Letters
cld_df <- data.frame(Group = names(cld_letters), CLD = cld_letters, 
                     stringsAsFactors = FALSE)

tukey_table_with_cld <- tuk_df %>%
  left_join(cld_df, by = c("Group1" = "Group")) %>%
  rename(Group1_CLD = CLD) %>%
  left_join(cld_df, by = c("Group2" = "Group")) %>%
  rename(Group2_CLD = CLD)

view(tukey_table_with_cld)
#write.csv(tukey_table_with_cld, "../output/tables/anova_kw_results/tukey_height_site_10022025.csv", row.names = FALSE) 

```

### weight_final
```{r}

# weight_final, site: significant result returned
tuk <- TukeyHSD(wf_anova_site, "site_number")
tuk_df <- broom::tidy(tuk) %>%
  filter(term == "site_number") %>%
  separate(contrast, into = c("Group1", "Group2"), sep = "-") %>%
  mutate(Significant = ifelse(adj.p.value < 0.05, "Yes", "No"))
# cld letters
groups <- sort(unique(c(tuk_df$Group1, tuk_df$Group2)))
pval_matrix <- matrix(1, nrow = length(groups), ncol = length(groups),
                      dimnames = list(groups, groups))

for (i in seq_len(nrow(tuk_df))) {
  g1 <- tuk_df$Group1[i]; g2 <- tuk_df$Group2[i]
  p  <- as.numeric(tuk_df$adj.p.value[i])
  pval_matrix[g1, g2] <- p
  pval_matrix[g2, g1] <- p
}
cld_letters <- multcompLetters(pval_matrix < 0.05)$Letters
cld_df <- data.frame(Group = names(cld_letters), CLD = cld_letters, 
                     stringsAsFactors = FALSE)

tukey_table_with_cld <- tuk_df %>%
  left_join(cld_df, by = c("Group1" = "Group")) %>%
  rename(Group1_CLD = CLD) %>%
  left_join(cld_df, by = c("Group2" = "Group")) %>%
  rename(Group2_CLD = CLD)

view(tukey_table_with_cld)
#write.csv(tukey_table_with_cld, "../output/tables/anova_kw_results/tukey_weight_final_site_10012025.csv", row.names = FALSE) 

```

## Kruskal-Wallis
### both biomarkers, sod, ci1, ci2, shell, ibr_bio, ibr_combined, and all of the contaminant indices
```{r}

# both biomarkers - no significant result
kruskal.test(tc_p450 ~ tc_sod, data = sample_data) # p-value = 0.478 at site-level, p-value = 0.5131 at sample-level

# sod - significant p-value for site, non-significant p=value for reporting area
kruskal.test(tc_sod ~ site_number, data = sample_data) # p-value = 0.001777
kruskal.test(sod ~ reporting_area, data = site_data) # p-value = 0.7705

# ci1 - significant p-value for site, non-significant p=value for reporting area
kruskal.test(tc_ci1 ~ site_number, data = sample_data) # p-value = 0.001056
kruskal.test(ci1 ~ reporting_area, data = site_data) # p-value = 0.991

# ci2 - significant p-value for site, non-significant p=value for reporting area
kruskal.test(tc_ci2 ~ site_number, data = sample_data) # p-value = 2.191e-8
kruskal.test(ci2 ~ reporting_area, data = site_data) # p-value = 0.8179

# shell - significant p=value for both
kruskal.test(tc_shell ~ site_number, data = sample_data) # p-value = 1.092e-08
kruskal.test(shell ~ reporting_area, data = site_data) # p-value = 0.0204

# ibr_bio - significant p-value for site, non-significant p=value for reporting area
kruskal.test(ibr_biomarker ~ site_number, data = sample_ibr) # p-value = 0.000902
kruskal.test(ibr_bio ~ reporting_area, data = site_data) # p-value = 0.6185

# ibr_combined - significant p-value for site, non-significant p=value for reporting area
kruskal.test(ibr_total ~ site_number, data = sample_ibr) # p-value = 0.0001618
kruskal.test(ibr_combined ~ reporting_area, data = site_data) # p-value = 0.4618

# chlordane_index - significant
kruskal.test(chlordane_index ~ reporting_area, data = site_data) # p-value = 0.0001187

# ddt_index - significant
kruskal.test(ddt_index ~ reporting_area, data = site_data) # p-value = 6.389e-06

# hch_index - not significant
kruskal.test(hch_index ~ reporting_area, data = site_data) # p-value = 0.1796

# heavy_metal_index - not significant
kruskal.test(heavy_metal_index ~ reporting_area, data = site_data) # p-value = 0.07802

# nutrient_metal_index - significant
kruskal.test(nutrient_metal_index ~ reporting_area, data = site_data) # p-value = 0.02028

# total_metal_index - significant
kruskal.test(total_metal_index ~ reporting_area, data = site_data) # p-value = 0.01076

# pah_lmw_index - significant
kruskal.test(pah_lmw_index ~ reporting_area, data = site_data) # p-value = 0.005112

# pah_hmw_index - significant
kruskal.test(pah_hmw_index ~ reporting_area, data = site_data) # p-value = 7.555e-05

# pah_add_index - not significant
kruskal.test(pah_add_index ~ reporting_area, data = site_data) # p-value =0.1179

# total_pah_index - significant
kruskal.test(total_pah_index ~ reporting_area, data = site_data) # p-value = 0.001526

# pbde_index - significant
kruskal.test(pbde_index ~ reporting_area, data = site_data) # p-value = 0.0002848

# pcb_index - significant
kruskal.test(pcb_index ~ reporting_area, data = site_data) # p-value = 0.01909

# pesticide_index - not significant
kruskal.test(pesticide_index ~ reporting_area, data = site_data) # p-value = 0.1069

# total_contaminants_index - significant
kruskal.test(total_con_index ~ reporting_area, data = site_data) # p-value = 0.0006062

```

## Dunn's Test - 'bh' method
### sod
```{r}

# sod, site - no significant result
dunn_result <- dunnTest(tc_sod ~ site_name, data = sample_data, method = "bh") 
dunn_df <- dunn_result$res %>%
  dplyr::select(Comparison, Z, P.unadj, P.adj) %>%
  tidyr::separate(Comparison, into = c("Group1", "Group2"), sep = " - ") %>%
  dplyr::mutate(Significant = ifelse(P.adj < 0.05, "Yes", "No"))
dunn_table <- dunn_df %>%
  dplyr::mutate(across(c(P.unadj, P.adj), round, digits = 4)) %>%
  dplyr::arrange(P.adj)
print(dunn_table) # view

groups <- unique(c(dunn_df$Group1, dunn_df$Group2)) # add letter designation
pval_matrix <- matrix(1, nrow = length(groups), ncol = length(groups),
                      dimnames = list(groups, groups))
for (i in 1:nrow(dunn_df)) {
  g1 <- dunn_df$Group1[i]
  g2 <- dunn_df$Group2[i]
  p <- dunn_df$P.adj[i]
  pval_matrix[g1, g2] <- p
  pval_matrix[g2, g1] <- p
}
cld_letters <- multcompLetters(pval_matrix < 0.05)$Letters
cld_df <- data.frame(
  Group = names(cld_letters),
  CLD = cld_letters,
  stringsAsFactors = FALSE
)
dunn_table_with_cld <- dunn_table %>%
  left_join(cld_df, by = c("Group1" = "Group")) %>%
  rename(Group1_CLD = CLD) %>%
  left_join(cld_df, by = c("Group2" = "Group")) %>%
  rename(Group2_CLD = CLD)

view(dunn_table_with_cld)
#write.csv(dunn_table_with_cld, "../output/tables/anova_kw_results/dunn_sod_site_10022025.csv", row.names = FALSE) 

```

### ci1
```{r}

# ci1, site: significant results returned
dunn_result <- dunnTest(tc_ci1 ~ site_name, data = sample_data, method = "bh") 
dunn_df <- dunn_result$res %>%
  dplyr::select(Comparison, Z, P.unadj, P.adj) %>%
  tidyr::separate(Comparison, into = c("Group1", "Group2"), sep = " - ") %>%
  dplyr::mutate(Significant = ifelse(P.adj < 0.05, "Yes", "No"))
dunn_table <- dunn_df %>%
  dplyr::mutate(across(c(P.unadj, P.adj), round, digits = 4)) %>%
  dplyr::arrange(P.adj)
print(dunn_table) # view

groups <- unique(c(dunn_df$Group1, dunn_df$Group2)) # add letter designation
pval_matrix <- matrix(1, nrow = length(groups), ncol = length(groups),
                      dimnames = list(groups, groups))
for (i in 1:nrow(dunn_df)) {
  g1 <- dunn_df$Group1[i]
  g2 <- dunn_df$Group2[i]
  p <- dunn_df$P.adj[i]
  pval_matrix[g1, g2] <- p
  pval_matrix[g2, g1] <- p
}
cld_letters <- multcompLetters(pval_matrix < 0.05)$Letters
cld_df <- data.frame(
  Group = names(cld_letters),
  CLD = cld_letters,
  stringsAsFactors = FALSE
)
dunn_table_with_cld <- dunn_table %>%
  left_join(cld_df, by = c("Group1" = "Group")) %>%
  rename(Group1_CLD = CLD) %>%
  left_join(cld_df, by = c("Group2" = "Group")) %>%
  rename(Group2_CLD = CLD)

view(dunn_table_with_cld)
#write.csv(dunn_table_with_cld, "../output/tables/anova_kw_results/dunn_ci1_site_10022025.csv", row.names = FALSE) 

```

### ci2
```{r}

# ci2, site - no significant result
dunn_result <- dunnTest(tc_ci2 ~ site_name, data = sample_data, method = "bh") 
dunn_df <- dunn_result$res %>%
  dplyr::select(Comparison, Z, P.unadj, P.adj) %>%
  tidyr::separate(Comparison, into = c("Group1", "Group2"), sep = " - ") %>%
  dplyr::mutate(Significant = ifelse(P.adj < 0.05, "Yes", "No"))
dunn_table <- dunn_df %>%
  dplyr::mutate(across(c(P.unadj, P.adj), round, digits = 4)) %>%
  dplyr::arrange(P.adj)
print(dunn_table) # view

groups <- unique(c(dunn_df$Group1, dunn_df$Group2)) # add letter designation
pval_matrix <- matrix(1, nrow = length(groups), ncol = length(groups),
                      dimnames = list(groups, groups))
for (i in 1:nrow(dunn_df)) {
  g1 <- dunn_df$Group1[i]
  g2 <- dunn_df$Group2[i]
  p <- dunn_df$P.adj[i]
  pval_matrix[g1, g2] <- p
  pval_matrix[g2, g1] <- p
}
cld_letters <- multcompLetters(pval_matrix < 0.05)$Letters
cld_df <- data.frame(
  Group = names(cld_letters),
  CLD = cld_letters,
  stringsAsFactors = FALSE
)
dunn_table_with_cld <- dunn_table %>%
  left_join(cld_df, by = c("Group1" = "Group")) %>%
  rename(Group1_CLD = CLD) %>%
  left_join(cld_df, by = c("Group2" = "Group")) %>%
  rename(Group2_CLD = CLD)

view(dunn_table_with_cld)
#write.csv(dunn_table_with_cld, "../output/tables/anova_kw_results/dunn_ci2_site_10022025.csv", row.names = FALSE) 

```

### shell
```{r}

#### shell, site: significant results returned
dunn_result <- dunnTest(tc_shell ~ site_name, data = sample_data, method = "bh") 
dunn_df <- dunn_result$res %>%
  dplyr::select(Comparison, Z, P.unadj, P.adj) %>%
  tidyr::separate(Comparison, into = c("Group1", "Group2"), sep = " - ") %>%
  dplyr::mutate(Significant = ifelse(P.adj < 0.05, "Yes", "No"))
dunn_table <- dunn_df %>%
  dplyr::mutate(across(c(P.unadj, P.adj), round, digits = 4)) %>%
  dplyr::arrange(P.adj)
print(dunn_table) # view

groups <- unique(c(dunn_df$Group1, dunn_df$Group2)) # add letter designation
pval_matrix <- matrix(1, nrow = length(groups), ncol = length(groups),
                      dimnames = list(groups, groups))
for (i in 1:nrow(dunn_df)) {
  g1 <- dunn_df$Group1[i]
  g2 <- dunn_df$Group2[i]
  p <- dunn_df$P.adj[i]
  pval_matrix[g1, g2] <- p
  pval_matrix[g2, g1] <- p
}
cld_letters <- multcompLetters(pval_matrix < 0.05)$Letters
cld_df <- data.frame(
  Group = names(cld_letters),
  CLD = cld_letters,
  stringsAsFactors = FALSE
)
dunn_table_with_cld <- dunn_table %>%
  left_join(cld_df, by = c("Group1" = "Group")) %>%
  rename(Group1_CLD = CLD) %>%
  left_join(cld_df, by = c("Group2" = "Group")) %>%
  rename(Group2_CLD = CLD)

view(dunn_table_with_cld)
#write.csv(dunn_table_with_cld, "../output/tables/anova_kw_results/dunn_shell_site_10032025.csv", row.names = FALSE) 

#### shell, reporting area: no significant result returned
dunn_result <- dunnTest(shell ~ reporting_area, data = site_data, method = "bh") 
dunn_df <- dunn_result$res %>%
  dplyr::select(Comparison, Z, P.unadj, P.adj) %>%
  tidyr::separate(Comparison, into = c("Group1", "Group2"), sep = " - ") %>%
  dplyr::mutate(Significant = ifelse(P.adj < 0.05, "Yes", "No"))
dunn_table <- dunn_df %>%
  dplyr::mutate(across(c(P.unadj, P.adj), round, digits = 4)) %>%
  dplyr::arrange(P.adj)
print(dunn_table) # view

groups <- unique(c(dunn_df$Group1, dunn_df$Group2)) # add letter designation
pval_matrix <- matrix(1, nrow = length(groups), ncol = length(groups),
                      dimnames = list(groups, groups))
for (i in 1:nrow(dunn_df)) {
  g1 <- dunn_df$Group1[i]
  g2 <- dunn_df$Group2[i]
  p <- dunn_df$P.adj[i]
  pval_matrix[g1, g2] <- p
  pval_matrix[g2, g1] <- p
}
cld_letters <- multcompLetters(pval_matrix < 0.05)$Letters
cld_df <- data.frame(
  Group = names(cld_letters),
  CLD = cld_letters,
  stringsAsFactors = FALSE
)
dunn_table_with_cld <- dunn_table %>%
  left_join(cld_df, by = c("Group1" = "Group")) %>%
  rename(Group1_CLD = CLD) %>%
  left_join(cld_df, by = c("Group2" = "Group")) %>%
  rename(Group2_CLD = CLD)

view(dunn_table_with_cld)
#write.csv(dunn_table_with_cld, "../output/tables/anova_kw_results/dunn_shell_ra_10022025.csv", row.names = FALSE) 

```

### ibr_bio
```{r}

# ibr_bio, site: no significant results
dunn_result <- dunnTest(ibr_biomarker ~ site_number, data = sample_ibr, method = "bh") 
dunn_df <- dunn_result$res %>%
  dplyr::select(Comparison, Z, P.unadj, P.adj) %>%
  tidyr::separate(Comparison, into = c("Group1", "Group2"), sep = " - ") %>%
  dplyr::mutate(Significant = ifelse(P.adj < 0.05, "Yes", "No"))
dunn_table <- dunn_df %>%
  dplyr::mutate(across(c(P.unadj, P.adj), round, digits = 4)) %>%
  dplyr::arrange(P.adj)
print(dunn_table) # view

groups <- unique(c(dunn_df$Group1, dunn_df$Group2)) # add letter designation
pval_matrix <- matrix(1, nrow = length(groups), ncol = length(groups),
                      dimnames = list(groups, groups))
for (i in 1:nrow(dunn_df)) {
  g1 <- dunn_df$Group1[i]
  g2 <- dunn_df$Group2[i]
  p <- dunn_df$P.adj[i]
  pval_matrix[g1, g2] <- p
  pval_matrix[g2, g1] <- p
}
cld_letters <- multcompLetters(pval_matrix < 0.05)$Letters
cld_df <- data.frame(
  Group = names(cld_letters),
  CLD = cld_letters,
  stringsAsFactors = FALSE
)
dunn_table_with_cld <- dunn_table %>%
  left_join(cld_df, by = c("Group1" = "Group")) %>%
  rename(Group1_CLD = CLD) %>%
  left_join(cld_df, by = c("Group2" = "Group")) %>%
  rename(Group2_CLD = CLD)

view(dunn_table_with_cld)
#write.csv(dunn_table_with_cld, "../output/tables/anova_kw_results/dunn_ibr_bio_site_10022025.csv", row.names = FALSE) 

```

### ibr_combined (ibr_total)
```{r}

# ibr_combined (total), site: no significant result
dunn_result <- dunnTest(ibr_total ~ site_name, data = sample_ibr, method = "bh") 
dunn_df <- dunn_result$res %>%
  dplyr::select(Comparison, Z, P.unadj, P.adj) %>%
  tidyr::separate(Comparison, into = c("Group1", "Group2"), sep = " - ") %>%
  dplyr::mutate(Significant = ifelse(P.adj < 0.05, "Yes", "No"))
dunn_table <- dunn_df %>%
  dplyr::mutate(across(c(P.unadj, P.adj), round, digits = 4)) %>%
  dplyr::arrange(P.adj)
print(dunn_table) # view

groups <- unique(c(dunn_df$Group1, dunn_df$Group2)) # add letter designation
pval_matrix <- matrix(1, nrow = length(groups), ncol = length(groups),
                      dimnames = list(groups, groups))
for (i in 1:nrow(dunn_df)) {
  g1 <- dunn_df$Group1[i]
  g2 <- dunn_df$Group2[i]
  p <- dunn_df$P.adj[i]
  pval_matrix[g1, g2] <- p
  pval_matrix[g2, g1] <- p
}
cld_letters <- multcompLetters(pval_matrix < 0.05)$Letters
cld_df <- data.frame(
  Group = names(cld_letters),
  CLD = cld_letters,
  stringsAsFactors = FALSE
)
dunn_table_with_cld <- dunn_table %>%
  left_join(cld_df, by = c("Group1" = "Group")) %>%
  rename(Group1_CLD = CLD) %>%
  left_join(cld_df, by = c("Group2" = "Group")) %>%
  rename(Group2_CLD = CLD)

view(dunn_table_with_cld)
#write.csv(dunn_table_with_cld, "../output/tables/anova_kw_results/dunn_ibr_total_site_10022025.csv", row.names = FALSE) 

```

## Note: all contaminants are at the reporting area level only because site values are singular and will be used in correlations
### chlordane
```{r}

# chlordane: significant results returned
dunn_result <- dunnTest(chlordane_index ~ reporting_area, data = site_data, method = "bh") 
dunn_df <- dunn_result$res %>%
  dplyr::select(Comparison, Z, P.unadj, P.adj) %>%
  tidyr::separate(Comparison, into = c("Group1", "Group2"), sep = " - ") %>%
  dplyr::mutate(Significant = ifelse(P.adj < 0.05, "Yes", "No"))

dunn_table <- dunn_df %>%
  dplyr::mutate(across(c(P.unadj, P.adj), round, digits = 4)) %>%
  dplyr::arrange(P.adj)

print(dunn_table) # view
groups <- unique(c(dunn_df$Group1, dunn_df$Group2)) # add letter designation
pval_matrix <- matrix(1, nrow = length(groups), ncol = length(groups),
                      dimnames = list(groups, groups))
for (i in 1:nrow(dunn_df)) {
  g1 <- dunn_df$Group1[i]
  g2 <- dunn_df$Group2[i]
  p <- dunn_df$P.adj[i]
  pval_matrix[g1, g2] <- p
  pval_matrix[g2, g1] <- p
}
cld_letters <- multcompLetters(pval_matrix < 0.05)$Letters
cld_df <- data.frame(
  Group = names(cld_letters),
  CLD = cld_letters,
  stringsAsFactors = FALSE
)
dunn_table_with_cld <- dunn_table %>%
  left_join(cld_df, by = c("Group1" = "Group")) %>%
  rename(Group1_CLD = CLD) %>%
  left_join(cld_df, by = c("Group2" = "Group")) %>%
  rename(Group2_CLD = CLD)

view(dunn_table_with_cld)
#write.csv(dunn_table_with_cld, "../output/tables/anova_kw_results/dunn_chlordane_ra.csv", row.names = FALSE) 

```

### ddt
```{r}

# ddt: significant results returned
dunn_result <- dunnTest(ddt_index ~ reporting_area, data = site_data, method = "bh") 
dunn_df <- dunn_result$res %>%
  dplyr::select(Comparison, Z, P.unadj, P.adj) %>%
  tidyr::separate(Comparison, into = c("Group1", "Group2"), sep = " - ") %>%
  dplyr::mutate(Significant = ifelse(P.adj < 0.05, "Yes", "No"))

dunn_table <- dunn_df %>%
  dplyr::mutate(across(c(P.unadj, P.adj), round, digits = 4)) %>%
  dplyr::arrange(P.adj)

print(dunn_table) # view
groups <- unique(c(dunn_df$Group1, dunn_df$Group2)) # add letter designation
pval_matrix <- matrix(1, nrow = length(groups), ncol = length(groups),
                      dimnames = list(groups, groups))
for (i in 1:nrow(dunn_df)) {
  g1 <- dunn_df$Group1[i]
  g2 <- dunn_df$Group2[i]
  p <- dunn_df$P.adj[i]
  pval_matrix[g1, g2] <- p
  pval_matrix[g2, g1] <- p
}
cld_letters <- multcompLetters(pval_matrix < 0.05)$Letters
cld_df <- data.frame(
  Group = names(cld_letters),
  CLD = cld_letters,
  stringsAsFactors = FALSE
)
dunn_table_with_cld <- dunn_table %>%
  left_join(cld_df, by = c("Group1" = "Group")) %>%
  rename(Group1_CLD = CLD) %>%
  left_join(cld_df, by = c("Group2" = "Group")) %>%
  rename(Group2_CLD = CLD)

view(dunn_table_with_cld)
#write.csv(dunn_table_with_cld, "../output/tables/anova_kw_results/dunn_ddt_ra.csv", row.names = FALSE) 

```

### nutrient_metals
```{r}

# nutrient metals: significant result returned
dunn_result <- dunnTest(nutrient_metal_index ~ reporting_area, data = site_data, method = "bh") 
dunn_df <- dunn_result$res %>%
  dplyr::select(Comparison, Z, P.unadj, P.adj) %>%
  tidyr::separate(Comparison, into = c("Group1", "Group2"), sep = " - ") %>%
  dplyr::mutate(Significant = ifelse(P.adj < 0.05, "Yes", "No"))

dunn_table <- dunn_df %>%
  dplyr::mutate(across(c(P.unadj, P.adj), round, digits = 4)) %>%
  dplyr::arrange(P.adj)

print(dunn_table) # view
groups <- unique(c(dunn_df$Group1, dunn_df$Group2)) # add letter designation
pval_matrix <- matrix(1, nrow = length(groups), ncol = length(groups),
                      dimnames = list(groups, groups))
for (i in 1:nrow(dunn_df)) {
  g1 <- dunn_df$Group1[i]
  g2 <- dunn_df$Group2[i]
  p <- dunn_df$P.adj[i]
  pval_matrix[g1, g2] <- p
  pval_matrix[g2, g1] <- p
}
cld_letters <- multcompLetters(pval_matrix < 0.05)$Letters
cld_df <- data.frame(
  Group = names(cld_letters),
  CLD = cld_letters,
  stringsAsFactors = FALSE
)
dunn_table_with_cld <- dunn_table %>%
  left_join(cld_df, by = c("Group1" = "Group")) %>%
  rename(Group1_CLD = CLD) %>%
  left_join(cld_df, by = c("Group2" = "Group")) %>%
  rename(Group2_CLD = CLD)

view(dunn_table_with_cld)
#write.csv(dunn_table_with_cld, "../output/tables/anova_kw_results/dunn_nutrient_metal_ra.csv", row.names = FALSE) 

```

### total_metals
```{r}

# total metal: no significant results
dunn_result <- dunnTest(total_metal_index ~ reporting_area, data = site_data, method = "bh") 
dunn_df <- dunn_result$res %>%
  dplyr::select(Comparison, Z, P.unadj, P.adj) %>%
  tidyr::separate(Comparison, into = c("Group1", "Group2"), sep = " - ") %>%
  dplyr::mutate(Significant = ifelse(P.adj < 0.05, "Yes", "No"))

dunn_table <- dunn_df %>%
  dplyr::mutate(across(c(P.unadj, P.adj), round, digits = 4)) %>%
  dplyr::arrange(P.adj)

print(dunn_table) # view
groups <- unique(c(dunn_df$Group1, dunn_df$Group2)) # add letter designation
pval_matrix <- matrix(1, nrow = length(groups), ncol = length(groups),
                      dimnames = list(groups, groups))
for (i in 1:nrow(dunn_df)) {
  g1 <- dunn_df$Group1[i]
  g2 <- dunn_df$Group2[i]
  p <- dunn_df$P.adj[i]
  pval_matrix[g1, g2] <- p
  pval_matrix[g2, g1] <- p
}
cld_letters <- multcompLetters(pval_matrix < 0.05)$Letters
cld_df <- data.frame(
  Group = names(cld_letters),
  CLD = cld_letters,
  stringsAsFactors = FALSE
)
dunn_table_with_cld <- dunn_table %>%
  left_join(cld_df, by = c("Group1" = "Group")) %>%
  rename(Group1_CLD = CLD) %>%
  left_join(cld_df, by = c("Group2" = "Group")) %>%
  rename(Group2_CLD = CLD)

view(dunn_table_with_cld)
#write.csv(dunn_table_with_cld, "../output/tables/anova_kw_results/dunn_total_metal_ra.csv", row.names = FALSE) 

```

### lmw_pah
```{r}

# low pah: significant results returned
dunn_result <- dunnTest(pah_lmw_index ~ reporting_area, data = site_data, method = "bh") 
dunn_df <- dunn_result$res %>%
  dplyr::select(Comparison, Z, P.unadj, P.adj) %>%
  tidyr::separate(Comparison, into = c("Group1", "Group2"), sep = " - ") %>%
  dplyr::mutate(Significant = ifelse(P.adj < 0.05, "Yes", "No"))

dunn_table <- dunn_df %>%
  dplyr::mutate(across(c(P.unadj, P.adj), round, digits = 4)) %>%
  dplyr::arrange(P.adj)

print(dunn_table) # view
groups <- unique(c(dunn_df$Group1, dunn_df$Group2)) # add letter designation
pval_matrix <- matrix(1, nrow = length(groups), ncol = length(groups),
                      dimnames = list(groups, groups))
for (i in 1:nrow(dunn_df)) {
  g1 <- dunn_df$Group1[i]
  g2 <- dunn_df$Group2[i]
  p <- dunn_df$P.adj[i]
  pval_matrix[g1, g2] <- p
  pval_matrix[g2, g1] <- p
}
cld_letters <- multcompLetters(pval_matrix < 0.05)$Letters
cld_df <- data.frame(
  Group = names(cld_letters),
  CLD = cld_letters,
  stringsAsFactors = FALSE
)
dunn_table_with_cld <- dunn_table %>%
  left_join(cld_df, by = c("Group1" = "Group")) %>%
  rename(Group1_CLD = CLD) %>%
  left_join(cld_df, by = c("Group2" = "Group")) %>%
  rename(Group2_CLD = CLD)

view(dunn_table_with_cld)
#write.csv(dunn_table_with_cld, "../output/tables/anova_kw_results/dunn_low_pah_ra.csv", row.names = FALSE) 

```

### hmw_pah
```{r}

# high pah: signficant results returned
dunn_result <- dunnTest(pah_hmw_index ~ reporting_area, data = site_data, method = "bh") 
dunn_df <- dunn_result$res %>%
  dplyr::select(Comparison, Z, P.unadj, P.adj) %>%
  tidyr::separate(Comparison, into = c("Group1", "Group2"), sep = " - ") %>%
  dplyr::mutate(Significant = ifelse(P.adj < 0.05, "Yes", "No"))

dunn_table <- dunn_df %>%
  dplyr::mutate(across(c(P.unadj, P.adj), round, digits = 4)) %>%
  dplyr::arrange(P.adj)

print(dunn_table) # view
groups <- unique(c(dunn_df$Group1, dunn_df$Group2)) # add letter designation
pval_matrix <- matrix(1, nrow = length(groups), ncol = length(groups),
                      dimnames = list(groups, groups))
for (i in 1:nrow(dunn_df)) {
  g1 <- dunn_df$Group1[i]
  g2 <- dunn_df$Group2[i]
  p <- dunn_df$P.adj[i]
  pval_matrix[g1, g2] <- p
  pval_matrix[g2, g1] <- p
}
cld_letters <- multcompLetters(pval_matrix < 0.05)$Letters
cld_df <- data.frame(
  Group = names(cld_letters),
  CLD = cld_letters,
  stringsAsFactors = FALSE
)
dunn_table_with_cld <- dunn_table %>%
  left_join(cld_df, by = c("Group1" = "Group")) %>%
  rename(Group1_CLD = CLD) %>%
  left_join(cld_df, by = c("Group2" = "Group")) %>%
  rename(Group2_CLD = CLD)

view(dunn_table_with_cld)
#write.csv(dunn_table_with_cld, "../output/tables/anova_kw_results/dunn_high_pah_ra.csv", row.names = FALSE) 


```

### total_pah
```{r}

# total pah: significant results returned
dunn_result <- dunnTest(total_pah_index ~ reporting_area, data = site_data, method = "bh") 
dunn_df <- dunn_result$res %>%
  dplyr::select(Comparison, Z, P.unadj, P.adj) %>%
  tidyr::separate(Comparison, into = c("Group1", "Group2"), sep = " - ") %>%
  dplyr::mutate(Significant = ifelse(P.adj < 0.05, "Yes", "No"))

dunn_table <- dunn_df %>%
  dplyr::mutate(across(c(P.unadj, P.adj), round, digits = 4)) %>%
  dplyr::arrange(P.adj)

print(dunn_table) # view
groups <- unique(c(dunn_df$Group1, dunn_df$Group2)) # add letter designation
pval_matrix <- matrix(1, nrow = length(groups), ncol = length(groups),
                      dimnames = list(groups, groups))
for (i in 1:nrow(dunn_df)) {
  g1 <- dunn_df$Group1[i]
  g2 <- dunn_df$Group2[i]
  p <- dunn_df$P.adj[i]
  pval_matrix[g1, g2] <- p
  pval_matrix[g2, g1] <- p
}
cld_letters <- multcompLetters(pval_matrix < 0.05)$Letters
cld_df <- data.frame(
  Group = names(cld_letters),
  CLD = cld_letters,
  stringsAsFactors = FALSE
)
dunn_table_with_cld <- dunn_table %>%
  left_join(cld_df, by = c("Group1" = "Group")) %>%
  rename(Group1_CLD = CLD) %>%
  left_join(cld_df, by = c("Group2" = "Group")) %>%
  rename(Group2_CLD = CLD)

view(dunn_table_with_cld)
#write.csv(dunn_table_with_cld, "../output/tables/anova_kw_results/dunn_total_pah_ra.csv", row.names = FALSE) 

```

### pbde
```{r}

# pbde: signficant results returned
dunn_result <- dunnTest(pbde_index ~ reporting_area, data = site_data, method = "bh") 
dunn_df <- dunn_result$res %>%
  dplyr::select(Comparison, Z, P.unadj, P.adj) %>%
  tidyr::separate(Comparison, into = c("Group1", "Group2"), sep = " - ") %>%
  dplyr::mutate(Significant = ifelse(P.adj < 0.05, "Yes", "No"))

dunn_table <- dunn_df %>%
  dplyr::mutate(across(c(P.unadj, P.adj), round, digits = 4)) %>%
  dplyr::arrange(P.adj)

print(dunn_table) # view
groups <- unique(c(dunn_df$Group1, dunn_df$Group2)) # add letter designation
pval_matrix <- matrix(1, nrow = length(groups), ncol = length(groups),
                      dimnames = list(groups, groups))
for (i in 1:nrow(dunn_df)) {
  g1 <- dunn_df$Group1[i]
  g2 <- dunn_df$Group2[i]
  p <- dunn_df$P.adj[i]
  pval_matrix[g1, g2] <- p
  pval_matrix[g2, g1] <- p
}
cld_letters <- multcompLetters(pval_matrix < 0.05)$Letters
cld_df <- data.frame(
  Group = names(cld_letters),
  CLD = cld_letters,
  stringsAsFactors = FALSE
)
dunn_table_with_cld <- dunn_table %>%
  left_join(cld_df, by = c("Group1" = "Group")) %>%
  rename(Group1_CLD = CLD) %>%
  left_join(cld_df, by = c("Group2" = "Group")) %>%
  rename(Group2_CLD = CLD)

view(dunn_table_with_cld)
#write.csv(dunn_table_with_cld, "../output/tables/anova_kw_results/dunn_pbde_ra.csv", row.names = FALSE) 


```

### pcb
```{r}

# pcb: no significant results
dunn_result <- dunnTest(pcb_index ~ reporting_area, data = site_data, method = "bh") 
dunn_df <- dunn_result$res %>%
  dplyr::select(Comparison, Z, P.unadj, P.adj) %>%
  tidyr::separate(Comparison, into = c("Group1", "Group2"), sep = " - ") %>%
  dplyr::mutate(Significant = ifelse(P.adj < 0.05, "Yes", "No"))

dunn_table <- dunn_df %>%
  dplyr::mutate(across(c(P.unadj, P.adj), round, digits = 4)) %>%
  dplyr::arrange(P.adj)

print(dunn_table) # view
groups <- unique(c(dunn_df$Group1, dunn_df$Group2)) # add letter designation
pval_matrix <- matrix(1, nrow = length(groups), ncol = length(groups),
                      dimnames = list(groups, groups))
for (i in 1:nrow(dunn_df)) {
  g1 <- dunn_df$Group1[i]
  g2 <- dunn_df$Group2[i]
  p <- dunn_df$P.adj[i]
  pval_matrix[g1, g2] <- p
  pval_matrix[g2, g1] <- p
}
cld_letters <- multcompLetters(pval_matrix < 0.05)$Letters
cld_df <- data.frame(
  Group = names(cld_letters),
  CLD = cld_letters,
  stringsAsFactors = FALSE
)
dunn_table_with_cld <- dunn_table %>%
  left_join(cld_df, by = c("Group1" = "Group")) %>%
  rename(Group1_CLD = CLD) %>%
  left_join(cld_df, by = c("Group2" = "Group")) %>%
  rename(Group2_CLD = CLD)

view(dunn_table_with_cld)
#write.csv(dunn_table_with_cld, "../output/tables/anova_kw_results/dunn_pcb_ra.csv", row.names = FALSE) 

```

### total_contaminants
```{r}

# total_con: significant results returned
dunn_result <- dunnTest(total_con_index ~ reporting_area, data = site_data, method = "bh") 
dunn_df <- dunn_result$res %>%
  dplyr::select(Comparison, Z, P.unadj, P.adj) %>%
  tidyr::separate(Comparison, into = c("Group1", "Group2"), sep = " - ") %>%
  dplyr::mutate(Significant = ifelse(P.adj < 0.05, "Yes", "No"))

dunn_table <- dunn_df %>%
  dplyr::mutate(across(c(P.unadj, P.adj), round, digits = 4)) %>%
  dplyr::arrange(P.adj)

print(dunn_table) # view
groups <- unique(c(dunn_df$Group1, dunn_df$Group2)) # add letter designation
pval_matrix <- matrix(1, nrow = length(groups), ncol = length(groups),
                      dimnames = list(groups, groups))
for (i in 1:nrow(dunn_df)) {
  g1 <- dunn_df$Group1[i]
  g2 <- dunn_df$Group2[i]
  p <- dunn_df$P.adj[i]
  pval_matrix[g1, g2] <- p
  pval_matrix[g2, g1] <- p
}
cld_letters <- multcompLetters(pval_matrix < 0.05)$Letters
cld_df <- data.frame(
  Group = names(cld_letters),
  CLD = cld_letters,
  stringsAsFactors = FALSE
)
dunn_table_with_cld <- dunn_table %>%
  left_join(cld_df, by = c("Group1" = "Group")) %>%
  rename(Group1_CLD = CLD) %>%
  left_join(cld_df, by = c("Group2" = "Group")) %>%
  rename(Group2_CLD = CLD)

view(dunn_table_with_cld)
#write.csv(dunn_table_with_cld, "../output/tables/anova_kw_results/dunn_total_con_ra.csv", row.names = FALSE) 

```

# Asking: Are there correlations between the contaminants indices and the metrics(Spearman)? Is there a relationship between the contaminants indices and metrics that could indicate dependence or independence (Kendall's) in the Spearman results?
## Spearman & Kendall's
### metrics & all indices
```{r}

# define variables
metrics_vars <- c("p450", "sod", "shell", "ci1", "ci2", "ci3",
                  "weight_initial", "weight_change", "weight_final",
                  "length", "width", "height", "ibr_bio", "ibr_morph", "ibr_combined")

# define id columns
id_columns <- c("site_name", "site_number", "reporting_area", "latitude", "longitude")

analyte_vars <- c("chlordane_index", "ddt_index", "hch_index", "heavy_metal_index", "nutrient_metal_index", "total_metal_index",
"pah_lmw_index", "pah_hmw_index", "pah_add_index", "total_pah_index", "pbde_index", "pcb_index", "pesticide_index", "total_con_index")  

# make sure these are plain character vectors (not factors)
metrics_vars <- as.character(metrics_vars)
analyte_vars <- as.character(analyte_vars)

needed <- c(metrics_vars, analyte_vars)

# check for missing columns (common cause: typos)
missing_cols <- setdiff(needed, names(site_data))
if (length(missing_cols) > 0) {
  warning("These columns are missing from site_data: ",
          paste(missing_cols, collapse = ", "))
}

# coerce just the needed columns to numeric (safe conversion)
to_numeric <- function(v) {
  if (is.numeric(v)) return(v)
  if (is.factor(v)) return(as.numeric(as.character(v)))
  if (is.character(v)) return(suppressWarnings(as.numeric(v)))
  suppressWarnings(as.numeric(v))
}

site_data <- site_data |>
  dplyr::mutate(dplyr::across(dplyr::all_of(intersect(needed, names(site_data))), to_numeric))

# --- correlation loop --------------------------------------------------
results_list <- list()
k <- 1L

for (metric in metrics_vars) {
  if (!metric %in% names(site_data)) next
  x <- site_data[[metric]]
  if (!is.numeric(x)) next

  for (analyte in analyte_vars) {
    if (!analyte %in% names(site_data)) next
    y <- site_data[[analyte]]
    if (!is.numeric(y)) next

    valid <- is.finite(x) & is.finite(y)
    x_valid <- x[valid]
    y_valid <- y[valid]

    
    spearman <- try(stats::cor.test(x_valid, y_valid, method = "spearman", exact = FALSE), silent = TRUE)
    kendall  <- try(stats::cor.test(x_valid, y_valid, method = "kendall"), silent = TRUE)

    if (inherits(spearman, "try-error") || inherits(kendall, "try-error")) next

    results_list[[k]] <- data.frame(
      Metric = metric,
      Analyte = analyte,
      Spearman_r = unname(spearman$estimate),
      Spearman_p = unname(spearman$p.value),
      Kendall_tau = unname(kendall$estimate),
      Kendall_p = unname(kendall$p.value),
      stringsAsFactors = FALSE
    )
    k <- k + 1L
  }
}

# --- combine + significance stars -------------------------------------
corr_full <- dplyr::bind_rows(results_list)

corr_full <- corr_full |>
  dplyr::mutate(
    Spearman_sig = dplyr::case_when(
      Spearman_p <= 0.001 ~ "***",
      Spearman_p <= 0.01  ~ "**",
      Spearman_p <= 0.05  ~ "*",
      TRUE ~ ""
    ),
    Kendall_sig = dplyr::case_when(
      Kendall_p <= 0.001 ~ "***",
      Kendall_p <= 0.01  ~ "**",
      Kendall_p <= 0.05  ~ "*",
      TRUE ~ ""
    )
  ) |>
  dplyr::arrange(Spearman_p, Kendall_p)

view(corr_full)
#write.csv(corr_full, "../output/tables/spearman_kendall_results/correlation_all_indices_10042025.csv", row.names = FALSE)

```

### individual analytes
```{r}

# ---- column ranges based on your layout ----
id_columns      <- names(site_data)[1:5]
metrics_vars    <- names(site_data)[6:20]
index_vars      <- names(site_data)[21:34]   # not used here; for clarity
analyte_vars    <- names(site_data)[35:142]  


needed <- c(metrics_vars, analyte_vars)

to_numeric <- function(v) {
  if (is.numeric(v)) return(v)
  if (is.factor(v)) return(as.numeric(as.character(v)))
  if (is.character(v)) return(suppressWarnings(as.numeric(v)))
  suppressWarnings(as.numeric(v))
}

site_data <- site_data |>
  dplyr::mutate(dplyr::across(dplyr::all_of(intersect(needed, names(site_data))), to_numeric))

# ---- correlation loop: metrics x individual analytes ----
results_list <- list()
k <- 1L
min_pairs <- 4L  # require at least 4 paired points

for (metric in metrics_vars) {
  if (!metric %in% names(site_data)) next
  x <- site_data[[metric]]
  if (!is.numeric(x)) next

  for (analyte in analyte_vars) {
    if (!analyte %in% names(site_data)) next
    y <- site_data[[analyte]]
    if (!is.numeric(y)) next

    valid <- is.finite(x) & is.finite(y)
    if (!any(valid)) next
    x_valid <- x[valid]
    y_valid <- y[valid]

   
    # correlations
    spearman <- try(stats::cor.test(x_valid, y_valid, method = "spearman", exact = FALSE), silent = TRUE)
    kendall  <- try(stats::cor.test(x_valid, y_valid, method = "kendall"), silent = TRUE)
    if (inherits(spearman, "try-error") || inherits(kendall, "try-error")) next

    results_list[[k]] <- data.frame(
      Metric       = metric,
      Analyte      = analyte,
      N_Pairs      = length(x_valid),
      Spearman_r   = unname(spearman$estimate),
      Spearman_p   = unname(spearman$p.value),
      Kendall_tau  = unname(kendall$estimate),
      Kendall_p    = unname(kendall$p.value),
      stringsAsFactors = FALSE
    )
    k <- k + 1L
  }
}

corr_full <- dplyr::bind_rows(results_list)

# ---- significance flags + ordering ----
corr_full <- corr_full |>
  dplyr::mutate(
    Spearman_sig = dplyr::case_when(
      Spearman_p <= 0.001 ~ "***",
      Spearman_p <= 0.01  ~ "**",
      Spearman_p <= 0.05  ~ "*",
      TRUE ~ ""
    ),
    Kendall_sig = dplyr::case_when(
      Kendall_p <= 0.001 ~ "***",
      Kendall_p <= 0.01  ~ "**",
      Kendall_p <= 0.05  ~ "*",
      TRUE ~ ""
    )
  ) |>
  dplyr::arrange(Spearman_p, Kendall_p)

# view
view(corr_full)
#write.csv(corr_full, "../output/tables/spearman_kendall_results/correlation_metrics_analytes_10042025.csv", row.names = FALSE)

```

# Asking: Are there discernable, significant spatial correlations/ relations amongst the metrics or analytes?
## Global Moran's I & LISA (Local Indicators of Spatial Association) w/ data prep
### biomarkers and ibrs only
```{r}

# define my columns/ variables
id_idx <- 1:5 # site_number, reporting_area, site_name, latitude, longitude
biomarker_idx <- 6:7 # e.g., p450, sod <-- EDIT to your true range
morphometric_idx<- 8:14 # e.g., shell, length/height/width, weights <-- EDIT
condition_idx <- 15:17 # e.g., ci1:ci3 (example) <-- EDIT
ibr_idx <- 18:20 # e.g., ibr_bio, ibr_morph, ibr_combined <-- EDIT
index_idx <- 21:34 # contaminant indices
analyte_idx <- 35:142 # individual analytes (z_*)

# pull the column names from indices
nm <- names(site_data)
id_cols <- nm[intersect(id_idx, seq_along(nm))]
biomarkers <- nm[intersect(biomarker_idx, seq_along(nm))]
morphometrics <- nm[intersect(morphometric_idx, seq_along(nm))]
conditions <- nm[intersect(condition_idx, seq_along(nm))]
ibrs <- nm[intersect(ibr_idx, seq_along(nm))]
index_cols <- nm[intersect(index_idx, seq_along(nm))]
analyte_cols <- nm[intersect(analyte_idx, seq_along(nm))]

# key id columns
lon_col <- "longitude"
lat_col <- "latitude"
site_col<- "site_name" 

# Choose response set: prioritize IBRs (overall) + biomarkers (mechanistic)
responses <- unique(c(intersect(c("ibr_combined","ibr_bio","ibr_morph"), ibrs),
                      intersect(c("p450","sod"), biomarkers)))
if (length(responses) == 0) responses <- c(ibrs, biomarkers)[1:min(3, length(c(ibrs, biomarkers)))]

# Coerce to sf and project to meters
site_sf <- st_as_sf(site_data, coords = c(lon_col, lat_col), crs = 4326)
site_sf <- st_transform(site_sf, 3857)
xy <- st_coordinates(site_sf)

# Neighborhood weights (k-NN with k = sqrt(n) capped at 8)
k_default <- max(2, min(8, ceiling(sqrt(nrow(site_sf)))))
nb_knn <- knn2nb(knearneigh(xy, k = k_default))
if (any(card(nb_knn) == 0)) {
  k_default <- max(k_default + 1, 3)
  nb_knn <- knn2nb(knearneigh(xy, k = k_default))
}
lw <- nb2listw(nb_knn, style = "W")

message(sprintf("weights: %d-NN (style=W)", k_default))

# 1) Global & Local autocorrelation (clean, single pass; values as-is)
moran_results <- list()
lisa_results  <- list()

for (resp in responses) {
  if (!resp %in% names(site_data)) next

  y  <- site_data[[resp]]
  ly <- lag.listw(lw, y)

  # Global Moran's I
  moran_results[[resp]] <- moran.test(y, lw)

  # Local Moran's I (LISA)
  li <- localmoran(y, lw)

  out <- site_sf
  out$resp <- resp
  out$Ii   <- li[,1]
  out$Z.Ii <- li[,4]
  out$p    <- li[,5]
  out$p_fdr <- p.adjust(out$p, method = "fdr")   # optional but helpful

  # Simple cluster labeling relative to overall mean (since not z-scored)
  m_y  <- mean(y,  na.rm = TRUE)
  m_ly <- mean(ly, na.rm = TRUE)

  out$cluster <- dplyr::case_when(
    out$p_fdr < 0.05 & y  > m_y  & ly > m_ly ~ "High-High",
    out$p_fdr < 0.05 & y  < m_y  & ly < m_ly ~ "Low-Low",
    out$p_fdr < 0.05 & y  > m_y  & ly < m_ly ~ "High-Low",
    out$p_fdr < 0.05 & y  < m_y  & ly > m_ly ~ "Low-High",
    TRUE ~ "NS"
  )

  # carry through reporting_area for faceting
  out$reporting_area <- site_data$reporting_area

  lisa_results[[resp]] <- out
}

# Example map for IBR clusters
if ("ibr_combined" %in% names(lisa_results)) {
  tm_shape(lisa_results[["ibr_combined"]]) +
    tm_dots(col = "cluster", size = 0.15, title = "lisa: ibr_combined") +
    tm_layout(legend.outside = TRUE)
}

# GLOBAL MORAN'S I SUMMARY -----------------------------------------------
# creates a tibble with metric, Moran's I, expected I, variance, z, p, FDR, significance, n_sites, k
global_moran_table <- dplyr::bind_rows(lapply(names(moran_results), function(resp) {
  mres <- moran_results[[resp]]
  # robust extraction
  est <- suppressWarnings(unname(mres$estimate["Moran I statistic"]))
  ei  <- suppressWarnings(unname(mres$estimate["Expectation"]))
  vi  <- suppressWarnings(unname(mres$estimate["Variance"]))
  if (is.na(est) || is.na(ei) || is.na(vi)) {
    # fallback: try to compute z if needed
    zval <- as.numeric(mres$statistic)
  } else {
    zval <- (est - ei) / sqrt(vi)
  }
  tibble::tibble(
    metric         = resp,
    moran_I        = est,
    expected_I     = ei,
    variance       = vi,
    z              = zval,
    p_value        = mres$p.value
  )
})) %>%
  dplyr::mutate(
    p_fdr          = p.adjust(p_value, method = "fdr"),
    sig_p05        = p_value < 0.05,
    sig_fdr05      = p_fdr   < 0.05,
    direction      = dplyr::case_when(moran_I > 0 ~ "positive", moran_I < 0 ~ "negative", TRUE ~ "≈0"),
    n_sites        = nrow(site_sf),
    k_neighbors    = k_default
  ) %>%
  dplyr::arrange(p_value)

global_moran_table
#write.csv(global_moran_table, "../output/tables/global_moran_10042025.csv", row.names = FALSE)

# LISA SUMMARY (site-level) ----------------------------------------------
# adds site name and (if present) reporting_area; flags p<0.05 and FDR<0.05

lisa_table <- dplyr::bind_rows(lapply(names(lisa_results), function(resp) {
  x  <- lisa_results[[resp]]
  df <- sf::st_drop_geometry(x)
  # ensure metric name column
  if (!"resp" %in% names(df)) df$resp <- resp
  # attach site + reporting area from your original data (row order should match)
  df[[site_col]] <- site_data[[site_col]]
  if ("reporting_area" %in% names(site_data) && !"reporting_area" %in% names(df)) {
    df$reporting_area <- site_data$reporting_area
  }
  # FDR across sites within each metric
  if (!"p_fdr" %in% names(df)) {
    df$p_fdr <- p.adjust(df$p, method = "fdr")
  }
  dplyr::select(df,
                metric = resp,
                !!site_col,
                dplyr::any_of("reporting_area"),
                Ii, Z.Ii, p, p_fdr, cluster) %>%
    dplyr::mutate(sig_p05   = p    < 0.05,
                  sig_fdr05 = p_fdr < 0.05)
}), .id = NULL) %>%
  dplyr::arrange(metric, p)

lisa_table
#write.csv(lisa_table, "../output/tables/lisa_10042025.csv", row.names = FALSE)

```

### remaining metrics - global morans & lisa
```{r}

# group the columns you want to scan
metric_groups <- list(
  biomarkers    = biomarkers,
  morphometrics = morphometrics,
  conditions    = conditions,
  ibrs          = ibrs,
  indices       = index_cols
)

# keep only columns that exist & are non-empty
metric_groups <- lapply(metric_groups, function(v) v[v %in% names(site_data)])
metric_groups <- metric_groups[sapply(metric_groups, length) > 0]

# a helper for the site id column name
sc <- if (exists("site_col")) site_col else "site_name"

library(dplyr)
library(tibble)

safe_moran <- function(y) {
  # skip NA/constant vectors
  if (all(is.na(y)) || (sd(y, na.rm = TRUE) %||% 0) == 0) return(NULL)
  res <- moran.test(y, lw)
  est <- suppressWarnings(unname(res$estimate["Moran I statistic"]))
  ei  <- suppressWarnings(unname(res$estimate["Expectation"]))
  vi  <- suppressWarnings(unname(res$estimate["Variance"]))
  z   <- if (is.finite(vi) && !is.na(vi)) (est - ei)/sqrt(vi) else as.numeric(res$statistic)
  tibble(moran_I = est, expected_I = ei, variance = vi, z = z, p_value = res$p.value)
}

`%||%` <- function(a, b) if (is.null(a) || is.na(a)) b else a

global_moran_table_all <- bind_rows(lapply(names(metric_groups), function(g) {
  cols <- metric_groups[[g]]
  bind_rows(lapply(cols, function(colname) {
    y <- site_data[[colname]]
    mr <- safe_moran(y)
    if (is.null(mr)) return(NULL)
    mutate(mr, group = g, metric = colname, n_sites = nrow(site_sf))
  }))
})) %>%
  mutate(p_fdr_all = p.adjust(p_value, "fdr"),
         sig_p05   = p_value   < 0.05,
         sig_fdr05 = p_fdr_all < 0.05) %>%
  select(group, metric, n_sites, moran_I, expected_I, variance, z, p_value, p_fdr_all, sig_p05, sig_fdr05) %>%
  arrange(p_value)

global_moran_table_all
#write.csv(global_moran_table_all, "../output/tables/global_moran_all_10042025.csv", row.names = FALSE)


lisa_table_all <- bind_rows(lapply(names(metric_groups), function(g) {
  cols <- metric_groups[[g]]
  bind_rows(lapply(cols, function(colname) {
    y <- site_data[[colname]]
    if (all(is.na(y)) || (sd(y, na.rm = TRUE) %||% 0) == 0) return(NULL)

    li <- localmoran(y, lw)
    ly <- lag.listw(lw, y)

    out <- sf::st_drop_geometry(site_sf)
    out$Ii   <- li[,1]
    out$Z.Ii <- li[,4]
    out$p    <- li[,5]
    out$metric <- colname
    out$group  <- g
    out[[sc]]  <- site_data[[sc]]
    if ("reporting_area" %in% names(site_data)) out$reporting_area <- site_data$reporting_area

    m_y  <- mean(y,  na.rm = TRUE)
    m_ly <- mean(ly, na.rm = TRUE)
    out$cluster <- dplyr::case_when(
      out$p < 0.05 & y  > m_y & ly > m_ly ~ "High-High",
      out$p < 0.05 & y  < m_y & ly < m_ly ~ "Low-Low",
      out$p < 0.05 & y  > m_y & ly < m_ly ~ "High-Low",
      out$p < 0.05 & y  < m_y & ly > m_ly ~ "Low-High",
      TRUE ~ "NS"
    )
    out
  }))
}))

# add FDR choices:
# (a) FDR within each metric (common for LISA)
lisa_table_all <- lisa_table_all %>%
  group_by(metric) %>%
  mutate(p_fdr_metric = p.adjust(p, "fdr")) %>%
  ungroup() %>%
  mutate(sig_p05   = p < 0.05,
         sig_fdr05 = p_fdr_metric < 0.05)

# (b) Optional: FDR within reporting area, per metric (uncomment if you prefer):
# lisa_table_all <- lisa_table_all %>%
#   group_by(metric, reporting_area) %>%
#   mutate(p_fdr_area = p.adjust(p, "fdr")) %>%
#   ungroup()

# nice ordering
lisa_table_all <- lisa_table_all %>%
  relocate(group, metric, !!sc, reporting_area, Ii, Z.Ii, p, p_fdr_metric, sig_p05, sig_fdr05, cluster, .before = 1)

lisa_table_all
#write.csv(lisa_table_all, "../output/tables/lisa_all_10042025.csv", row.names = FALSE)

```


## GETIS-ORD Gi - Hot/ cold spot analysis 
```{r}
# ─────────────────────────────────────────────────────────────────────────────────────
# 2) GETIS-ORD Gi* HOTSPOT / COLDSPOT ANALYSIS
# ─────────────────────────────────────────────────────────────────────────────────────
# Metric guidance:
# - Use IBR and also try the *most responsive* biomarker (e.g., p450 for PAHs) to find intensity clusters.
# - Gi* is magnitude-focused; results can differ from LISA.

getis_results <- list()
for (resp in RESPONSES) {
  if (!resp %in% names(site_data)) next
  Y <- z(site_data[[resp]])
  Gi <- as.numeric(localG(Y, lw))
  out <- site_sf
  out$Gi <- Gi
  out$resp <- resp
  out$hotcold <- cut(Gi, breaks = classInt::classIntervals(Gi, n = 5, style = "pretty")$brks,
                     include.lowest = TRUE, labels = FALSE)
  getis_results[[resp]] <- out
}

# Example map for p450 hotspots
if (CFG$y_p450 %in% names(getis_results)) {
  tm_shape(getis_results[[CFG$y_p450]]) +
    tm_dots(col = "Gi", size = 0.15, title = paste("Getis-Ord Gi*:", CFG$y_p450)) +
    tm_layout(legend.outside = TRUE)
}

# ─────────────────────────────────────────────────────────────────────────────────────
# 3) INTERPOLATION (IDW & ORDINARY KRIGING)
# ─────────────────────────────────────────────────────────────────────────────────────
# Metric guidance:
# - Interpolate a continuous indicator (often IBR). If a single biomarker strongly tracks a contaminant class, interpolate that too.
# - Kriging requires a reasonable variogram; otherwise, use IDW as baseline.

# Build a simple grid covering your study area
bbox <- st_bbox(site_sf)
# Create a grid with ~2 km spacing (tune as needed)
res_m <- 2000
xs <- seq(bbox[1], bbox[3], by = res_m)
ys <- seq(bbox[2], bbox[4], by = res_m)
grid <- expand.grid(x = xs, y = ys)
grid_sf <- st_as_sf(grid, coords = c("x","y"), crs = st_crs(site_sf))

# Choose a response for interpolation (example: IBR)
if (CFG$y_IBR %in% names(site_data)) {
  df_sp <- as(site_sf |> dplyr::mutate(Y = site_data[[CFG$y_IBR]]), "Spatial")
  grid_sp <- as(grid_sf, "Spatial")

  # IDW
  idw_pred <- gstat::idw(Y ~ 1, locations = df_sp, newdata = grid_sp)

  # Kriging (spherical model as a starting point)
  v <- variogram(Y ~ 1, data = df_sp)
  vm <- fit.variogram(v, model = vgm("Sph"))
  kr_pred <- gstat::krige(Y ~ 1, df_sp, grid_sp, model = vm)

  # Compare visually by mapping in tmap (convert back to sf)
  idw_sf <- st_as_sf(idw_pred)
  kr_sf  <- st_as_sf(kr_pred)

  # Map Kriging result
  tm_shape(kr_sf) + tm_raster(col = "var1.pred", alpha = 0.8, title = paste("Kriged", CFG$y_IBR)) +
    tm_shape(site_sf) + tm_dots(size = 0.05) + tm_layout(legend.outside = TRUE)
}

# ─────────────────────────────────────────────────────────────────────────────────────
# 4) SPATIAL REGRESSION (OLS + residual Moran; SAR/SEM/SDM)
# ─────────────────────────────────────────────────────────────────────────────────────
# Metric guidance:
# - Response: Pick IBR first (integrated signal). Then test key biomarkers separately.
# - Predictors: Start with contaminant *class sums / indices* (e.g., PAH_sum, Metals_sum) for stability and interpretability.
#   Add individual analytes in sensitivity analyses (beware multicollinearity; standardize or use PCA of analytes).

# Prepare modeling frame using index sets
idx_df  <- as.data.frame(site_data[, CFG$idx_cols, drop = FALSE])
ana_df  <- as.data.frame(site_data[, CFG$analyte_cols, drop = FALSE])

# Transform indices (log+z unless already z_*) and analytes similarly
for (nm_i in names(idx_df))  idx_df[[nm_i]] <- lz(idx_df[[nm_i]], nm_i)
for (nm_a in names(ana_df))  ana_df[[nm_a]] <- lz(ana_df[[nm_a]], nm_a)

# Response: first of RESPONSES (prefer ibr_combined if present)
resp_order <- c("ibr_combined", RESPONSES)
resp_name <- unique(resp_order[resp_order %in% names(site_data)])[1]
Y <- site_data[[resp_name]]

mod_df <- cbind(Y = as.numeric(Y), idx_df, ana_df)

# OLS baseline with indices first (more stable), then (optionally) a small set of analytes
# Tip: to limit analytes, pick a few mechanistic ones (e.g., z_benzo_a_pyrene, z_PCB153)
keep_analytes <- intersect(c("z_benzo_a_pyrene","z_PCB153","z_zinc","z_copper","z_mercury"), names(ana_df))
X_df <- cbind(idx_df, ana_df[, keep_analytes, drop = FALSE])
ols <- lm(Y ~ ., data = cbind(Y = mod_df[,"Y"], X_df))
summary(ols)

# Residual spatial autocorrelation
lw <- nb2listw(knn2nb(knearneigh(xy, k = max(2, min(8, ceiling(sqrt(nrow(site_sf))))))), style = "W")
moran.test(z(residuals(ols)), lw)

o_res <- residuals(ols)
moran.test(z(o_res), lw)

# If residuals autocorrelated → Spatial models
sar <- try(lagsarlm(formula(ols), data = cbind(st_drop_geometry(site_sf), cbind(Y = mod_df[,"Y"], X_df)), listw = lw))
sem <- try(errorsarlm(formula(ols), data = cbind(st_drop_geometry(site_sf), cbind(Y = mod_df[,"Y"], X_df)), listw = lw))
if (!inherits(sar, "try-error")) summary(sar)
if (!inherits(sem, "try-error")) summary(sem)
# Choose via AIC + residual Moran’s I diagnostics

# ─────────────────────────────────────────────────────────────────────────────────────
# 5) MULTIVARIATE SPATIAL PATTERNS (Mantel / RDA + MEM)
# ─────────────────────────────────────────────────────────────────────────────────────
# Response matrix from metrics (use up to three to balance signal)
Y_vars <- RESPONSES[RESPONSES %in% names(site_data)]
Y_mat <- as.matrix(scale(site_data[, Y_vars, drop = FALSE]))
X_df  <- as.data.frame(idx_df)  # indices as primary explanatory set

# Spatial eigenfunctions (MEM)
coords_mat <- as.matrix(xy)
mem <- dbmem(coords_mat)

# RDA with environment + space
rda_env_space <- rda(Y_mat ~ ., data = cbind(X_df, as.data.frame(mem)))
summary(rda_env_space)
anova(rda_env_space, by = "terms")

# Variation partitioning: env vs space
vp <- varpart(Y_mat, X_df, as.data.frame(mem))
print(vp)

# Mantel test comparing biomarker and contaminant dissimilarities
bio_dist <- dist(scale(site_data[, Y_vars, drop = FALSE]))
con_dist <- dist(scale(X_df))
mantel_res <- mantel(bio_dist, con_dist, permutations = 999)
print(mantel_res)
# ─────────────────────────────────────────────────────────────────────────────────────
# Metric guidance:
# - Use a matrix of biomarkers (e.g., cbind(IBR, p450, sod)).
# - Explanatory set: contaminant indices first (PAH_sum, Metals_sum, etc.).
# - Alternative: reduce individual analytes with PCA, then use top PCs as predictors.

# Build response and predictor matrices (drop missing columns automatically)
Y_vars <- RESPONSES[RESPONSES %in% names(site_data)]
X_idx  <- c(CFG$x_PAH_sum, CFG$x_metals_sum)
X_idx  <- X_idx[X_idx %in% names(site_data)]

Y_mat <- as.matrix(scale(site_data[, Y_vars]))
X_df  <- as.data.frame(site_data[, X_idx, drop = FALSE])
X_df[] <- lapply(X_df, lz)  # log-scale + z-score for indices

# Spatial eigenfunctions (MEM) from coordinates
coords_mat <- as.matrix(st_coordinates(site_sf))
mem <- dbmem(coords_mat)

# RDA with environment + space (partial out space or include jointly)
rda_env_space <- rda(Y_mat ~ ., data = cbind(X_df, as.data.frame(mem)))
summary(rda_env_space)
anova(rda_env_space, by = "terms")

# Variation partitioning example: env vs space (vegan::varpart)
if (ncol(X_df) > 0) {
  vp <- varpart(Y_mat, X_df, as.data.frame(mem))
  print(vp)
}

# Mantel test comparing biomarker and contaminant dissimilarities
if (ncol(X_df) > 0) {
  bio_dist <- dist(scale(site_data[, Y_vars]))
  con_dist <- dist(scale(X_df))
  mantel_res <- mantel(bio_dist, con_dist, permutations = 999)
  print(mantel_res)
}

# ─────────────────────────────────────────────────────────────────────────────────────
# 6) GEOGRAPHICALLY WEIGHTED REGRESSION (GWR)
# ─────────────────────────────────────────────────────────────────────────────────────
# Metric guidance:
# - Response: IBR or the biomarker most mechanistically linked to contaminants (e.g., p450 ~ PAH).
# - Predictors: Start with 1–2 key indices to avoid overfitting; GWR prefers n_sites >= ~40.

if (nrow(site_sf) >= 40 && all(c("PAH","MET") %in% names(mod_df))) {
  df_sp <- SpatialPointsDataFrame(coords = xy, data = cbind(st_drop_geometry(site_sf), mod_df), proj4string = CRS(st_crs(site_sf)$wkt))
  bw <- bw.gwr(Y ~ PAH + MET, data = df_sp, approach = "AICc", adaptive = TRUE)
  gwr_fit <- gwr.basic(Y ~ PAH + MET, data = df_sp, bw = bw, adaptive = TRUE)
  # Local coefficients and R^2 are in gwr_fit$SDF
  # Map local R^2
  gwr_sf <- st_as_sf(gwr_fit$SDF)
  tm_shape(gwr_sf) + tm_dots(col = "localR2", size = 0.15, title = "GWR local R^2") + tm_layout(legend.outside = TRUE)
}

# ─────────────────────────────────────────────────────────────────────────────────────
# 7) SPATIALLY CONSTRAINED CLUSTERING (zonation)
# ─────────────────────────────────────────────────────────────────────────────────────
# Metric guidance:
# - Use a biomarker profile matrix (e.g., IBR, p450, sod) and incorporate spatial proximity
#   so clusters are contiguous. Consider clustGeo (biological + spatial dissimilarity balance).

# Prepare dissimilarities
bio_mat <- scale(site_data[, Y_vars])
bio_dist <- dist(bio_mat)
# Spatial distance (in meters)
sp_dist <- dist(xy)

# Combine distances (alpha balances biology vs space; try 0.6)
alpha <- 0.6
D <- (1 - alpha) * as.matrix(bio_dist) + alpha * as.matrix(sp_dist) / max(sp_dist)
# Hierarchical clustering
hc <- hclust(as.dist(D), method = "ward.D2")
# Choose k clusters (inspect dendrogram / silhouette)
k <- 4
cl <- cutree(hc, k = k)
site_sf$zone <- factor(cl)

# Map zones
tm_shape(site_sf) + tm_dots(col = "zone", size = 0.18, title = sprintf("Spatially constrained zones (k=%d)", k)) +
  tm_layout(legend.outside = TRUE)

# ─────────────────────────────────────────────────────────────────────────────────────
# 8) METRIC SELECTION NOTES (AT-A-GLANCE)
# ─────────────────────────────────────────────────────────────────────────────────────
# • Global Moran's / LISA: IBR (robust), plus each biomarker (p450/sod) to attribute clusters.
# • Getis-Ord Gi*: IBR or biomarker with strongest expected link to a contaminant class.
# • Interpolation: IBR for overall field; add biomarker if mechanism is clear (e.g., p450 ↔ PAH).
# • Spatial regression: IBR ~ contaminant indices first; then sensitivity with individual analytes or analyte PCs.
# • Multivariate (RDA+MEM): response = cbind(IBR, p450, sod); predictors = contaminant indices (± analyte PCs), + spatial MEM.
# • GWR: pick 1–2 predictors (indices) to avoid instability; interpret local R^2 and coefficient maps.
# • Clustering: use biomarker matrix; blend in spatial distances for contiguous ecological zones.

# ─────────────────────────────────────────────────────────────────────────────────────
# 9) QUICK CHECKS & TIPS
# ─────────────────────────────────────────────────────────────────────────────────────
# • Always visualize neighbors (plot(nb_knn, xy)) and try sensitivity (k ± 1–2).
# • Standardize responses (z-score) for autocorrelation tests; log+z for skewed contaminants.
# • Multiple testing: when mapping many local stats, consider p.adjust(..., method='fdr').
# • Collinearity: if using many analytes, consider PCA or sparse regression before spatial models.
# • Reproducibility: set a seed for permutation-based tests if you use Monte Carlo options.

# END OF CODE KIT


```

## plotting LISA output
### testing p450 to spot check LISA results
```{r}


```

# OLD CODE - Verify before using
## mapping p450 LISA clusters to visualize the results before moving to the next steps
```{r}

library(tmap)

# basic LISA plot
tm_shape(lisa_p450) +
  tm_symbols(col = "p450_lisa_cluster",
             palette = "Set1",
             size = 0.5,
             title.col = "LISA Cluster") +
  tm_layout(main.title = "LISA Clusters for P450 Biomarker")

# only signficant clusters
tm_shape(lisa_p450) +
  tm_symbols(col = "p450_lisa_cluster",
             palette = c("High-High" = "red",
                         "Low-Low" = "blue",
                         "Outlier" = "purple",
                         "Not Significant" = "grey80"),
             size = 0.5,
             title.col = "Cluster Type") +
  tm_layout(main.title = "Significant LISA Clusters (P450)")

# table of results
table(lisa_p450$p450_lisa_cluster)

# adding WA basemap for another way to see the clusters
library(rnaturalearth)

# grab WA
us_states <- ne_states(country = "united states of america", returnclass = "sf")
wa_outline <- us_states[us_states$name == "Washington", ]

library(tmap)

tm_shape(wa_outline) +
  tm_borders(col = "gray30") +
tm_shape(lisa_p450) +
  tm_symbols(col = "p450_lisa_cluster",
             palette = c("High-High" = "red",
                         "Low-Low" = "blue",
                         "Outlier" = "purple",
                         "Not Significant" = "gray80"),
             size = 0.5,
             title.col = "Cluster Type") +
  tm_layout(main.title = "LISA Clusters for P450 Biomarker")


```

## creating LISA summary table
```{r}

# Directly from Chat GPT

library(stringr)

# Get list of all LISA geojson files
lisa_files <- list.files("lisa_outputs", pattern = "\\.geojson$", full.names = TRUE)

# Create a summary table for each
lisa_summary <- lapply(lisa_files, function(file) {
  data <- st_read(file, quiet = TRUE)
  
  # Extract the variable name from the file name
  var_name <- str_extract(basename(file), "(?<=LISA_).*(?=\\.geojson)")
  
  # Identify cluster column (should be the only one with 'cluster' in name)
  cluster_col <- names(data)[grepl("cluster", names(data))][1]
  
  # Summarize cluster counts
  summary <- data %>%
    st_drop_geometry() %>%
    count(!!sym(cluster_col), name = "n") %>%
    mutate(variable = var_name, cluster = !!sym(cluster_col)) %>%
    select(variable, cluster, n)
  
  return(summary)
})

# Combine all summaries into one dataframe
all_lisa_summary <- bind_rows(lisa_summary)

#write.csv(all_lisa_summary, "/Users/cmantegna/Documents/Github/WDFWmussels/output/lisa_summary.csv", row.names = FALSE) # write it out

```

