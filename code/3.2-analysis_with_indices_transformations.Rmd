---
title: "3.2- Data Analysis with transformed and scaled metrics, IBRs and contaminant indices"
output:
  pdf_document: 
    fig_width: 20
    fig_height: 9
  html_document: 
    toc: true
    toc_float:
        collapsed: false
        smooth_scroll: true
    fig_width: 20
---

# Directory and doc rules

```{r, setup, eval=TRUE, include=TRUE, echo=FALSE}

knitr::opts_chunk$set(
  root.dir = here::here(),
  echo = TRUE,         # show code chunks
  eval = TRUE,         # evaluate code chunks
  warning = FALSE,     # hide warnings
  message = FALSE,     # hide messages
  #fig.width = 15,       # set plot width in inches
  #fig.height = 9,      # set plot height in inches
  fig.align = "center" # slign plots to the center in output doc/ slide/ whatever
)

# libraries
library("adespatial")
library(broom) # converting output tables to tidy tables for saving or easy view
library(classInt) # creating univariate variables for mapping
library(cluster) # grouping metrics - VERIFY still needed
library(devtools) # installing bespoke packages
library(dplyr) # data wrangling
library(factoextra) # pca/ nmds/ tweaking radars
library(FactoMineR) # pca/ nmds/ tweaking radars
library(fmsb) # polygon calculations for the radars
library(FSA) # post hoc test - Dunn's Test   
library(ggplot2) # plots
library("gstat")
library("GWmodel")
library(knitr) # output formatting
library(multcompView) # used for the letter assignment
library(pgirmess) # stats - KW
library(rcompanion) # for annotation of permanova
library(rstatix) # VERIFY what this is for      
library(RVAideMemoire) # post hoc test for permanova
library(scales) # scaling data for IBR - works with data wrangling packages
library(sf) # mapping - needed for converting to spatial data
library(spdep) # building spatial geometric components for analysis
library(spatialreg) # spatial regression analysis
library(tidyr) # data wrangling
library(tidyverse) # data wrangling
library(tmap) #mapping themes
library(vegan) # ecological stats 

```

# Load & Check Data
```{r}

# working from the clean data folder
getwd()

site_data<- read.csv("../data/site_with_indices_identifiers_analytes_10042025.csv") # for reporting area comparisons
#sample_data<- read.csv("../data/interim_df/sample_level_scaling_09292025.csv") # for site comparisons for the metrics
sample_ibr<- read.csv("../data/interim_df/sample_level_ibr_09292025.csv") # for the reporting area comparisons for the ibrs

```

# Data prep
```{r}

# make ID columns factors 
site_data$reporting_area <- as.factor(site_data$reporting_area)
site_data$site_name <- as.factor(site_data$site_name)
site_data$site_number <- as.factor(site_data$site_number)

sample_data$reporting_area <- as.factor(sample_data$reporting_area)
sample_data$site_name <- as.factor(sample_data$site_name)
sample_data$site_number <- as.factor(sample_data$site_number)

sample_ibr$reporting_area <- as.factor(sample_ibr$reporting_area)
sample_ibr$site_name <- as.factor(sample_ibr$site_name)
sample_ibr$site_number <- as.factor(sample_ibr$site_number)

```

# Asking: What is the distribution of my transformed and scaled metrics, my created IBRs, and the scaled contaminant indices?
## Shapiro- Wilks 
```{r}

# shapiro-wilks on scaled metrics and indices

shapiro_results <- site_data %>%
  select(6:34) %>%
  map_df(~ broom::tidy(shapiro.test(.x)), .id = "variable")

shapiro_results

# save
#write.csv(shapiro_results, "../output/tables/shapiro_scaled_and_indices_10042025.csv", row.names = FALSE)

```

# Asking: Are there differences between these values at the site and reporting area level?
## ANOVA 
### p450, weight_change, ci3, ibr_morph, length, width, height, weight_initial, weight_final
```{r}

#NOTE: RA comparisons using site_data, Site comparisons using sample_data for non-ibr metrics, the tc value since it is the transformed and scaled value

#p450 - significant p-value for both 
p450_anova_site <- aov(tc_p450 ~ site_number, data = sample_data) # p-value= 1.25e-7
p450_anova_ra <- aov(p450 ~ reporting_area, data = site_data) # p-value= 0.0116
summary(p450_anova_site)
summary(p450_anova_ra)

#weight_change - non-significant p-value for both
wc_anova_site <- aov(tc_weight_change ~ site_number, data = sample_data) # p-value= 0.0674
wc_anova_ra <- aov(weight_change ~ reporting_area, data = site_data) # p-value= 0.177
summary(wc_anova_site)
summary(wc_anova_ra)

#ci3 - non-significant p-value for both. Note significance for site is at the edge, will posthoc for piece of mind
ci3_anova_site <- aov(tc_ci3 ~ site_number, data = sample_data) # p-value= 0.0507
ci3_anova_ra <- aov(ci3 ~ reporting_area, data = site_data) # p-value= 0.422
summary(ci3_anova_site)
summary(ci3_anova_ra)

#ibr_morph - significant p-value for both
morph_anova_site <- aov(ibr_morphometric ~ site_number, data = sample_ibr) # p-value= 2.65e-10
morph_anova_ra <- aov(ibr_morph ~ reporting_area, data = site_data) # p-value= 0.048
summary(morph_anova_site)
summary(morph_anova_ra)

# these may not be consequential in what I need, but running just in case
#length - significant p-value for site, non-significant p=value for reporting area
len_anova_site <- aov(tc_length ~ site_number, data = sample_data) # p-value= 0.0128
len_anova_ra <- aov(length ~ reporting_area, data = site_data) # p-value= 0.594
summary(len_anova_site)
summary(len_anova_ra)

#width - significant p-value for site, non-significant p=value for reporting area
wid_anova_site <- aov(tc_width ~ site_number, data = sample_data) # p-value= 0.000336
wid_anova_ra <- aov(width ~ reporting_area, data = site_data) # p-value= 0.214
summary(wid_anova_site)
summary(wid_anova_ra)

#height - significant p-value for site, non-significant p=value for reporting area
hei_anova_site <- aov(tc_height ~ site_number, data = sample_data) # p-value= 0.00987
hei_anova_ra <- aov(height ~ reporting_area, data = site_data) # p-value= 0.22
summary(hei_anova_site)
summary(hei_anova_ra)

#weight initial - non-significant p-value for both.
wi_anova_site <- aov(tc_weight_initial ~ site_number, data = sample_data) # p-value= 0.0954
wi_anova_ra <- aov(weight_initial ~ reporting_area, data = site_data) # p-value= 0.0519
summary(wi_anova_site)
summary(wi_anova_ra)

#weight final - significant p-value for site, non-significant p=value for reporting area
wf_anova_site <- aov(tc_weight_final ~ site_number, data = sample_data) # p-value= 0.00101
wf_anova_ra <- aov(weight_final ~ reporting_area, data = site_data) # p-value= 0.0767
summary(wf_anova_site)
summary(wf_anova_ra)

```

## Tukey's
### p450   
```{r}

#### p450, site: significant values returned
tuk <- TukeyHSD(p450_anova_site, "site_number")
tuk_df <- broom::tidy(tuk) %>%
  filter(term == "site_number") %>%
  separate(contrast, into = c("Group1", "Group2"), sep = "-") %>%
  mutate(Significant = ifelse(adj.p.value < 0.05, "Yes", "No"))
# cld letters
groups <- sort(unique(c(tuk_df$Group1, tuk_df$Group2)))
pval_matrix <- matrix(1, nrow = length(groups), ncol = length(groups),
                      dimnames = list(groups, groups))

for (i in seq_len(nrow(tuk_df))) {
  g1 <- tuk_df$Group1[i]; g2 <- tuk_df$Group2[i]
  p  <- as.numeric(tuk_df$adj.p.value[i])
  pval_matrix[g1, g2] <- p
  pval_matrix[g2, g1] <- p
}
cld_letters <- multcompLetters(pval_matrix < 0.05)$Letters
cld_df <- data.frame(Group = names(cld_letters), CLD = cld_letters, 
                     stringsAsFactors = FALSE)

tukey_table_with_cld <- tuk_df %>%
  left_join(cld_df, by = c("Group1" = "Group")) %>%
  rename(Group1_CLD = CLD) %>%
  left_join(cld_df, by = c("Group2" = "Group")) %>%
  rename(Group2_CLD = CLD)

view(tukey_table_with_cld)
#write.csv(tukey_table_with_cld, "../output/tukey_p450_site_10012025.csv", row.names = FALSE) 

#### p450 - reporting area: significant values returned
tuk <- TukeyHSD(p450_anova_ra, "reporting_area")
tuk_df <- broom::tidy(tuk) %>%
  filter(term == "reporting_area") %>%
  separate(contrast, into = c("Group1", "Group2"), sep = "-") %>%
  mutate(Significant = ifelse(adj.p.value < 0.05, "Yes", "No"))
# cld letters
groups <- sort(unique(c(tuk_df$Group1, tuk_df$Group2)))
pval_matrix <- matrix(1, nrow = length(groups), ncol = length(groups),
                      dimnames = list(groups, groups))

for (i in seq_len(nrow(tuk_df))) {
  g1 <- tuk_df$Group1[i]; g2 <- tuk_df$Group2[i]
  p  <- as.numeric(tuk_df$adj.p.value[i])
  pval_matrix[g1, g2] <- p
  pval_matrix[g2, g1] <- p
}
cld_letters <- multcompLetters(pval_matrix < 0.05)$Letters
cld_df <- data.frame(Group = names(cld_letters), CLD = cld_letters, 
                     stringsAsFactors = FALSE)

tukey_table_with_cld <- tuk_df %>%
  left_join(cld_df, by = c("Group1" = "Group")) %>%
  rename(Group1_CLD = CLD) %>%
  left_join(cld_df, by = c("Group2" = "Group")) %>%
  rename(Group2_CLD = CLD)

view(tukey_table_with_cld)
#write.csv(tukey_table_with_cld, "../output/tables/anova_kw_results/tukey_p450_ra_10012025.csv", row.names = FALSE) 

```

### ci3
```{r}

# ci3, site: no significant values returned
tuk <- TukeyHSD(ci3_anova_site, "site_number")
tuk_df <- broom::tidy(tuk) %>%
  filter(term == "site_number") %>%
  separate(contrast, into = c("Group1", "Group2"), sep = "-") %>%
  mutate(Significant = ifelse(adj.p.value < 0.05, "Yes", "No"))
# cld letters
groups <- sort(unique(c(tuk_df$Group1, tuk_df$Group2)))
pval_matrix <- matrix(1, nrow = length(groups), ncol = length(groups),
                      dimnames = list(groups, groups))

for (i in seq_len(nrow(tuk_df))) {
  g1 <- tuk_df$Group1[i]; g2 <- tuk_df$Group2[i]
  p  <- as.numeric(tuk_df$adj.p.value[i])
  pval_matrix[g1, g2] <- p
  pval_matrix[g2, g1] <- p
}
cld_letters <- multcompLetters(pval_matrix < 0.05)$Letters
cld_df <- data.frame(Group = names(cld_letters), CLD = cld_letters, 
                     stringsAsFactors = FALSE)

tukey_table_with_cld <- tuk_df %>%
  left_join(cld_df, by = c("Group1" = "Group")) %>%
  rename(Group1_CLD = CLD) %>%
  left_join(cld_df, by = c("Group2" = "Group")) %>%
  rename(Group2_CLD = CLD)

view(tukey_table_with_cld)
#write.csv(tukey_table_with_cld, "../output/tables/anova_kw_results/tukey_ci3_site_10032025.csv", row.names = FALSE) 

```

### ibr_morph
```{r}

#### ibr_morph, site: significant values returned
tuk <- TukeyHSD(morph_anova_site, "site_number")
tuk_df <- broom::tidy(tuk) %>%
  filter(term == "site_number") %>%
  separate(contrast, into = c("Group1", "Group2"), sep = "-") %>%
  mutate(Significant = ifelse(adj.p.value < 0.05, "Yes", "No"))
# cld letters
groups <- sort(unique(c(tuk_df$Group1, tuk_df$Group2)))
pval_matrix <- matrix(1, nrow = length(groups), ncol = length(groups),
                      dimnames = list(groups, groups))

for (i in seq_len(nrow(tuk_df))) {
  g1 <- tuk_df$Group1[i]; g2 <- tuk_df$Group2[i]
  p  <- as.numeric(tuk_df$adj.p.value[i])
  pval_matrix[g1, g2] <- p
  pval_matrix[g2, g1] <- p
}
cld_letters <- multcompLetters(pval_matrix < 0.05)$Letters
cld_df <- data.frame(Group = names(cld_letters), CLD = cld_letters, 
                     stringsAsFactors = FALSE)

tukey_table_with_cld <- tuk_df %>%
  left_join(cld_df, by = c("Group1" = "Group")) %>%
  rename(Group1_CLD = CLD) %>%
  left_join(cld_df, by = c("Group2" = "Group")) %>%
  rename(Group2_CLD = CLD)

view(tukey_table_with_cld)
#write.csv(tukey_table_with_cld, "../output/tables/anova_kw_results/tukey_morph_site_10052025.csv", row.names = FALSE) 

#### ibr_morphometrics, reporting area: no significant result
tuk <- TukeyHSD(morph_anova_ra, "reporting_area")
tuk_df <- broom::tidy(tuk) %>%
  filter(term == "reporting_area") %>%
  separate(contrast, into = c("Group1", "Group2"), sep = "-") %>%
  mutate(Significant = ifelse(adj.p.value < 0.05, "Yes", "No"))
# cld letters
groups <- sort(unique(c(tuk_df$Group1, tuk_df$Group2)))
pval_matrix <- matrix(1, nrow = length(groups), ncol = length(groups),
                      dimnames = list(groups, groups))

for (i in seq_len(nrow(tuk_df))) {
  g1 <- tuk_df$Group1[i]; g2 <- tuk_df$Group2[i]
  p  <- as.numeric(tuk_df$adj.p.value[i])
  pval_matrix[g1, g2] <- p
  pval_matrix[g2, g1] <- p
}
cld_letters <- multcompLetters(pval_matrix < 0.05)$Letters
cld_df <- data.frame(Group = names(cld_letters), CLD = cld_letters, 
                     stringsAsFactors = FALSE)

tukey_table_with_cld <- tuk_df %>%
  left_join(cld_df, by = c("Group1" = "Group")) %>%
  rename(Group1_CLD = CLD) %>%
  left_join(cld_df, by = c("Group2" = "Group")) %>%
  rename(Group2_CLD = CLD)

view(tukey_table_with_cld)
#write.csv(tukey_table_with_cld, "../output/tables/anova_kw_results/tukey_ibr_morph_ra_10012025.csv", row.names = FALSE)

```

### length
```{r}

# length, site: no significant result
tuk <- TukeyHSD(len_anova_site, "site_number")
tuk_df <- broom::tidy(tuk) %>%
  filter(term == "site_number") %>%
  separate(contrast, into = c("Group1", "Group2"), sep = "-") %>%
  mutate(Significant = ifelse(adj.p.value < 0.05, "Yes", "No"))
# cld letters
groups <- sort(unique(c(tuk_df$Group1, tuk_df$Group2)))
pval_matrix <- matrix(1, nrow = length(groups), ncol = length(groups),
                      dimnames = list(groups, groups))

for (i in seq_len(nrow(tuk_df))) {
  g1 <- tuk_df$Group1[i]; g2 <- tuk_df$Group2[i]
  p  <- as.numeric(tuk_df$adj.p.value[i])
  pval_matrix[g1, g2] <- p
  pval_matrix[g2, g1] <- p
}
cld_letters <- multcompLetters(pval_matrix < 0.05)$Letters
cld_df <- data.frame(Group = names(cld_letters), CLD = cld_letters, 
                     stringsAsFactors = FALSE)

tukey_table_with_cld <- tuk_df %>%
  left_join(cld_df, by = c("Group1" = "Group")) %>%
  rename(Group1_CLD = CLD) %>%
  left_join(cld_df, by = c("Group2" = "Group")) %>%
  rename(Group2_CLD = CLD)

view(tukey_table_with_cld)
#write.csv(tukey_table_with_cld, "../output/tables/anova_kw_results/tukey_length_site_10012025.csv", row.names = FALSE) 

```

### width
```{r}

# width, site: significant results returned
tuk <- TukeyHSD(wid_anova_site, "site_number")
tuk_df <- broom::tidy(tuk) %>%
  filter(term == "site_number") %>%
  separate(contrast, into = c("Group1", "Group2"), sep = "-") %>%
  mutate(Significant = ifelse(adj.p.value < 0.05, "Yes", "No"))
# cld letters
groups <- sort(unique(c(tuk_df$Group1, tuk_df$Group2)))
pval_matrix <- matrix(1, nrow = length(groups), ncol = length(groups),
                      dimnames = list(groups, groups))

for (i in seq_len(nrow(tuk_df))) {
  g1 <- tuk_df$Group1[i]; g2 <- tuk_df$Group2[i]
  p  <- as.numeric(tuk_df$adj.p.value[i])
  pval_matrix[g1, g2] <- p
  pval_matrix[g2, g1] <- p
}
cld_letters <- multcompLetters(pval_matrix < 0.05)$Letters
cld_df <- data.frame(Group = names(cld_letters), CLD = cld_letters, 
                     stringsAsFactors = FALSE)

tukey_table_with_cld <- tuk_df %>%
  left_join(cld_df, by = c("Group1" = "Group")) %>%
  rename(Group1_CLD = CLD) %>%
  left_join(cld_df, by = c("Group2" = "Group")) %>%
  rename(Group2_CLD = CLD)

view(tukey_table_with_cld)
#write.csv(tukey_table_with_cld, "../output/tables/anova_kw_results/tukey_width_site_10012025.csv", row.names = FALSE) 

```

### height
```{r}

# height, site: significant result returned
tuk <- TukeyHSD(hei_anova_site, "site_number")
tuk_df <- broom::tidy(tuk) %>%
  filter(term == "site_number") %>%
  separate(contrast, into = c("Group1", "Group2"), sep = "-") %>%
  mutate(Significant = ifelse(adj.p.value < 0.05, "Yes", "No"))
# cld letters
groups <- sort(unique(c(tuk_df$Group1, tuk_df$Group2)))
pval_matrix <- matrix(1, nrow = length(groups), ncol = length(groups),
                      dimnames = list(groups, groups))

for (i in seq_len(nrow(tuk_df))) {
  g1 <- tuk_df$Group1[i]; g2 <- tuk_df$Group2[i]
  p  <- as.numeric(tuk_df$adj.p.value[i])
  pval_matrix[g1, g2] <- p
  pval_matrix[g2, g1] <- p
}
cld_letters <- multcompLetters(pval_matrix < 0.05)$Letters
cld_df <- data.frame(Group = names(cld_letters), CLD = cld_letters, 
                     stringsAsFactors = FALSE)

tukey_table_with_cld <- tuk_df %>%
  left_join(cld_df, by = c("Group1" = "Group")) %>%
  rename(Group1_CLD = CLD) %>%
  left_join(cld_df, by = c("Group2" = "Group")) %>%
  rename(Group2_CLD = CLD)

view(tukey_table_with_cld)
#write.csv(tukey_table_with_cld, "../output/tables/anova_kw_results/tukey_height_site_10022025.csv", row.names = FALSE) 

```

### weight_final
```{r}

# weight_final, site: significant result returned
tuk <- TukeyHSD(wf_anova_site, "site_number")
tuk_df <- broom::tidy(tuk) %>%
  filter(term == "site_number") %>%
  separate(contrast, into = c("Group1", "Group2"), sep = "-") %>%
  mutate(Significant = ifelse(adj.p.value < 0.05, "Yes", "No"))
# cld letters
groups <- sort(unique(c(tuk_df$Group1, tuk_df$Group2)))
pval_matrix <- matrix(1, nrow = length(groups), ncol = length(groups),
                      dimnames = list(groups, groups))

for (i in seq_len(nrow(tuk_df))) {
  g1 <- tuk_df$Group1[i]; g2 <- tuk_df$Group2[i]
  p  <- as.numeric(tuk_df$adj.p.value[i])
  pval_matrix[g1, g2] <- p
  pval_matrix[g2, g1] <- p
}
cld_letters <- multcompLetters(pval_matrix < 0.05)$Letters
cld_df <- data.frame(Group = names(cld_letters), CLD = cld_letters, 
                     stringsAsFactors = FALSE)

tukey_table_with_cld <- tuk_df %>%
  left_join(cld_df, by = c("Group1" = "Group")) %>%
  rename(Group1_CLD = CLD) %>%
  left_join(cld_df, by = c("Group2" = "Group")) %>%
  rename(Group2_CLD = CLD)

view(tukey_table_with_cld)
#write.csv(tukey_table_with_cld, "../output/tables/anova_kw_results/tukey_weight_final_site_10012025.csv", row.names = FALSE) 

```

## Kruskal-Wallis
### both biomarkers, sod, ci1, ci2, shell, ibr_bio, ibr_combined, and all of the contaminant indices
```{r}

# both biomarkers - no significant result
kruskal.test(tc_p450 ~ tc_sod, data = sample_data) # p-value = 0.478 at site-level, p-value = 0.5131 at sample-level

# sod - significant p-value for site, non-significant p=value for reporting area
kruskal.test(tc_sod ~ site_number, data = sample_data) # p-value = 0.001777
kruskal.test(sod ~ reporting_area, data = site_data) # p-value = 0.7705

# ci1 - significant p-value for site, non-significant p=value for reporting area
kruskal.test(tc_ci1 ~ site_number, data = sample_data) # p-value = 0.001056
kruskal.test(ci1 ~ reporting_area, data = site_data) # p-value = 0.991

# ci2 - significant p-value for site, non-significant p=value for reporting area
kruskal.test(tc_ci2 ~ site_number, data = sample_data) # p-value = 2.191e-8
kruskal.test(ci2 ~ reporting_area, data = site_data) # p-value = 0.8179

# shell - significant p-value for both
kruskal.test(tc_shell ~ site_number, data = sample_data) # p-value = 1.092e-08
kruskal.test(shell ~ reporting_area, data = site_data) # p-value = 0.0204

# ibr_bio - significant p-value for site, non-significant p=value for reporting area
kruskal.test(ibr_biomarker ~ site_number, data = sample_ibr) # p-value = 0.000902
kruskal.test(ibr_bio ~ reporting_area, data = site_data) # p-value = 0.6185

# ibr_combined - significant p-value for site, non-significant p-value for reporting area
kruskal.test(ibr_total ~ site_number, data = sample_ibr) # p-value = 0.0001618
kruskal.test(ibr_combined ~ reporting_area, data = site_data) # p-value = 0.4618

# chlordane_index - significant
kruskal.test(chlordane_index ~ reporting_area, data = site_data) # p-value = 0.0001187

# ddt_index - significant
kruskal.test(ddt_index ~ reporting_area, data = site_data) # p-value = 6.389e-06

# hch_index - not significant
kruskal.test(hch_index ~ reporting_area, data = site_data) # p-value = 0.1796

# heavy_metal_index - not significant
kruskal.test(heavy_metal_index ~ reporting_area, data = site_data) # p-value = 0.07802

# nutrient_metal_index - significant
kruskal.test(nutrient_metal_index ~ reporting_area, data = site_data) # p-value = 0.02028

# total_metal_index - significant
kruskal.test(total_metal_index ~ reporting_area, data = site_data) # p-value = 0.01076

# pah_lmw_index - significant
kruskal.test(pah_lmw_index ~ reporting_area, data = site_data) # p-value = 0.005112

# pah_hmw_index - significant
kruskal.test(pah_hmw_index ~ reporting_area, data = site_data) # p-value = 7.555e-05

# pah_add_index - not significant
kruskal.test(pah_add_index ~ reporting_area, data = site_data) # p-value =0.1179

# total_pah_index - significant
kruskal.test(total_pah_index ~ reporting_area, data = site_data) # p-value = 0.001526

# pbde_index - significant
kruskal.test(pbde_index ~ reporting_area, data = site_data) # p-value = 0.0002848

# pcb_index - significant
kruskal.test(pcb_index ~ reporting_area, data = site_data) # p-value = 0.01909

# pesticide_index - not significant
kruskal.test(pesticide_index ~ reporting_area, data = site_data) # p-value = 0.1069

# total_contaminants_index - significant
kruskal.test(total_con_index ~ reporting_area, data = site_data) # p-value = 0.0006062

```

## Dunn's Test - 'bh' method
### sod
```{r}

# sod, site - no significant result
dunn_result <- dunnTest(tc_sod ~ site_name, data = sample_data, method = "bh") 
dunn_df <- dunn_result$res %>%
  dplyr::select(Comparison, Z, P.unadj, P.adj) %>%
  tidyr::separate(Comparison, into = c("Group1", "Group2"), sep = " - ") %>%
  dplyr::mutate(Significant = ifelse(P.adj < 0.05, "Yes", "No"))
dunn_table <- dunn_df %>%
  dplyr::mutate(across(c(P.unadj, P.adj), round, digits = 4)) %>%
  dplyr::arrange(P.adj)
print(dunn_table) # view

groups <- unique(c(dunn_df$Group1, dunn_df$Group2)) # add letter designation
pval_matrix <- matrix(1, nrow = length(groups), ncol = length(groups),
                      dimnames = list(groups, groups))
for (i in 1:nrow(dunn_df)) {
  g1 <- dunn_df$Group1[i]
  g2 <- dunn_df$Group2[i]
  p <- dunn_df$P.adj[i]
  pval_matrix[g1, g2] <- p
  pval_matrix[g2, g1] <- p
}
cld_letters <- multcompLetters(pval_matrix < 0.05)$Letters
cld_df <- data.frame(
  Group = names(cld_letters),
  CLD = cld_letters,
  stringsAsFactors = FALSE
)
dunn_table_with_cld <- dunn_table %>%
  left_join(cld_df, by = c("Group1" = "Group")) %>%
  rename(Group1_CLD = CLD) %>%
  left_join(cld_df, by = c("Group2" = "Group")) %>%
  rename(Group2_CLD = CLD)

view(dunn_table_with_cld)
#write.csv(dunn_table_with_cld, "../output/tables/anova_kw_results/dunn_sod_site_10022025.csv", row.names = FALSE) 

```

### ci1
```{r}

# ci1, site: significant results returned
dunn_result <- dunnTest(tc_ci1 ~ site_name, data = sample_data, method = "bh") 
dunn_df <- dunn_result$res %>%
  dplyr::select(Comparison, Z, P.unadj, P.adj) %>%
  tidyr::separate(Comparison, into = c("Group1", "Group2"), sep = " - ") %>%
  dplyr::mutate(Significant = ifelse(P.adj < 0.05, "Yes", "No"))
dunn_table <- dunn_df %>%
  dplyr::mutate(across(c(P.unadj, P.adj), round, digits = 4)) %>%
  dplyr::arrange(P.adj)
print(dunn_table) # view

groups <- unique(c(dunn_df$Group1, dunn_df$Group2)) # add letter designation
pval_matrix <- matrix(1, nrow = length(groups), ncol = length(groups),
                      dimnames = list(groups, groups))
for (i in 1:nrow(dunn_df)) {
  g1 <- dunn_df$Group1[i]
  g2 <- dunn_df$Group2[i]
  p <- dunn_df$P.adj[i]
  pval_matrix[g1, g2] <- p
  pval_matrix[g2, g1] <- p
}
cld_letters <- multcompLetters(pval_matrix < 0.05)$Letters
cld_df <- data.frame(
  Group = names(cld_letters),
  CLD = cld_letters,
  stringsAsFactors = FALSE
)
dunn_table_with_cld <- dunn_table %>%
  left_join(cld_df, by = c("Group1" = "Group")) %>%
  rename(Group1_CLD = CLD) %>%
  left_join(cld_df, by = c("Group2" = "Group")) %>%
  rename(Group2_CLD = CLD)

view(dunn_table_with_cld)
#write.csv(dunn_table_with_cld, "../output/tables/anova_kw_results/dunn_ci1_site_10022025.csv", row.names = FALSE) 

```

### ci2
```{r}

# ci2, site - no significant result
dunn_result <- dunnTest(tc_ci2 ~ site_name, data = sample_data, method = "bh") 
dunn_df <- dunn_result$res %>%
  dplyr::select(Comparison, Z, P.unadj, P.adj) %>%
  tidyr::separate(Comparison, into = c("Group1", "Group2"), sep = " - ") %>%
  dplyr::mutate(Significant = ifelse(P.adj < 0.05, "Yes", "No"))
dunn_table <- dunn_df %>%
  dplyr::mutate(across(c(P.unadj, P.adj), round, digits = 4)) %>%
  dplyr::arrange(P.adj)
print(dunn_table) # view

groups <- unique(c(dunn_df$Group1, dunn_df$Group2)) # add letter designation
pval_matrix <- matrix(1, nrow = length(groups), ncol = length(groups),
                      dimnames = list(groups, groups))
for (i in 1:nrow(dunn_df)) {
  g1 <- dunn_df$Group1[i]
  g2 <- dunn_df$Group2[i]
  p <- dunn_df$P.adj[i]
  pval_matrix[g1, g2] <- p
  pval_matrix[g2, g1] <- p
}
cld_letters <- multcompLetters(pval_matrix < 0.05)$Letters
cld_df <- data.frame(
  Group = names(cld_letters),
  CLD = cld_letters,
  stringsAsFactors = FALSE
)
dunn_table_with_cld <- dunn_table %>%
  left_join(cld_df, by = c("Group1" = "Group")) %>%
  rename(Group1_CLD = CLD) %>%
  left_join(cld_df, by = c("Group2" = "Group")) %>%
  rename(Group2_CLD = CLD)

view(dunn_table_with_cld)
#write.csv(dunn_table_with_cld, "../output/tables/anova_kw_results/dunn_ci2_site_10022025.csv", row.names = FALSE) 

```

### shell
```{r}

#### shell, site: significant results returned
dunn_result <- dunnTest(tc_shell ~ site_name, data = sample_data, method = "bh") 
dunn_df <- dunn_result$res %>%
  dplyr::select(Comparison, Z, P.unadj, P.adj) %>%
  tidyr::separate(Comparison, into = c("Group1", "Group2"), sep = " - ") %>%
  dplyr::mutate(Significant = ifelse(P.adj < 0.05, "Yes", "No"))
dunn_table <- dunn_df %>%
  dplyr::mutate(across(c(P.unadj, P.adj), round, digits = 4)) %>%
  dplyr::arrange(P.adj)
print(dunn_table) # view

groups <- unique(c(dunn_df$Group1, dunn_df$Group2)) # add letter designation
pval_matrix <- matrix(1, nrow = length(groups), ncol = length(groups),
                      dimnames = list(groups, groups))
for (i in 1:nrow(dunn_df)) {
  g1 <- dunn_df$Group1[i]
  g2 <- dunn_df$Group2[i]
  p <- dunn_df$P.adj[i]
  pval_matrix[g1, g2] <- p
  pval_matrix[g2, g1] <- p
}
cld_letters <- multcompLetters(pval_matrix < 0.05)$Letters
cld_df <- data.frame(
  Group = names(cld_letters),
  CLD = cld_letters,
  stringsAsFactors = FALSE
)
dunn_table_with_cld <- dunn_table %>%
  left_join(cld_df, by = c("Group1" = "Group")) %>%
  rename(Group1_CLD = CLD) %>%
  left_join(cld_df, by = c("Group2" = "Group")) %>%
  rename(Group2_CLD = CLD)

view(dunn_table_with_cld)
#write.csv(dunn_table_with_cld, "../output/tables/anova_kw_results/dunn_shell_site_10032025.csv", row.names = FALSE) 

#### shell, reporting area: no significant result returned
dunn_result <- dunnTest(shell ~ reporting_area, data = site_data, method = "bh") 
dunn_df <- dunn_result$res %>%
  dplyr::select(Comparison, Z, P.unadj, P.adj) %>%
  tidyr::separate(Comparison, into = c("Group1", "Group2"), sep = " - ") %>%
  dplyr::mutate(Significant = ifelse(P.adj < 0.05, "Yes", "No"))
dunn_table <- dunn_df %>%
  dplyr::mutate(across(c(P.unadj, P.adj), round, digits = 4)) %>%
  dplyr::arrange(P.adj)
print(dunn_table) # view

groups <- unique(c(dunn_df$Group1, dunn_df$Group2)) # add letter designation
pval_matrix <- matrix(1, nrow = length(groups), ncol = length(groups),
                      dimnames = list(groups, groups))
for (i in 1:nrow(dunn_df)) {
  g1 <- dunn_df$Group1[i]
  g2 <- dunn_df$Group2[i]
  p <- dunn_df$P.adj[i]
  pval_matrix[g1, g2] <- p
  pval_matrix[g2, g1] <- p
}
cld_letters <- multcompLetters(pval_matrix < 0.05)$Letters
cld_df <- data.frame(
  Group = names(cld_letters),
  CLD = cld_letters,
  stringsAsFactors = FALSE
)
dunn_table_with_cld <- dunn_table %>%
  left_join(cld_df, by = c("Group1" = "Group")) %>%
  rename(Group1_CLD = CLD) %>%
  left_join(cld_df, by = c("Group2" = "Group")) %>%
  rename(Group2_CLD = CLD)

view(dunn_table_with_cld)
#write.csv(dunn_table_with_cld, "../output/tables/anova_kw_results/dunn_shell_ra_10022025.csv", row.names = FALSE) 

```

### ibr_bio
```{r}

# ibr_bio, site: no significant results
dunn_result <- dunnTest(ibr_biomarker ~ site_number, data = sample_ibr, method = "bh") 
dunn_df <- dunn_result$res %>%
  dplyr::select(Comparison, Z, P.unadj, P.adj) %>%
  tidyr::separate(Comparison, into = c("Group1", "Group2"), sep = " - ") %>%
  dplyr::mutate(Significant = ifelse(P.adj < 0.05, "Yes", "No"))
dunn_table <- dunn_df %>%
  dplyr::mutate(across(c(P.unadj, P.adj), round, digits = 4)) %>%
  dplyr::arrange(P.adj)
print(dunn_table) # view

groups <- unique(c(dunn_df$Group1, dunn_df$Group2)) # add letter designation
pval_matrix <- matrix(1, nrow = length(groups), ncol = length(groups),
                      dimnames = list(groups, groups))
for (i in 1:nrow(dunn_df)) {
  g1 <- dunn_df$Group1[i]
  g2 <- dunn_df$Group2[i]
  p <- dunn_df$P.adj[i]
  pval_matrix[g1, g2] <- p
  pval_matrix[g2, g1] <- p
}
cld_letters <- multcompLetters(pval_matrix < 0.05)$Letters
cld_df <- data.frame(
  Group = names(cld_letters),
  CLD = cld_letters,
  stringsAsFactors = FALSE
)
dunn_table_with_cld <- dunn_table %>%
  left_join(cld_df, by = c("Group1" = "Group")) %>%
  rename(Group1_CLD = CLD) %>%
  left_join(cld_df, by = c("Group2" = "Group")) %>%
  rename(Group2_CLD = CLD)

view(dunn_table_with_cld)
#write.csv(dunn_table_with_cld, "../output/tables/anova_kw_results/dunn_ibr_bio_site_10022025.csv", row.names = FALSE) 

```

### ibr_combined (ibr_total)
```{r}

# ibr_combined (total), site: no significant result
dunn_result <- dunnTest(ibr_total ~ site_name, data = sample_ibr, method = "bh") 
dunn_df <- dunn_result$res %>%
  dplyr::select(Comparison, Z, P.unadj, P.adj) %>%
  tidyr::separate(Comparison, into = c("Group1", "Group2"), sep = " - ") %>%
  dplyr::mutate(Significant = ifelse(P.adj < 0.05, "Yes", "No"))
dunn_table <- dunn_df %>%
  dplyr::mutate(across(c(P.unadj, P.adj), round, digits = 4)) %>%
  dplyr::arrange(P.adj)
print(dunn_table) # view

groups <- unique(c(dunn_df$Group1, dunn_df$Group2)) # add letter designation
pval_matrix <- matrix(1, nrow = length(groups), ncol = length(groups),
                      dimnames = list(groups, groups))
for (i in 1:nrow(dunn_df)) {
  g1 <- dunn_df$Group1[i]
  g2 <- dunn_df$Group2[i]
  p <- dunn_df$P.adj[i]
  pval_matrix[g1, g2] <- p
  pval_matrix[g2, g1] <- p
}
cld_letters <- multcompLetters(pval_matrix < 0.05)$Letters
cld_df <- data.frame(
  Group = names(cld_letters),
  CLD = cld_letters,
  stringsAsFactors = FALSE
)
dunn_table_with_cld <- dunn_table %>%
  left_join(cld_df, by = c("Group1" = "Group")) %>%
  rename(Group1_CLD = CLD) %>%
  left_join(cld_df, by = c("Group2" = "Group")) %>%
  rename(Group2_CLD = CLD)

view(dunn_table_with_cld)
#write.csv(dunn_table_with_cld, "../output/tables/anova_kw_results/dunn_ibr_total_site_10022025.csv", row.names = FALSE) 

```

## Note: all contaminants are at the reporting area level only because site values are singular and will be used in correlations
### chlordane
```{r}

# chlordane: significant results returned
dunn_result <- dunnTest(chlordane_index ~ reporting_area, data = site_data, method = "bh") 
dunn_df <- dunn_result$res %>%
  dplyr::select(Comparison, Z, P.unadj, P.adj) %>%
  tidyr::separate(Comparison, into = c("Group1", "Group2"), sep = " - ") %>%
  dplyr::mutate(Significant = ifelse(P.adj < 0.05, "Yes", "No"))

dunn_table <- dunn_df %>%
  dplyr::mutate(across(c(P.unadj, P.adj), round, digits = 4)) %>%
  dplyr::arrange(P.adj)

print(dunn_table) # view
groups <- unique(c(dunn_df$Group1, dunn_df$Group2)) # add letter designation
pval_matrix <- matrix(1, nrow = length(groups), ncol = length(groups),
                      dimnames = list(groups, groups))
for (i in 1:nrow(dunn_df)) {
  g1 <- dunn_df$Group1[i]
  g2 <- dunn_df$Group2[i]
  p <- dunn_df$P.adj[i]
  pval_matrix[g1, g2] <- p
  pval_matrix[g2, g1] <- p
}
cld_letters <- multcompLetters(pval_matrix < 0.05)$Letters
cld_df <- data.frame(
  Group = names(cld_letters),
  CLD = cld_letters,
  stringsAsFactors = FALSE
)
dunn_table_with_cld <- dunn_table %>%
  left_join(cld_df, by = c("Group1" = "Group")) %>%
  rename(Group1_CLD = CLD) %>%
  left_join(cld_df, by = c("Group2" = "Group")) %>%
  rename(Group2_CLD = CLD)

view(dunn_table_with_cld)
#write.csv(dunn_table_with_cld, "../output/tables/anova_kw_results/dunn_chlordane_ra.csv", row.names = FALSE) 

```

### ddt
```{r}

# ddt: significant results returned
dunn_result <- dunnTest(ddt_index ~ reporting_area, data = site_data, method = "bh") 
dunn_df <- dunn_result$res %>%
  dplyr::select(Comparison, Z, P.unadj, P.adj) %>%
  tidyr::separate(Comparison, into = c("Group1", "Group2"), sep = " - ") %>%
  dplyr::mutate(Significant = ifelse(P.adj < 0.05, "Yes", "No"))

dunn_table <- dunn_df %>%
  dplyr::mutate(across(c(P.unadj, P.adj), round, digits = 4)) %>%
  dplyr::arrange(P.adj)

print(dunn_table) # view
groups <- unique(c(dunn_df$Group1, dunn_df$Group2)) # add letter designation
pval_matrix <- matrix(1, nrow = length(groups), ncol = length(groups),
                      dimnames = list(groups, groups))
for (i in 1:nrow(dunn_df)) {
  g1 <- dunn_df$Group1[i]
  g2 <- dunn_df$Group2[i]
  p <- dunn_df$P.adj[i]
  pval_matrix[g1, g2] <- p
  pval_matrix[g2, g1] <- p
}
cld_letters <- multcompLetters(pval_matrix < 0.05)$Letters
cld_df <- data.frame(
  Group = names(cld_letters),
  CLD = cld_letters,
  stringsAsFactors = FALSE
)
dunn_table_with_cld <- dunn_table %>%
  left_join(cld_df, by = c("Group1" = "Group")) %>%
  rename(Group1_CLD = CLD) %>%
  left_join(cld_df, by = c("Group2" = "Group")) %>%
  rename(Group2_CLD = CLD)

view(dunn_table_with_cld)
#write.csv(dunn_table_with_cld, "../output/tables/anova_kw_results/dunn_ddt_ra.csv", row.names = FALSE) 

```

### nutrient_metals
```{r}

# nutrient metals: significant result returned
dunn_result <- dunnTest(nutrient_metal_index ~ reporting_area, data = site_data, method = "bh") 
dunn_df <- dunn_result$res %>%
  dplyr::select(Comparison, Z, P.unadj, P.adj) %>%
  tidyr::separate(Comparison, into = c("Group1", "Group2"), sep = " - ") %>%
  dplyr::mutate(Significant = ifelse(P.adj < 0.05, "Yes", "No"))

dunn_table <- dunn_df %>%
  dplyr::mutate(across(c(P.unadj, P.adj), round, digits = 4)) %>%
  dplyr::arrange(P.adj)

print(dunn_table) # view
groups <- unique(c(dunn_df$Group1, dunn_df$Group2)) # add letter designation
pval_matrix <- matrix(1, nrow = length(groups), ncol = length(groups),
                      dimnames = list(groups, groups))
for (i in 1:nrow(dunn_df)) {
  g1 <- dunn_df$Group1[i]
  g2 <- dunn_df$Group2[i]
  p <- dunn_df$P.adj[i]
  pval_matrix[g1, g2] <- p
  pval_matrix[g2, g1] <- p
}
cld_letters <- multcompLetters(pval_matrix < 0.05)$Letters
cld_df <- data.frame(
  Group = names(cld_letters),
  CLD = cld_letters,
  stringsAsFactors = FALSE
)
dunn_table_with_cld <- dunn_table %>%
  left_join(cld_df, by = c("Group1" = "Group")) %>%
  rename(Group1_CLD = CLD) %>%
  left_join(cld_df, by = c("Group2" = "Group")) %>%
  rename(Group2_CLD = CLD)

view(dunn_table_with_cld)
#write.csv(dunn_table_with_cld, "../output/tables/anova_kw_results/dunn_nutrient_metal_ra.csv", row.names = FALSE) 

```

### total_metals
```{r}

# total metal: no significant results
dunn_result <- dunnTest(total_metal_index ~ reporting_area, data = site_data, method = "bh") 
dunn_df <- dunn_result$res %>%
  dplyr::select(Comparison, Z, P.unadj, P.adj) %>%
  tidyr::separate(Comparison, into = c("Group1", "Group2"), sep = " - ") %>%
  dplyr::mutate(Significant = ifelse(P.adj < 0.05, "Yes", "No"))

dunn_table <- dunn_df %>%
  dplyr::mutate(across(c(P.unadj, P.adj), round, digits = 4)) %>%
  dplyr::arrange(P.adj)

print(dunn_table) # view
groups <- unique(c(dunn_df$Group1, dunn_df$Group2)) # add letter designation
pval_matrix <- matrix(1, nrow = length(groups), ncol = length(groups),
                      dimnames = list(groups, groups))
for (i in 1:nrow(dunn_df)) {
  g1 <- dunn_df$Group1[i]
  g2 <- dunn_df$Group2[i]
  p <- dunn_df$P.adj[i]
  pval_matrix[g1, g2] <- p
  pval_matrix[g2, g1] <- p
}
cld_letters <- multcompLetters(pval_matrix < 0.05)$Letters
cld_df <- data.frame(
  Group = names(cld_letters),
  CLD = cld_letters,
  stringsAsFactors = FALSE
)
dunn_table_with_cld <- dunn_table %>%
  left_join(cld_df, by = c("Group1" = "Group")) %>%
  rename(Group1_CLD = CLD) %>%
  left_join(cld_df, by = c("Group2" = "Group")) %>%
  rename(Group2_CLD = CLD)

view(dunn_table_with_cld)
#write.csv(dunn_table_with_cld, "../output/tables/anova_kw_results/dunn_total_metal_ra.csv", row.names = FALSE) 

```

### lmw_pah
```{r}

# low pah: significant results returned
dunn_result <- dunnTest(pah_lmw_index ~ reporting_area, data = site_data, method = "bh") 
dunn_df <- dunn_result$res %>%
  dplyr::select(Comparison, Z, P.unadj, P.adj) %>%
  tidyr::separate(Comparison, into = c("Group1", "Group2"), sep = " - ") %>%
  dplyr::mutate(Significant = ifelse(P.adj < 0.05, "Yes", "No"))

dunn_table <- dunn_df %>%
  dplyr::mutate(across(c(P.unadj, P.adj), round, digits = 4)) %>%
  dplyr::arrange(P.adj)

print(dunn_table) # view
groups <- unique(c(dunn_df$Group1, dunn_df$Group2)) # add letter designation
pval_matrix <- matrix(1, nrow = length(groups), ncol = length(groups),
                      dimnames = list(groups, groups))
for (i in 1:nrow(dunn_df)) {
  g1 <- dunn_df$Group1[i]
  g2 <- dunn_df$Group2[i]
  p <- dunn_df$P.adj[i]
  pval_matrix[g1, g2] <- p
  pval_matrix[g2, g1] <- p
}
cld_letters <- multcompLetters(pval_matrix < 0.05)$Letters
cld_df <- data.frame(
  Group = names(cld_letters),
  CLD = cld_letters,
  stringsAsFactors = FALSE
)
dunn_table_with_cld <- dunn_table %>%
  left_join(cld_df, by = c("Group1" = "Group")) %>%
  rename(Group1_CLD = CLD) %>%
  left_join(cld_df, by = c("Group2" = "Group")) %>%
  rename(Group2_CLD = CLD)

view(dunn_table_with_cld)
#write.csv(dunn_table_with_cld, "../output/tables/anova_kw_results/dunn_low_pah_ra.csv", row.names = FALSE) 

```

### hmw_pah
```{r}

# high pah: signficant results returned
dunn_result <- dunnTest(pah_hmw_index ~ reporting_area, data = site_data, method = "bh") 
dunn_df <- dunn_result$res %>%
  dplyr::select(Comparison, Z, P.unadj, P.adj) %>%
  tidyr::separate(Comparison, into = c("Group1", "Group2"), sep = " - ") %>%
  dplyr::mutate(Significant = ifelse(P.adj < 0.05, "Yes", "No"))

dunn_table <- dunn_df %>%
  dplyr::mutate(across(c(P.unadj, P.adj), round, digits = 4)) %>%
  dplyr::arrange(P.adj)

print(dunn_table) # view
groups <- unique(c(dunn_df$Group1, dunn_df$Group2)) # add letter designation
pval_matrix <- matrix(1, nrow = length(groups), ncol = length(groups),
                      dimnames = list(groups, groups))
for (i in 1:nrow(dunn_df)) {
  g1 <- dunn_df$Group1[i]
  g2 <- dunn_df$Group2[i]
  p <- dunn_df$P.adj[i]
  pval_matrix[g1, g2] <- p
  pval_matrix[g2, g1] <- p
}
cld_letters <- multcompLetters(pval_matrix < 0.05)$Letters
cld_df <- data.frame(
  Group = names(cld_letters),
  CLD = cld_letters,
  stringsAsFactors = FALSE
)
dunn_table_with_cld <- dunn_table %>%
  left_join(cld_df, by = c("Group1" = "Group")) %>%
  rename(Group1_CLD = CLD) %>%
  left_join(cld_df, by = c("Group2" = "Group")) %>%
  rename(Group2_CLD = CLD)

view(dunn_table_with_cld)
#write.csv(dunn_table_with_cld, "../output/tables/anova_kw_results/dunn_high_pah_ra.csv", row.names = FALSE) 


```

### total_pah
```{r}

# total pah: significant results returned
dunn_result <- dunnTest(total_pah_index ~ reporting_area, data = site_data, method = "bh") 
dunn_df <- dunn_result$res %>%
  dplyr::select(Comparison, Z, P.unadj, P.adj) %>%
  tidyr::separate(Comparison, into = c("Group1", "Group2"), sep = " - ") %>%
  dplyr::mutate(Significant = ifelse(P.adj < 0.05, "Yes", "No"))

dunn_table <- dunn_df %>%
  dplyr::mutate(across(c(P.unadj, P.adj), round, digits = 4)) %>%
  dplyr::arrange(P.adj)

print(dunn_table) # view
groups <- unique(c(dunn_df$Group1, dunn_df$Group2)) # add letter designation
pval_matrix <- matrix(1, nrow = length(groups), ncol = length(groups),
                      dimnames = list(groups, groups))
for (i in 1:nrow(dunn_df)) {
  g1 <- dunn_df$Group1[i]
  g2 <- dunn_df$Group2[i]
  p <- dunn_df$P.adj[i]
  pval_matrix[g1, g2] <- p
  pval_matrix[g2, g1] <- p
}
cld_letters <- multcompLetters(pval_matrix < 0.05)$Letters
cld_df <- data.frame(
  Group = names(cld_letters),
  CLD = cld_letters,
  stringsAsFactors = FALSE
)
dunn_table_with_cld <- dunn_table %>%
  left_join(cld_df, by = c("Group1" = "Group")) %>%
  rename(Group1_CLD = CLD) %>%
  left_join(cld_df, by = c("Group2" = "Group")) %>%
  rename(Group2_CLD = CLD)

view(dunn_table_with_cld)
#write.csv(dunn_table_with_cld, "../output/tables/anova_kw_results/dunn_total_pah_ra.csv", row.names = FALSE) 

```

### pbde
```{r}

# pbde: signficant results returned
dunn_result <- dunnTest(pbde_index ~ reporting_area, data = site_data, method = "bh") 
dunn_df <- dunn_result$res %>%
  dplyr::select(Comparison, Z, P.unadj, P.adj) %>%
  tidyr::separate(Comparison, into = c("Group1", "Group2"), sep = " - ") %>%
  dplyr::mutate(Significant = ifelse(P.adj < 0.05, "Yes", "No"))

dunn_table <- dunn_df %>%
  dplyr::mutate(across(c(P.unadj, P.adj), round, digits = 4)) %>%
  dplyr::arrange(P.adj)

print(dunn_table) # view
groups <- unique(c(dunn_df$Group1, dunn_df$Group2)) # add letter designation
pval_matrix <- matrix(1, nrow = length(groups), ncol = length(groups),
                      dimnames = list(groups, groups))
for (i in 1:nrow(dunn_df)) {
  g1 <- dunn_df$Group1[i]
  g2 <- dunn_df$Group2[i]
  p <- dunn_df$P.adj[i]
  pval_matrix[g1, g2] <- p
  pval_matrix[g2, g1] <- p
}
cld_letters <- multcompLetters(pval_matrix < 0.05)$Letters
cld_df <- data.frame(
  Group = names(cld_letters),
  CLD = cld_letters,
  stringsAsFactors = FALSE
)
dunn_table_with_cld <- dunn_table %>%
  left_join(cld_df, by = c("Group1" = "Group")) %>%
  rename(Group1_CLD = CLD) %>%
  left_join(cld_df, by = c("Group2" = "Group")) %>%
  rename(Group2_CLD = CLD)

view(dunn_table_with_cld)
#write.csv(dunn_table_with_cld, "../output/tables/anova_kw_results/dunn_pbde_ra.csv", row.names = FALSE) 


```

### pcb
```{r}

# pcb: no significant results
dunn_result <- dunnTest(pcb_index ~ reporting_area, data = site_data, method = "bh") 
dunn_df <- dunn_result$res %>%
  dplyr::select(Comparison, Z, P.unadj, P.adj) %>%
  tidyr::separate(Comparison, into = c("Group1", "Group2"), sep = " - ") %>%
  dplyr::mutate(Significant = ifelse(P.adj < 0.05, "Yes", "No"))

dunn_table <- dunn_df %>%
  dplyr::mutate(across(c(P.unadj, P.adj), round, digits = 4)) %>%
  dplyr::arrange(P.adj)

print(dunn_table) # view
groups <- unique(c(dunn_df$Group1, dunn_df$Group2)) # add letter designation
pval_matrix <- matrix(1, nrow = length(groups), ncol = length(groups),
                      dimnames = list(groups, groups))
for (i in 1:nrow(dunn_df)) {
  g1 <- dunn_df$Group1[i]
  g2 <- dunn_df$Group2[i]
  p <- dunn_df$P.adj[i]
  pval_matrix[g1, g2] <- p
  pval_matrix[g2, g1] <- p
}
cld_letters <- multcompLetters(pval_matrix < 0.05)$Letters
cld_df <- data.frame(
  Group = names(cld_letters),
  CLD = cld_letters,
  stringsAsFactors = FALSE
)
dunn_table_with_cld <- dunn_table %>%
  left_join(cld_df, by = c("Group1" = "Group")) %>%
  rename(Group1_CLD = CLD) %>%
  left_join(cld_df, by = c("Group2" = "Group")) %>%
  rename(Group2_CLD = CLD)

view(dunn_table_with_cld)
#write.csv(dunn_table_with_cld, "../output/tables/anova_kw_results/dunn_pcb_ra.csv", row.names = FALSE) 

```

### total_contaminants
```{r}

# total_con: significant results returned
dunn_result <- dunnTest(total_con_index ~ reporting_area, data = site_data, method = "bh") 
dunn_df <- dunn_result$res %>%
  dplyr::select(Comparison, Z, P.unadj, P.adj) %>%
  tidyr::separate(Comparison, into = c("Group1", "Group2"), sep = " - ") %>%
  dplyr::mutate(Significant = ifelse(P.adj < 0.05, "Yes", "No"))

dunn_table <- dunn_df %>%
  dplyr::mutate(across(c(P.unadj, P.adj), round, digits = 4)) %>%
  dplyr::arrange(P.adj)

print(dunn_table) # view
groups <- unique(c(dunn_df$Group1, dunn_df$Group2)) # add letter designation
pval_matrix <- matrix(1, nrow = length(groups), ncol = length(groups),
                      dimnames = list(groups, groups))
for (i in 1:nrow(dunn_df)) {
  g1 <- dunn_df$Group1[i]
  g2 <- dunn_df$Group2[i]
  p <- dunn_df$P.adj[i]
  pval_matrix[g1, g2] <- p
  pval_matrix[g2, g1] <- p
}
cld_letters <- multcompLetters(pval_matrix < 0.05)$Letters
cld_df <- data.frame(
  Group = names(cld_letters),
  CLD = cld_letters,
  stringsAsFactors = FALSE
)
dunn_table_with_cld <- dunn_table %>%
  left_join(cld_df, by = c("Group1" = "Group")) %>%
  rename(Group1_CLD = CLD) %>%
  left_join(cld_df, by = c("Group2" = "Group")) %>%
  rename(Group2_CLD = CLD)

view(dunn_table_with_cld)
#write.csv(dunn_table_with_cld, "../output/tables/anova_kw_results/dunn_total_con_ra_10052025.csv", row.names = FALSE) 

```

# Asking: Are there correlations between the contaminants indices and the metrics(Spearman)? Is there a relationship between the contaminants indices and metrics that could indicate dependence or independence (Kendall's) in the Spearman results?
## Spearman & Kendall's
### metrics & all indices
```{r}

# define variables
metrics_vars <- c("p450", "sod", "shell", "ci1", "ci2", "ci3",
                  "weight_initial", "weight_change", "weight_final",
                  "length", "width", "height", "ibr_bio", "ibr_morph", "ibr_combined")

# define id columns
id_columns <- c("site_name", "site_number", "reporting_area", "latitude", "longitude")

analyte_vars <- c("chlordane_index", "ddt_index", "hch_index", "heavy_metal_index", "nutrient_metal_index", "total_metal_index",
"pah_lmw_index", "pah_hmw_index", "pah_add_index", "total_pah_index", "pbde_index", "pcb_index", "pesticide_index", "total_con_index")  

# make sure these are plain character vectors (not factors)
metrics_vars <- as.character(metrics_vars)
analyte_vars <- as.character(analyte_vars)

needed <- c(metrics_vars, analyte_vars)

# check for missing columns (common cause: typos)
missing_cols <- setdiff(needed, names(site_data))
if (length(missing_cols) > 0) {
  warning("These columns are missing from site_data: ",
          paste(missing_cols, collapse = ", "))
}

# coerce just the needed columns to numeric (safe conversion)
to_numeric <- function(v) {
  if (is.numeric(v)) return(v)
  if (is.factor(v)) return(as.numeric(as.character(v)))
  if (is.character(v)) return(suppressWarnings(as.numeric(v)))
  suppressWarnings(as.numeric(v))
}

site_data <- site_data |>
  dplyr::mutate(dplyr::across(dplyr::all_of(intersect(needed, names(site_data))), to_numeric))

# --- correlation loop --------------------------------------------------
results_list <- list()
k <- 1L

for (metric in metrics_vars) {
  if (!metric %in% names(site_data)) next
  x <- site_data[[metric]]
  if (!is.numeric(x)) next

  for (analyte in analyte_vars) {
    if (!analyte %in% names(site_data)) next
    y <- site_data[[analyte]]
    if (!is.numeric(y)) next

    valid <- is.finite(x) & is.finite(y)
    x_valid <- x[valid]
    y_valid <- y[valid]

    
    spearman <- try(stats::cor.test(x_valid, y_valid, method = "spearman", exact = FALSE), silent = TRUE)
    kendall  <- try(stats::cor.test(x_valid, y_valid, method = "kendall"), silent = TRUE)

    if (inherits(spearman, "try-error") || inherits(kendall, "try-error")) next

    results_list[[k]] <- data.frame(
      Metric = metric,
      Analyte = analyte,
      Spearman_r = unname(spearman$estimate),
      Spearman_p = unname(spearman$p.value),
      Kendall_tau = unname(kendall$estimate),
      Kendall_p = unname(kendall$p.value),
      stringsAsFactors = FALSE
    )
    k <- k + 1L
  }
}

# --- combine + significance stars -------------------------------------
corr_full <- dplyr::bind_rows(results_list)

corr_full <- corr_full |>
  dplyr::mutate(
    Spearman_sig = dplyr::case_when(
      Spearman_p <= 0.001 ~ "***",
      Spearman_p <= 0.01  ~ "**",
      Spearman_p <= 0.05  ~ "*",
      TRUE ~ ""
    ),
    Kendall_sig = dplyr::case_when(
      Kendall_p <= 0.001 ~ "***",
      Kendall_p <= 0.01  ~ "**",
      Kendall_p <= 0.05  ~ "*",
      TRUE ~ ""
    )
  ) |>
  dplyr::arrange(Spearman_p, Kendall_p)

view(corr_full)
#write.csv(corr_full, "../output/tables/spearman_kendall_results/correlation_all_indices_10042025.csv", row.names = FALSE)

```

### individual analytes
```{r}

# ---- column ranges based on your layout ----
id_columns      <- names(site_data)[1:5]
metrics_vars    <- names(site_data)[6:20]
index_vars      <- names(site_data)[21:34]   # not used here; for clarity
analyte_vars    <- names(site_data)[35:142]  


needed <- c(metrics_vars, analyte_vars)

to_numeric <- function(v) {
  if (is.numeric(v)) return(v)
  if (is.factor(v)) return(as.numeric(as.character(v)))
  if (is.character(v)) return(suppressWarnings(as.numeric(v)))
  suppressWarnings(as.numeric(v))
}

site_data <- site_data |>
  dplyr::mutate(dplyr::across(dplyr::all_of(intersect(needed, names(site_data))), to_numeric))

# ---- correlation loop: metrics x individual analytes ----
results_list <- list()
k <- 1L
min_pairs <- 4L  # require at least 4 paired points

for (metric in metrics_vars) {
  if (!metric %in% names(site_data)) next
  x <- site_data[[metric]]
  if (!is.numeric(x)) next

  for (analyte in analyte_vars) {
    if (!analyte %in% names(site_data)) next
    y <- site_data[[analyte]]
    if (!is.numeric(y)) next

    valid <- is.finite(x) & is.finite(y)
    if (!any(valid)) next
    x_valid <- x[valid]
    y_valid <- y[valid]

   
    # correlations
    spearman <- try(stats::cor.test(x_valid, y_valid, method = "spearman", exact = FALSE), silent = TRUE)
    kendall  <- try(stats::cor.test(x_valid, y_valid, method = "kendall"), silent = TRUE)
    if (inherits(spearman, "try-error") || inherits(kendall, "try-error")) next

    results_list[[k]] <- data.frame(
      Metric       = metric,
      Analyte      = analyte,
      N_Pairs      = length(x_valid),
      Spearman_r   = unname(spearman$estimate),
      Spearman_p   = unname(spearman$p.value),
      Kendall_tau  = unname(kendall$estimate),
      Kendall_p    = unname(kendall$p.value),
      stringsAsFactors = FALSE
    )
    k <- k + 1L
  }
}

corr_full <- dplyr::bind_rows(results_list)

# ---- significance flags + ordering ----
corr_full <- corr_full |>
  dplyr::mutate(
    Spearman_sig = dplyr::case_when(
      Spearman_p <= 0.001 ~ "***",
      Spearman_p <= 0.01  ~ "**",
      Spearman_p <= 0.05  ~ "*",
      TRUE ~ ""
    ),
    Kendall_sig = dplyr::case_when(
      Kendall_p <= 0.001 ~ "***",
      Kendall_p <= 0.01  ~ "**",
      Kendall_p <= 0.05  ~ "*",
      TRUE ~ ""
    )
  ) |>
  dplyr::arrange(Spearman_p, Kendall_p)

# view
view(corr_full)
#write.csv(corr_full, "../output/tables/spearman_kendall_results/correlation_metrics_analytes_10042025.csv", row.names = FALSE)

```

# Asking: Are there discernable, significant spatial correlations/ relations amongst the metrics or analytes?
## Global Moran's I & LISA (Local Indicators of Spatial Association) w/ data prep
### biomarkers and ibrs only
```{r}

# define my columns/ variables
id_idx <- 1:5 # site_number, reporting_area, site_name, latitude, longitude
biomarker_idx <- 6:7 # e.g., p450, sod <-- EDIT to your true range
morphometric_idx<- 8:14 # e.g., shell, length/height/width, weights <-- EDIT
condition_idx <- 15:17 # e.g., ci1:ci3 (example) <-- EDIT
ibr_idx <- 18:20 # e.g., ibr_bio, ibr_morph, ibr_combined <-- EDIT
index_idx <- 21:34 # contaminant indices
analyte_idx <- 35:142 # individual analytes (z_*)

# pull the column names from indices
nm <- names(site_data)
id_cols <- nm[intersect(id_idx, seq_along(nm))]
biomarkers <- nm[intersect(biomarker_idx, seq_along(nm))]
morphometrics <- nm[intersect(morphometric_idx, seq_along(nm))]
conditions <- nm[intersect(condition_idx, seq_along(nm))]
ibrs <- nm[intersect(ibr_idx, seq_along(nm))]
index_cols <- nm[intersect(index_idx, seq_along(nm))]
analyte_cols <- nm[intersect(analyte_idx, seq_along(nm))]

# key id columns
lon_col <- "longitude"
lat_col <- "latitude"
site_col<- "site_name" 

# choose response set: prioritize IBRs (overall) + biomarkers (mechanistic)
responses <- unique(c(intersect(c("ibr_combined","ibr_bio","ibr_morph"), ibrs),
                      intersect(c("p450","sod"), biomarkers)))
if (length(responses) == 0) responses <- c(ibrs, biomarkers)[1:min(3, length(c(ibrs, biomarkers)))]

# coerce to sf and project to meters
site_sf <- st_as_sf(site_data, coords = c(lon_col, lat_col), crs = 4326)
site_sf <- st_transform(site_sf, 3857)
xy <- st_coordinates(site_sf)

# Neighborhood weights (k-NN with k = sqrt(n) capped at 8)
k_default <- max(2, min(8, ceiling(sqrt(nrow(site_sf)))))
nb_knn <- knn2nb(knearneigh(xy, k = k_default))
if (any(card(nb_knn) == 0)) {
  k_default <- max(k_default + 1, 3)
  nb_knn <- knn2nb(knearneigh(xy, k = k_default))
}
lw <- nb2listw(nb_knn, style = "W")

message(sprintf("weights: %d-NN (style=W)", k_default))

# 1) Global & Local autocorrelation (clean, single pass; values as-is)
moran_results <- list()
lisa_results  <- list()

for (resp in responses) {
  if (!resp %in% names(site_data)) next

  y  <- site_data[[resp]]
  ly <- lag.listw(lw, y)

  # Global Moran's I
  moran_results[[resp]] <- moran.test(y, lw)

  # Local Moran's I (LISA)
  li <- localmoran(y, lw)

  out <- site_sf
  out$resp <- resp
  out$Ii   <- li[,1]
  out$Z.Ii <- li[,4]
  out$p    <- li[,5]
  out$p_fdr <- p.adjust(out$p, method = "fdr")   # optional but helpful

  # Simple cluster labeling relative to overall mean (since not z-scored)
  m_y  <- mean(y,  na.rm = TRUE)
  m_ly <- mean(ly, na.rm = TRUE)

  out$cluster <- dplyr::case_when(
    out$p_fdr < 0.05 & y  > m_y  & ly > m_ly ~ "High-High",
    out$p_fdr < 0.05 & y  < m_y  & ly < m_ly ~ "Low-Low",
    out$p_fdr < 0.05 & y  > m_y  & ly < m_ly ~ "High-Low",
    out$p_fdr < 0.05 & y  < m_y  & ly > m_ly ~ "Low-High",
    TRUE ~ "NS"
  )

  # carry through reporting_area for faceting
  out$reporting_area <- site_data$reporting_area

  lisa_results[[resp]] <- out
}

# Example map for IBR clusters
if ("ibr_combined" %in% names(lisa_results)) {
  tm_shape(lisa_results[["ibr_combined"]]) +
    tm_dots(col = "cluster", size = 0.15, title = "lisa: ibr_combined") +
    tm_layout(legend.outside = TRUE)
}

# summary tables from the tests: global moran's
global_moran_table <- dplyr::bind_rows(lapply(names(moran_results), function(resp) {
  mres <- moran_results[[resp]]
  # robust extraction
  est <- suppressWarnings(unname(mres$estimate["Moran I statistic"]))
  ei  <- suppressWarnings(unname(mres$estimate["Expectation"]))
  vi  <- suppressWarnings(unname(mres$estimate["Variance"]))
  if (is.na(est) || is.na(ei) || is.na(vi)) {
    # fallback: try to compute z if needed
    zval <- as.numeric(mres$statistic)
  } else {
    zval <- (est - ei) / sqrt(vi)
  }
  tibble::tibble(
    metric         = resp,
    moran_I        = est,
    expected_I     = ei,
    variance       = vi,
    z              = zval,
    p_value        = mres$p.value
  )
})) %>%
  dplyr::mutate(
    p_fdr          = p.adjust(p_value, method = "fdr"),
    sig_p05        = p_value < 0.05,
    sig_fdr05      = p_fdr   < 0.05,
    direction      = dplyr::case_when(moran_I > 0 ~ "positive", moran_I < 0 ~ "negative", TRUE ~ "≈0"),
    n_sites        = nrow(site_sf),
    k_neighbors    = k_default
  ) %>%
  dplyr::arrange(p_value)

global_moran_table
#write.csv(global_moran_table, "../output/tables/global_moran_10042025.csv", row.names = FALSE)

# lisa summary table
lisa_table <- dplyr::bind_rows(lapply(names(lisa_results), function(resp) {
  x  <- lisa_results[[resp]]
  df <- sf::st_drop_geometry(x)
  # ensure metric name column
  if (!"resp" %in% names(df)) df$resp <- resp
  # attach site + reporting area from your original data (row order should match)
  df[[site_col]] <- site_data[[site_col]]
  if ("reporting_area" %in% names(site_data) && !"reporting_area" %in% names(df)) {
    df$reporting_area <- site_data$reporting_area
  }
  # FDR across sites within each metric
  if (!"p_fdr" %in% names(df)) {
    df$p_fdr <- p.adjust(df$p, method = "fdr")
  }
  dplyr::select(df,
                metric = resp,
                !!site_col,
                dplyr::any_of("reporting_area"),
                Ii, Z.Ii, p, p_fdr, cluster) %>%
    dplyr::mutate(sig_p05   = p    < 0.05,
                  sig_fdr05 = p_fdr < 0.05)
}), .id = NULL) %>%
  dplyr::arrange(metric, p)

lisa_table
#write.csv(lisa_table, "../output/tables/lisa_10042025.csv", row.names = FALSE)

```

### remaining metrics - global morans & lisa
```{r}

# group the columns you want to scan
metric_groups <- list(
  biomarkers    = biomarkers,
  morphometrics = morphometrics,
  conditions    = conditions,
  ibrs          = ibrs,
  indices       = index_cols
)

# keep only columns that exist & are non-empty
metric_groups <- lapply(metric_groups, function(v) v[v %in% names(site_data)])
metric_groups <- metric_groups[sapply(metric_groups, length) > 0]

# a helper for the site id column name
sc <- if (exists("site_col")) site_col else "site_name"

library(dplyr)
library(tibble)

safe_moran <- function(y) {
  # skip NA/constant vectors
  if (all(is.na(y)) || (sd(y, na.rm = TRUE) %||% 0) == 0) return(NULL)
  res <- moran.test(y, lw)
  est <- suppressWarnings(unname(res$estimate["Moran I statistic"]))
  ei  <- suppressWarnings(unname(res$estimate["Expectation"]))
  vi  <- suppressWarnings(unname(res$estimate["Variance"]))
  z   <- if (is.finite(vi) && !is.na(vi)) (est - ei)/sqrt(vi) else as.numeric(res$statistic)
  tibble(moran_I = est, expected_I = ei, variance = vi, z = z, p_value = res$p.value)
}

`%||%` <- function(a, b) if (is.null(a) || is.na(a)) b else a

global_moran_table_all <- bind_rows(lapply(names(metric_groups), function(g) {
  cols <- metric_groups[[g]]
  bind_rows(lapply(cols, function(colname) {
    y <- site_data[[colname]]
    mr <- safe_moran(y)
    if (is.null(mr)) return(NULL)
    mutate(mr, group = g, metric = colname, n_sites = nrow(site_sf))
  }))
})) %>%
  mutate(p_fdr_all = p.adjust(p_value, "fdr"),
         sig_p05   = p_value   < 0.05,
         sig_fdr05 = p_fdr_all < 0.05) %>%
  select(group, metric, n_sites, moran_I, expected_I, variance, z, p_value, p_fdr_all, sig_p05, sig_fdr05) %>%
  arrange(p_value)

global_moran_table_all
#write.csv(global_moran_table_all, "../output/tables/global_moran_all_10042025.csv", row.names = FALSE)

lisa_table_all <- bind_rows(lapply(names(metric_groups), function(g) {
  cols <- metric_groups[[g]]
  bind_rows(lapply(cols, function(colname) {
    y <- site_data[[colname]]
    if (all(is.na(y)) || (sd(y, na.rm = TRUE) %||% 0) == 0) return(NULL)

    li <- localmoran(y, lw)
    ly <- lag.listw(lw, y)

    out <- sf::st_drop_geometry(site_sf)
    out$Ii   <- li[,1]
    out$Z.Ii <- li[,4]
    out$p    <- li[,5]
    out$metric <- colname
    out$group  <- g
    out[[sc]]  <- site_data[[sc]]
    if ("reporting_area" %in% names(site_data)) out$reporting_area <- site_data$reporting_area

    m_y  <- mean(y,  na.rm = TRUE)
    m_ly <- mean(ly, na.rm = TRUE)
    out$cluster <- dplyr::case_when(
      out$p < 0.05 & y  > m_y & ly > m_ly ~ "High-High",
      out$p < 0.05 & y  < m_y & ly < m_ly ~ "Low-Low",
      out$p < 0.05 & y  > m_y & ly < m_ly ~ "High-Low",
      out$p < 0.05 & y  < m_y & ly > m_ly ~ "Low-High",
      TRUE ~ "NS"
    )
    out
  }))
}))

# add FDR choices:
# (a) FDR within each metric (common for LISA)
lisa_table_all <- lisa_table_all %>%
  group_by(metric) %>%
  mutate(p_fdr_metric = p.adjust(p, "fdr")) %>%
  ungroup() %>%
  mutate(sig_p05   = p < 0.05,
         sig_fdr05 = p_fdr_metric < 0.05)

# nice ordering
lisa_table_all <- lisa_table_all %>%
  relocate(group, metric, !!sc, reporting_area, Ii, Z.Ii, p, p_fdr_metric, sig_p05, sig_fdr05, cluster, .before = 1)

lisa_table_all
#write.csv(lisa_table_all, "../output/tables/lisa_all_10042025.csv", row.names = FALSE)

```

## GETIS-ORD Gi - Hot/ cold spot analysis 
```{r}

getis_results <- list()

for (resp in responses) {
  if (!resp %in% names(site_data)) next
  y <- site_data[[resp]]
  if (all(is.na(y)) || sd(y, na.rm = TRUE) == 0) next

  Gi   <- as.numeric(localG(y, lw))                  # Gi* z-scores
  pval <- 2 * pnorm(abs(Gi), lower.tail = FALSE)     # two-sided p

  out <- site_sf
  out$resp <- resp
  out$Gi   <- Gi
  out$p    <- pval
  out$p_fdr <- p.adjust(out$p, method = "fdr")       # per-metric FDR
  out$hotspot <- dplyr::case_when(
    out$p_fdr < 0.05 & out$Gi > 0  ~ "hot",
    out$p_fdr < 0.05 & out$Gi < 0  ~ "cold",
    TRUE                           ~ "ns"
  )

  # keep reporting_area around for faceting, if present
  if ("reporting_area" %in% names(site_data)) {
    out$reporting_area <- site_data$reporting_area
  }

  getis_results[[resp]] <- out
}

# Example map for p450 hotspots (FDR<0.05)
if ("p450" %in% names(getis_results)) {
  tm_shape(getis_results[["p450"]]) +
    tm_dots(col = "hotspot", size = 0.15, title = "Gi*: p450 (FDR<0.05)") +
    tm_layout(legend.outside = TRUE)
}

gi_groups <- list(
  biomarkers    = biomarkers,
  morphometrics = morphometrics,
  conditions    = conditions,
  ibrs          = ibrs,
  indices       = index_cols
)
gi_groups <- lapply(gi_groups, function(v) v[v %in% names(site_data)])
gi_groups <- gi_groups[sapply(gi_groups, length) > 0]

getis_table_all <- dplyr::bind_rows(lapply(names(gi_groups), function(g) {
  cols <- gi_groups[[g]]
  dplyr::bind_rows(lapply(cols, function(colname) {
    y <- site_data[[colname]]
    if (all(is.na(y)) || sd(y, na.rm = TRUE) == 0) return(NULL)

    Gi   <- as.numeric(localG(y, lw))
    pval <- 2 * pnorm(abs(Gi), lower.tail = FALSE)

    df <- sf::st_drop_geometry(site_sf)
    df$group   <- g
    df$metric  <- colname
    df$Gi      <- Gi
    df$p       <- pval
    df$p_fdr   <- p.adjust(df$p, "fdr")
    df$hotspot <- dplyr::case_when(
      df$p_fdr < 0.05 & df$Gi > 0  ~ "hot",
      df$p_fdr < 0.05 & df$Gi < 0  ~ "cold",
      TRUE                         ~ "ns"
    )
    if ("reporting_area" %in% names(site_data)) df$reporting_area <- site_data$reporting_area
    df
  }))
}))

# quick rollup
gi_counts <- getis_table_all %>%
  dplyr::count(group, metric, hotspot, p_fdr < 0.05, name = "n_sites") %>%
  dplyr::arrange(group, dplyr::desc(n_sites))

view(gi_counts)
#write.csv(gi_counts, "../output/tables/gi_counts_10042025.csv", row.names = FALSE)

```

# These do not contribute to the current Results Analyses as of 10.04.2025
## Interpolation (IDW & Ordinary Kriging)
```{r}

target_metric <- if ("ibr_combined" %in% names(site_data)) "ibr_combined" else "p450"

# build a copy of your points with just the target metric as 'Y'
pts_sf <- site_sf |> dplyr::mutate(Y = site_data[[target_metric]])
df_sp  <- as(pts_sf, "Spatial")  # gstat works with 'Spatial*' classes

# grid spacing (meters). 2000 m ≈ 2 km; increase for coarser, decrease for finer
res_m <- 2000

bbox     <- sf::st_bbox(site_sf)
grid_pts <- sf::st_make_grid(sf::st_as_sfc(bbox), cellsize = res_m, what = "centers")
grid_sf  <- sf::st_as_sf(grid_pts) |> sf::st_set_crs(sf::st_crs(site_sf))
grid_sp  <- as(grid_sf, "Spatial")

hull <- pts_sf |> sf::st_union() |> sf::st_convex_hull() |> sf::st_buffer(2*res_m)
grid_sf <- grid_sf[sf::st_within(grid_sf, hull, sparse = FALSE), ]
grid_sp <- as(grid_sf, "Spatial")

# idp = 2 is a common default (stronger down-weighting with larger idp)
idw_pred <- gstat::idw(Y ~ 1, locations = df_sp, newdata = grid_sp, idp = 2)

# turn into a tidy table (x,y,pred)
idw_sf   <- sf::st_as_sf(idw_pred)
idw_xy   <- sf::st_coordinates(idw_sf)
idw_tbl  <- idw_sf |>
  sf::st_drop_geometry() |>
  dplyr::transmute(
    metric = target_metric,
    x = idw_xy[,1], y = idw_xy[,2],
    pred = var1.pred
  )

v_emp <- gstat::variogram(Y ~ 1, data = df_sp)  # empirical semivariance by distance bins
# You can plot v_emp in RStudio to eyeball the shape

v_mod <- gstat::fit.variogram(v_emp, model = gstat::vgm("Sph"))
v_mod  # look at nugget, partial sill (psill), and range

kr_pred <- gstat::krige(Y ~ 1, locations = df_sp, newdata = grid_sp, model = v_mod)

# tidy table (x,y,pred,variance)
kr_sf  <- sf::st_as_sf(kr_pred)
kr_xy  <- sf::st_coordinates(kr_sf)
kr_tbl <- kr_sf |>
  sf::st_drop_geometry() |>
  dplyr::transmute(
    metric   = target_metric,
    x = kr_xy[,1], y = kr_xy[,2],
    pred     = var1.pred,
    pred_var = var1.var
  )

set.seed(42)
# Kriging LOOCV (built-in)
kcv <- gstat::krige.cv(Y ~ 1, df_sp, model = v_mod)
kr_rmse <- sqrt(mean(kcv$residual^2, na.rm = TRUE))
kr_mae  <- mean(abs(kcv$residual), na.rm = TRUE)

# IDW LOOCV (manual)
idw_res <- sapply(seq_len(nrow(df_sp)), function(i) {
  pred_i <- gstat::idw(Y ~ 1, df_sp[-i,], df_sp[i,], idp = 2)
  as.numeric(pred_i$var1.pred - df_sp$Y[i])
})
idw_rmse <- sqrt(mean(idw_res^2, na.rm = TRUE))
idw_mae  <- mean(abs(idw_res), na.rm = TRUE)

# prediction grids
#write.csv(idw_tbl, "../output/tables/spatial_analyses/idw_table_10042025.csv", row.names = FALSE)
#write.csv(kr_tbl, "../output/tables/spatial_analyses/kr_table_10042025.csv", row.names = FALSE)

# one-row summary for the metric
vdf     <- as.data.frame(v_mod)
nugget  <- dplyr::coalesce(vdf$psill[vdf$model == "Nug"][1], NA_real_)
sph_row <- vdf[vdf$model != "Nug", ][1, , drop = FALSE]
partial <- dplyr::coalesce(sph_row$psill, NA_real_)
vrange  <- dplyr::coalesce(sph_row$range, NA_real_)
vmodel  <- dplyr::coalesce(sph_row$model, NA_character_)

interp_summary <- tibble::tibble(
  metric        = target_metric,
  grid_res_m    = res_m,
  n_sites       = nrow(df_sp),
  n_grid        = nrow(kr_tbl),
  variogram_mod = vmodel,
  nugget        = nugget,
  partial_sill  = partial,
  range         = vrange,
  idw_rmse      = idw_rmse,
  idw_mae       = idw_mae,
  krige_rmse    = kr_rmse,
  krige_mae     = kr_mae
)

view(interp_summary)
#write.csv(interp_summary, "../output/tables/spatial_analyses/interp_summary_10042025.csv", row.names = FALSE)

```

## Spatial Regression
```{r}

# SPATIAL REGRESSION (OLS → diagnostics → SAR/SEM/SDM → impacts/export)
# Assumes these already exist from earlier steps: site_data, site_sf, index_cols, analyte_cols, responses
# Optional: site_col (e.g., "site_name") and site_data$reporting_area

# ---- choose response & predictors ----
resp_y <- if ("ibr_combined" %in% names(site_data)) "ibr_combined" else responses[1]
pred_idx <- index_cols
mech_analytes <- intersect(c("z_benzo_a_pyrene","z_PCB153","z_zinc","z_copper","z_mercury"), analyte_cols)  # edit or set character(0)
use_area <- "reporting_area" %in% names(site_data)
sc <- if (exists("site_col")) site_col else "site_name"

# ---- build model frame & subset consistently (complete cases) ----
X_cols <- unique(c(pred_idx, mech_analytes, if (use_area) "reporting_area"))
model_df <- cbind(Y = site_data[[resp_y]], site_data[, X_cols, drop = FALSE])
model_df[[sc]] <- site_data[[sc]]
keep <- stats::complete.cases(model_df[, c("Y", X_cols), drop = FALSE])
model_df <- model_df[keep, , drop = FALSE]
if (use_area) model_df$reporting_area <- factor(model_df$reporting_area)

# neighbors/weights for the kept rows
sf_mod <- site_sf[keep, ]
xy_mod <- sf::st_coordinates(sf_mod)
k_mod <- max(2, min(8, ceiling(sqrt(nrow(sf_mod)))))
nb_mod <- spdep::knn2nb(spdep::knearneigh(xy_mod, k = k_mod))
if (any(spdep::card(nb_mod) == 0)) { k_mod <- max(k_mod + 1, 3); nb_mod <- spdep::knn2nb(spdep::knearneigh(xy_mod, k = k_mod)) }
lw_mod <- spdep::nb2listw(nb_mod, style = "W")

# ---- OLS baseline ----
ols_form <- stats::as.formula(paste("Y ~", paste(setdiff(colnames(model_df), c("Y", sc)), collapse = " + ")))
ols <- stats::lm(ols_form, data = model_df)
print(summary(ols))

# ---- residual spatial diagnostics ----
res_ols <- residuals(ols)
print(spdep::moran.test(res_ols, lw_mod))
print(spdep::lm.LMtests(ols, lw_mod, test = "all"))

# ---- spatial models ----
sar <- try(spatialreg::lagsarlm(ols_form, data = model_df, listw = lw_mod), silent = TRUE)
sem <- try(spatialreg::errorsarlm(ols_form, data = model_df, listw = lw_mod), silent = TRUE)
sdm <- try(spatialreg::lagsarlm(ols_form, data = model_df, listw = lw_mod, Durbin = TRUE), silent = TRUE)

if (!inherits(sar, "try-error")) print(summary(sar))
if (!inherits(sem, "try-error")) print(summary(sem))
if (!inherits(sdm, "try-error")) print(summary(sdm))

# ---- model diagnostics table (AIC + residual Moran's I) ----
get_diag <- function(mod, type) {
  if (inherits(mod, "try-error")) return(NULL)
  r <- residuals(mod)
  mi <- spdep::moran.test(r, lw_mod)
  data.frame(model = type, AIC = AIC(mod),
             moran_I = unname(mi$estimate["Moran I statistic"]),
             p_value = mi$p.value)
}
model_diag <- dplyr::bind_rows(get_diag(sar, "sar"),
                               get_diag(sem, "sem"),
                               get_diag(sdm, "sdm")) |>
  dplyr::arrange(AIC)
print(model_diag)

# ---- impacts (for SAR/SDM) ----
if (!inherits(sar, "try-error")) {
  imp_sar <- spatialreg::impacts(sar, listw = lw_mod, R = 1000)
  print(summary(imp_sar, zstats = TRUE, short = TRUE))
}
if (!inherits(sdm, "try-error")) {
  imp_sdm <- spatialreg::impacts(sdm, listw = lw_mod, R = 1000)
  print(summary(imp_sdm, zstats = TRUE, short = TRUE))
}

# ---- export CSVs (coefficients, diagnostics, impacts) ----
ols_tbl <- tibble::as_tibble(coef(summary(ols)), rownames = "term") |>
  dplyr::rename(estimate = Estimate, std_error = `Std. Error`, statistic = `t value`, p_value = `Pr(>|t|)`) |>
  dplyr::mutate(model = "ols", response = resp_y)

.tidy_sp <- function(m, nm) {
  if (inherits(m, "try-error")) return(NULL)
  co <- as.data.frame(summary(m)$Coef); co$term <- rownames(co)
  tibble::as_tibble(co) |>
    dplyr::rename(estimate = Estimate, std_error = `Std. Error`, z_value = `z value`, p_value = `Pr(>|z|)`) |>
    dplyr::select(term, estimate, std_error, z_value, p_value) |>
    dplyr::mutate(model = nm, response = resp_y)
}
coef_table <- dplyr::bind_rows(ols_tbl, .tidy_sp(sar, "sar"), .tidy_sp(sem, "sem"), .tidy_sp(sdm, "sdm"))
readr::write_csv(coef_table, paste0("spreg_coefficients_", resp_y, ".csv"))
readr::write_csv(model_diag, paste0("spreg_model_diagnostics_", resp_y, ".csv"))

.tidy_imp <- function(imp, nm) {
  if (is.null(imp)) return(NULL)
  tot <- imp$res$total; dir <- imp$res$direct; ind <- imp$res$indirect
  tibble::tibble(term = names(tot),
                 direct = as.numeric(dir),
                 indirect = as.numeric(ind),
                 total = as.numeric(tot),
                 model = nm, response = resp_y)
}
impacts_table <- dplyr::bind_rows(if (exists("imp_sar")) .tidy_imp(imp_sar, "sar") else NULL,
                                  if (exists("imp_sdm")) .tidy_imp(imp_sdm, "sdm") else NULL)
if (!is.null(impacts_table) && nrow(impacts_table) > 0) {
  readr::write_csv(impacts_table, paste0("spreg_impacts_", resp_y, ".csv"))
}

```

## Multivariate Spatial Patterns
```{r}

# MULTIVARIATE SPATIAL PATTERNS — RDA + MEM (+ Mantel, varpart)
# Assumes: site_data, site_sf, ibrs, biomarkers, responses, index_cols already exist.

{
  # ---- choose response metrics (IBRs + biomarkers; fallback to `responses`) ----
  y_vars <- unique(c(
    intersect(c("ibr_combined","ibr_bio","ibr_morph"), ibrs),
    intersect(c("p450","sod"), biomarkers)
  ))
  if (length(y_vars) == 0) y_vars <- responses

  # ---- predictors: contaminant indices ----
  x_cols <- index_cols

  # ---- align & drop NA rows used by either side ----
  keep <- stats::complete.cases(site_data[, c(y_vars, x_cols), drop = FALSE])
  sf_mod <- site_sf[keep, ]
  Y_mat  <- as.matrix(site_data[keep, y_vars,  drop = FALSE])   # responses (as-is)
  X_df   <- as.data.frame(site_data[keep, x_cols, drop = FALSE])# predictors (as-is)

  # ---- spatial eigenfunctions (MEM/DBMEM) from coordinates ----
  coords <- as.matrix(sf::st_coordinates(sf_mod))
  mem    <- adespatial::dbmem(coords)

  # ---- RDA with environment + space ----
  rda_env_space <- vegan::rda(Y_mat ~ ., data = cbind(X_df, as.data.frame(mem)))
  print(summary(rda_env_space))
  print(stats::anova(rda_env_space, by = "terms"))
  print(stats::anova(rda_env_space, by = "axis"))

  # ---- variation partitioning: environment vs space ----
  vp <- vegan::varpart(Y_mat, X_df, as.data.frame(mem))
  print(vp)

  # ---- Mantel test: biomarker/IBR dissimilarity vs contaminant-index dissimilarity ----
  bio_dist <- stats::dist(Y_mat)   # values as-is; optionally standardize if scales differ
  con_dist <- stats::dist(X_df)
  mantel_res <- vegan::mantel(bio_dist, con_dist, permutations = 999)
  print(mantel_res)
}


```

## Geographically weighted regression
```{r}

# ─────────────────────────────────────────────────────────────────────────────────────
# 6) GEOGRAPHICALLY WEIGHTED REGRESSION (GWR)
# ─────────────────────────────────────────────────────────────────────────────────────
# Metric guidance:
# - Response: IBR or the biomarker most mechanistically linked to contaminants (e.g., p450 ~ PAH).
# - Predictors: Start with 1–2 key indices to avoid overfitting; GWR prefers n_sites >= ~40.

if (nrow(site_sf) >= 40 && all(c("PAH","MET") %in% names(mod_df))) {
  df_sp <- SpatialPointsDataFrame(coords = xy, data = cbind(st_drop_geometry(site_sf), mod_df), proj4string = CRS(st_crs(site_sf)$wkt))
  bw <- bw.gwr(Y ~ PAH + MET, data = df_sp, approach = "AICc", adaptive = TRUE)
  gwr_fit <- gwr.basic(Y ~ PAH + MET, data = df_sp, bw = bw, adaptive = TRUE)
  # Local coefficients and R^2 are in gwr_fit$SDF
  # Map local R^2
  gwr_sf <- st_as_sf(gwr_fit$SDF)
  tm_shape(gwr_sf) + tm_dots(col = "localR2", size = 0.15, title = "GWR local R^2") + tm_layout(legend.outside = TRUE)
}

```

## Spatially Constrained Clustering
```{r}
# ─────────────────────────────────────────────────────────────────────────────────────
# 7) SPATIALLY CONSTRAINED CLUSTERING (zonation)
# ─────────────────────────────────────────────────────────────────────────────────────
# Metric guidance:
# - Use a biomarker profile matrix (e.g., IBR, p450, sod) and incorporate spatial proximity
#   so clusters are contiguous. Consider clustGeo (biological + spatial dissimilarity balance).

# Prepare dissimilarities
bio_mat <- scale(site_data[, Y_vars])
bio_dist <- dist(bio_mat)
# Spatial distance (in meters)
sp_dist <- dist(xy)

# Combine distances (alpha balances biology vs space; try 0.6)
alpha <- 0.6
D <- (1 - alpha) * as.matrix(bio_dist) + alpha * as.matrix(sp_dist) / max(sp_dist)
# Hierarchical clustering
hc <- hclust(as.dist(D), method = "ward.D2")
# Choose k clusters (inspect dendrogram / silhouette)
k <- 4
cl <- cutree(hc, k = k)
site_sf$zone <- factor(cl)

# Map zones
tm_shape(site_sf) + tm_dots(col = "zone", size = 0.18, title = sprintf("Spatially constrained zones (k=%d)", k)) +
  tm_layout(legend.outside = TRUE)

```
