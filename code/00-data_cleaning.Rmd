---
title: "00- Data Cleaning: Checking out the raw data and making adjustments to support analyses"
output:
  pdf_document: 
    fig_width: 20
    fig_height: 9
  html_document: 
    toc: true
    toc_float:
        collapsed: false
        smooth_scroll: true
    fig_width: 20
---

# Directory and doc rules

```{r, setup, eval=TRUE, include=TRUE}

knitr::opts_chunk$set(
  root.dir = here::here(),
  echo = TRUE,         # Display code chunks
  eval = TRUE,         # Evaluate code chunks
  warning = FALSE,     # Hide warnings
  message = FALSE,     # Hide messages
  #fig.width = 15,       # Set plot width in inches
  #fig.height = 9,      # Set plot height in inches
  fig.align = "center" # Align plots to the center
)

```

# Load Data

```{r, load data}

# double check where you are
# *NOTE* set to root (WDFWmussels) and not a directory within - check into why that is happening in the knitr block
getwd()

# load data
data<- read.csv("../data/cleaned/full_data_all_geo_groups.csv")


```

---
# Data Format
P450 & SOD Activity (Unit / mg"^"-1"~"protein)
Shell Thickness - mm
Weight - g
CI - unitless
---

# Data Review

```{r review data}

# take a look at your df
str(data) # df setup review

# str() tells us that our df has 312 rows and 9 columns and that our sample_id and site number are being treated as integers; this might be a problem in analyses and plotting.

summary(data) # df stats for each column

# summary() tells us a few useful things: (1) our lat/ long bounds which we'll need for mapping, (2) we have NA values in p450 and condition_factor that need to be investigated before moving forward.

```

# Dealing with NA's

```{r }

# Fixing NAs or errant values

# replace 0's with NA, we can ignore them in further analyses
data$p450[data$p450 <= 0] <- NA

# replace any values below LOQ with imputed LOQ (.5 x LOD), LOD= 0.05
data$sod[data$sod <= 0] <- 0.0025

# check
summary(data)

```

# Column Names - Don't Run 3.7.25

```{r}

# i also noticed that all of my column names aren't lowercase, so let's fix that to prevent unnecessary mistakes
#colnames(data) <- tolower(colnames(data))

```

# Normality

```{r}

# distribution, normality or non-normality, affects our analysis path
# test assumes normality, so any p-value > .05 indicates a rejection of that assumption

shapiro.test(data$p450) # NOT normal
shapiro.test(data$sod) # NOT normal
shapiro.test(data$ci1) # NOT normal
shapiro.test(data$ci2) # NOT normal
shapiro.test(data$ci3) # NOT normal
shapiro.test(data$shell) # Normal

```

# Histograms - all data

```{r}

# plotting histograms to visualize the Shapiro results and decide if I want to transform the data or maintain it
# p450 
hist(data$p450)

# SOD 
hist(data$sod)

# CI
hist(data$ci1)
hist(data$ci2)
hist(data$ci3)

# Shell
hist(data$shell)

```

# Significance

## Variance, p= 0.3598, we can use PERMANOVA or Kruskal-Wallis

```{r}

# when we looked at our plots, the data is highly variable and that may incorrectly inflate our PERMANOVA results. We check the variance of each group to determine if the PERMANOVA is the correct test. I used the 'bray' method for the matrix because it is ecological data and that's the standard. Note: variance can be evaluated with either bray or euclidian methods, bray is the most common until we get to permanova where euclidian method is used for continuous data. After testing both methods, the result is the same. 

# packages for these tests
library(vegan)
library(cluster)

data$site_name <- as.factor(data$site_name) # change site names to a factor instead of a character

metric_matrix <- as.matrix(data[, 8:13]) # pull out my metrics - confirm column numbers are still correct

dist_matrix_variance <- vegdist(metric_matrix, na.rm= TRUE, method = "bray") # create a distance matrix

dispersion_test <- betadisper(dist_matrix_variance, group = data$site_name) # check homogeneity of group variances


anova(dispersion_test) # Perform permutation test for homogeneity. A p-value > .05 means we need to use PERMANOVA. p= 5.744e-5

## *NOTE*: I don't actually know what it was supposed to look like, so I can followup in the future. Visualize results (boxplot of dispersions)
boxplot(dispersion_test) # visualize results (boxplot of dispersions)

```

# Check for Outliers
## Outliers identified for downstream viz; no impact to stats
```{r}

# let's find the outliers for each metric we are reviewing (p450, sod, condition_factor and avg_thickness). ChatGPT helped create the loop.
metrics <- c("p450", "sod", "ci1", "ci2", "ci3", "shell")  # identify columns of interest

# Loop through each metric and compute outliers
for (marker in metrics) {
  Q1 <- quantile(data[[marker]], 0.25, na.rm = TRUE)
  Q3 <- quantile(data[[marker]], 0.75, na.rm = TRUE)
  IQR_value <- Q3 - Q1
  
  lower_bound <- Q1 - 1.5 * IQR_value
  upper_bound <- Q3 + 1.5 * IQR_value
  
  # Create a new column to flag outliers for each metric
  data[[paste0(marker, "_outlier")]] <- ifelse(data[[marker]] < lower_bound | data[[marker]] > upper_bound, TRUE, FALSE)
}

# View a summary of outliers
summary(data[, paste0(metrics, "_outlier")]) # outliers: p450= 14, sod= 11, cf1= 31, cf2= 5, cf3= 17, shell= 3  

# write out this df for further use
# *NOTE* check why it only saves with the full path and not the relative

# last saved on 3.8.25
#write.csv(data, "/Users/cmantegna/Documents/GitHub/WDFWmussels/data/cleaned/full_data_all_geo_groups.csv")

```
