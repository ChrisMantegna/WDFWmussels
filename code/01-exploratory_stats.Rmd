---
title: "01- Exploratory Statistics: Normality, Distribution, and Variance"
output:
  pdf_document: 
    fig_width: 20
    fig_height: 9
  html_document: 
    toc: true
    toc_float:
        collapsed: false
        smooth_scroll: true
    fig_width: 20
---

# Directory and doc rules

```{r, setup, eval=TRUE, include=TRUE}

knitr::opts_chunk$set(
  root.dir = here::here(),
  echo = TRUE,         # Display code chunks
  eval = TRUE,         # Evaluate code chunks
  warning = FALSE,     # Hide warnings
  message = FALSE,     # Hide messages
  #fig.width = 15,       # Set plot width in inches
  #fig.height = 9,      # Set plot height in inches
  fig.align = "center" # Align plots to the center
)

```

# Load & Check Data
```{r}

# double check where you are
# *NOTE* see 00-data_cleaned for directory issue
getwd()

# load data
site_data<- read.csv("../data/avg_site_level_no_indices.csv")
sample_data<- read.csv("../data/cleaned_all_samples.csv")

# check it out
str(data) # checking df structure
# note that sample_id and site_number are integers and may need to be adjusted to characters for analysis

summary(data) #checking df contents

```

Tests of Normality and Variance indicate KW test + Dunn posthoc for all metrics except Shell Thickness which was normally distributed.
# Normality - sample level

```{r}

# distribution, normality or non-normality, affects our analysis path
# test assumes normality, so any p-value > .05 indicates a rejection of that assumption

shapiro.test(sample_data$p450) # NOT normal
shapiro.test(sample_data$sod) # NOT normal
shapiro.test(sample_data$ci1) # NOT normal
shapiro.test(sample_data$ci2) # NOT normal
shapiro.test(sample_data$ci3) # NOT normal
shapiro.test(sample_data$shell) # Normal

```

# Normality - site level

```{r}

# distribution, normality or non-normality, affects our analysis path
# test assumes normality, so any p-value > .05 indicates a rejection of that assumption

shapiro.test(site_data$p450) # NOT normal
shapiro.test(site_data$sod) # NOT normal
shapiro.test(site_data$ci1) # NOT normal
shapiro.test(site_data$ci2) # NOT normal
shapiro.test(site_data$ci3) # Normal
shapiro.test(site_data$shell) # Normal
# raw morph measurements
shapiro.test(site_data$weight_initial) # Normal
shapiro.test(site_data$weight_change) # Normal
shapiro.test(site_data$weight_final) # Normal
shapiro.test(site_data$length) # Normal
shapiro.test(site_data$height) # Not normal
shapiro.test(site_data$width) # Normal

```

# Histograms - all data

```{r}

# plotting histograms to visualize the Shapiro results and decide if I want to transform the data or maintain it
# p450 
hist(site_data$p450)

# SOD 
hist(site_data$sod)

# CI
hist(site_data$ci1)
hist(site_data$ci2)
hist(site_data$ci3)

# Shell
hist(site_data$shell)

```

# Significance

## Variance, p= 0.3598, we can use PERMANOVA or Kruskal-Wallis

```{r}

# when we looked at our plots, the data is highly variable and that may incorrectly inflate our PERMANOVA results. We check the variance of each group to determine if the PERMANOVA is the correct test. I used the 'bray' method for the matrix because it is ecological data and that's the standard. Note: variance can be evaluated with either bray or euclidian methods, bray is the most common until we get to permanova where euclidian method is used for continuous data. After testing both methods, the result is the same. 

# packages for these tests
library(vegan)
library(cluster)

#data<- read.csv("../data/cleaned/ibr_1.csv")

data$site_name <- as.factor(data$site_name) # change site names to a factor instead of a character

metric_matrix <- as.matrix(data[, 7:21]) # pull out my metrics - confirm column numbers are still correct

dist_matrix_variance <- vegdist(metric_matrix, na.rm= TRUE, method = "bray") # create a distance matrix

dispersion_test <- betadisper(dist_matrix_variance, group = data$site_name) # check homogeneity of group variances


anova(dispersion_test) # Perform permutation test for homogeneity. A p-value > .05 means we need to use PERMANOVA. Reviewing my ibr1 df after making my values absolute since the Bray method cannot properly handle negative values, The p-value= 4.866e-05. We will proceed with KW testing

## *NOTE*: I don't actually know what it was supposed to look like, so I can followup in the future. Visualize results (boxplot of dispersions)
boxplot(dispersion_test) # visualize results (boxplot of dispersions)

```

# Check for Outliers
## Outliers identified for downstream viz; no impact to stats
```{r}

# let's find the outliers for each metric we are reviewing (p450, sod, condition_factor and avg_thickness). ChatGPT helped create the loop.
metrics <- c("p450", "sod", "ci1", "ci2", "ci3", "shell")  # identify columns of interest

# Loop through each metric and compute outliers
for (marker in metrics) {
  Q1 <- quantile(data[[marker]], 0.25, na.rm = TRUE)
  Q3 <- quantile(data[[marker]], 0.75, na.rm = TRUE)
  IQR_value <- Q3 - Q1
  
  lower_bound <- Q1 - 1.5 * IQR_value
  upper_bound <- Q3 + 1.5 * IQR_value
  
  # Create a new column to flag outliers for each metric
  data[[paste0(marker, "_outlier")]] <- ifelse(data[[marker]] < lower_bound | data[[marker]] > upper_bound, TRUE, FALSE)
}

# View a summary of outliers
summary(data[, paste0(metrics, "_outlier")]) # outliers: p450= 14, sod= 11, cf1= 31, cf2= 5, cf3= 17, shell= 3  

# write out this df for further use
# *NOTE* check why it only saves with the full path and not the relative

# last saved on 3.8.25
#write.csv(data, "/Users/cmantegna/Documents/GitHub/WDFWmussels/data/cleaned/full_data_all_geo_groups.csv")

```


