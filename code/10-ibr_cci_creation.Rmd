---
title: "10- Creating an IBR & Contaminant Concentration Index (CCI)"
output:
  pdf_document: 
    fig_width: 20
    fig_height: 9
  html_document: 
    toc: true
    toc_float:
        collapsed: false
        smooth_scroll: true
    fig_width: 20
---

# Directory and doc rules

```{r, setup, eval=TRUE, include=TRUE, echo=FALSE}

# libraries
library(car) # VERIFY what this is for 
library(cluster) # grouping metrics - VERIFY still needed
library(dplyr) # data wrangling
library(factoextra) # pca/ nmds/ tweaking radars
library(FactoMineR) # pca/ nmds/ tweaking radars
library(fmsb) # polygon calculations for the radars
library(FSA) # post hoc test - Dunn's Test    
library(ggplot2) # plots
library(knitr) # output formatting
library(pgirmess) # stats - KW
library(rcompanion) # KW testing
library(rstatix) # VERIFY what this is for      
library(RVAideMemoire) # post hoc test for permanova
library(scales) # scaling data for IBR - works with data wrangling packages
library(tidyr) # data wrangling
library(tidyverse) # data wrangling
library(vegan) # ecological stats 

knitr::opts_chunk$set(
  root.dir = here::here(),
  echo = TRUE,         # show code chunks
  eval = TRUE,         # evaluate code chunks
  warning = FALSE,     # hide warnings
  message = FALSE,     # hide messages
  #fig.width = 15,       # set plot width in inches
  #fig.height = 9,      # set plot height in inches
  fig.align = "center" # slign plots to the center in output doc/ slide/ whatever
)

```

# Load & Check Data
```{r}

getwd()
#setwd("/Users/cmantegna/Documents/GitHub/WDFWmussels") # something here isn't working right - check out why

# DOUBLE CHECK the df's - i updated once i built my new ones as of May 7, 2025

metrics<- read.csv("../data/all_with_imputations_and_identifiers.csv")
chlordane<- read.csv("../data/index_df/chlordane_wide.csv")
ddt<- read.csv("../data/index_df/ddt_wide.csv")
hch<- read.csv("../data/index_df/hch_wide.csv")
metal<- read.csv("../data/index_df/metal_wide.csv")
pbde<- read.csv("../data/index_df/pbde_wide.csv")
pcb<- read.csv("../data/index_df/pcb_wide.csv")
pesticide<- read.csv("../data/index_df/pesticide_wide.csv")

str(metrics) # checking df structure (classes of each column of data)
summary(metrics) #checking df contents (quick stats for each column)

```

## fixing sod values 
```{r }

metrics$sod[metrics$sod <= 0] <- 0.0025 # replace any values below LOQ with imputed LOQ (.5 x LOD), LOD= 0.05

summary(metrics) # check

```

# Creating Mattos' IBRv2i Index with biomarkers and raw morphometrics (no condition indices)
## df prep
```{r}

# make categorical columns factors
metrics$site_number <- as.factor(metrics$site_number)
metrics$sample_id <- as.factor(metrics$sample_id)
metrics$reporting_area <- as.factor(metrics$reporting_area)

```

## fixing site names & trimming white space for chem data sets
```{r}

chlordane$site_name[chlordane$site_name == "Blair Waterway #2"] <- "Blair Waterway Two"
chlordane$site_name[chlordane$site_name == "Comm Bay Skookum"] <- "Commencement Bay Skookum"
chlordane$site_name[chlordane$site_name == "Comm Bay, Dick Gilmur Launch"] <- "Commencement Bay, Dick Gilmur Launch"
chlordane$site_name[chlordane$site_name == "Comm Bay, Milwaukee Waterway"] <- "Commencement Bay, Milwaukee Waterway"
chlordane$site_name[chlordane$site_name == "Meyer's Point - Henderson Inlet"] <- "Meyer's Point, Henderson Inlet"
chlordane$site_name[chlordane$site_name == "Purdy - Dexters"] <- "Purdy, Dexters"
chlordane$site_name[chlordane$site_name == "S of Skunk Island"] <- "South of Skunk Island"
chlordane$site_name[chlordane$site_name == "Suquamish, Stormwater Outfall"] <- "Suquamish Stormwater Outfall"

ddt$site_name[ddt$site_name == "Blair Waterway #2"] <- "Blair Waterway Two"
ddt$site_name[ddt$site_name == "Comm Bay Skookum"] <- "Commencement Bay Skookum"
ddt$site_name[ddt$site_name == "Comm Bay, Dick Gilmur Launch"] <- "Commencement Bay, Dick Gilmur Launch"
ddt$site_name[ddt$site_name == "Comm Bay, Milwaukee Waterway"] <- "Commencement Bay, Milwaukee Waterway"
ddt$site_name[ddt$site_name == "Meyer's Point - Henderson Inlet"] <- "Meyer's Point, Henderson Inlet"
ddt$site_name[ddt$site_name == "Purdy - Dexters"] <- "Purdy, Dexters"
ddt$site_name[ddt$site_name == "S of Skunk Island"] <- "South of Skunk Island"
ddt$site_name[ddt$site_name == "Suquamish, Stormwater Outfall"] <- "Suquamish Stormwater Outfall"

hch$site_name[hch$site_name == "Blair Waterway #2"] <- "Blair Waterway Two"
hch$site_name[hch$site_name == "Comm Bay Skookum"] <- "Commencement Bay Skookum"
hch$site_name[hch$site_name == "Comm Bay, Dick Gilmur Launch"] <- "Commencement Bay, Dick Gilmur Launch"
hch$site_name[hch$site_name == "Comm Bay, Milwaukee Waterway"] <- "Commencement Bay, Milwaukee Waterway"
hch$site_name[hch$site_name == "Meyer's Point - Henderson Inlet"] <- "Meyer's Point, Henderson Inlet"
hch$site_name[hch$site_name == "Purdy - Dexters"] <- "Purdy, Dexters"
hch$site_name[hch$site_name == "S of Skunk Island"] <- "South of Skunk Island"
hch$site_name[hch$site_name == "Suquamish, Stormwater Outfall"] <- "Suquamish Stormwater Outfall"

metal$site_name[metal$site_name == "Blair Waterway #2"] <- "Blair Waterway Two"
metal$site_name[metal$site_name == "Comm Bay Skookum"] <- "Commencement Bay Skookum"
metal$site_name[metal$site_name == "Comm Bay, Dick Gilmur Launch"] <- "Commencement Bay, Dick Gilmur Launch"
metal$site_name[metal$site_name == "Comm Bay, Milwaukee Waterway"] <- "Commencement Bay, Milwaukee Waterway"
metal$site_name[metal$site_name == "Meyer's Point - Henderson Inlet"] <- "Meyer's Point, Henderson Inlet"
metal$site_name[metal$site_name == "Purdy - Dexters"] <- "Purdy, Dexters"
metal$site_name[metal$site_name == "S of Skunk Island"] <- "South of Skunk Island"
metal$site_name[metal$site_name == "Suquamish, Stormwater Outfall"] <- "Suquamish Stormwater Outfall"
#metal$analyte[metal$analyte == "mercuryTotal"] <- "mercury"
#metal$analyte[metal$analyte == "Zinc"] <- "zinc"

pbde$site_name[pbde$site_name == "Blair Waterway #2"] <- "Blair Waterway Two"
pbde$site_name[pbde$site_name == "Comm Bay Skookum"] <- "Commencement Bay Skookum"
pbde$site_name[pbde$site_name == "Comm Bay, Dick Gilmur Launch"] <- "Commencement Bay, Dick Gilmur Launch"
pbde$site_name[pbde$site_name == "Comm Bay, Milwaukee Waterway"] <- "Commencement Bay, Milwaukee Waterway"
pbde$site_name[pbde$site_name == "Meyer's Point - Henderson Inlet"] <- "Meyer's Point, Henderson Inlet"
pbde$site_name[pbde$site_name == "Purdy - Dexters"] <- "Purdy, Dexters"
pbde$site_name[pbde$site_name == "S of Skunk Island"] <- "South of Skunk Island"
pbde$site_name[pbde$site_name == "Suquamish, Stormwater Outfall"] <- "Suquamish Stormwater Outfall"

pcb$site_name[pcb$site_name == "Blair Waterway #2"] <- "Blair Waterway Two"
pcb$site_name[pcb$site_name == "Comm Bay Skookum"] <- "Commencement Bay Skookum"
pcb$site_name[pcb$site_name == "Comm Bay, Dick Gilmur Launch"] <- "Commencement Bay, Dick Gilmur Launch"
pcb$site_name[pcb$site_name == "Comm Bay, Milwaukee Waterway"] <- "Commencement Bay, Milwaukee Waterway"
pcb$site_name[pcb$site_name == "Meyer's Point - Henderson Inlet"] <- "Meyer's Point, Henderson Inlet"
pcb$site_name[pcb$site_name == "Purdy - Dexters"] <- "Purdy, Dexters"
pcb$site_name[pcb$site_name == "S of Skunk Island"] <- "South of Skunk Island"
pcb$site_name[pcb$site_name == "Suquamish, Stormwater Outfall"] <- "Suquamish Stormwater Outfall"

pesticide$site_name[pesticide$site_name == "Blair Waterway #2"] <- "Blair Waterway Two"
pesticide$site_name[pesticide$site_name == "Comm Bay Skookum"] <- "Commencement Bay Skookum"
pesticide$site_name[pesticide$site_name == "Comm Bay, Dick Gilmur Launch"] <- "Commencement Bay, Dick Gilmur Launch"
pesticide$site_name[pesticide$site_name == "Comm Bay, Milwaukee Waterway"] <- "Commencement Bay, Milwaukee Waterway"
pesticide$site_name[pesticide$site_name == "Meyer's Point - Henderson Inlet"] <- "Meyer's Point, Henderson Inlet"
pesticide$site_name[pesticide$site_name == "Purdy - Dexters"] <- "Purdy, Dexters"
pesticide$site_name[pesticide$site_name == "S of Skunk Island"] <- "South of Skunk Island"
pesticide$site_name[pesticide$site_name == "Suquamish, Stormwater Outfall"] <- "Suquamish Stormwater Outfall"

metrics <- metrics %>%
  mutate(across(where(is.character), str_trim))

chlordane <- chlordane %>%
  mutate(across(where(is.character), str_trim))

ddt <- ddt %>%
  mutate(across(where(is.character), str_trim))

hch <- hch %>%
  mutate(across(where(is.character), str_trim))

metal <- metal %>%
  mutate(across(where(is.character), str_trim))

pbde <- pbde %>%
  mutate(across(where(is.character), str_trim))

pcb <- pcb %>%
  mutate(across(where(is.character), str_trim))

pesticide <- pesticide %>%
  mutate(across(where(is.character), str_trim))

```

## Completed 5-5-2025; Only run if rebuilding
### replace undetected analyte values 
```{r}

chlordane<- chlordane %>%
  mutate(flagged = grepl("U|B|I", qualifier),
         wet_value = ifelse(flagged, 0, wet_value))

ddt<- ddt %>%
  mutate(flagged = grepl("U|B|I", qualifier),
         wet_value = ifelse(flagged, 0, wet_value))

hch<- hch %>%
  mutate(flagged = grepl("U|B|I", qualifier),
         wet_value = ifelse(flagged, 0, wet_value))

metal<- metal %>%
  mutate(flagged = grepl("U|B|I", qualifier),
         wet_value = ifelse(flagged, 0, wet_value))

pbde<- pbde %>%
  mutate(flagged = grepl("U|B|I", qualifier),
         wet_value = ifelse(flagged, 0, wet_value))

pcb<- pcb %>%
  mutate(flagged = grepl("U|B|I", qualifier),
         wet_value = ifelse(flagged, 0, wet_value))

pesticide<- pesticide %>%
  mutate(flagged = grepl("U|B|I", qualifier),
         wet_value = ifelse(flagged, 0, wet_value))

```

## Completed 5-5-2025; Only run if rebuilding
### pivoting analytes
```{r}

chlordane <- chlordane %>%
  select(site_name, latitude, longitude, analyte, wet_value)  # keep only what's needed
chlordane_wide <- chlordane %>%
  pivot_wider(
    names_from = analyte,
    values_from = wet_value
  )

# Save the cleaned wide-format table
#write.csv(chlordane_wide, "/Users/cmantegna/Documents/Github/WDFWmussels/data/indices/chlordane_wide.csv", row.names = FALSE)

ddt <- ddt %>%
  select(site_name, latitude, longitude, analyte, wet_value) 
ddt_wide <- ddt %>%
  pivot_wider(
    names_from = analyte,      
    values_from = wet_value    
  )
#write.csv(ddt_wide, "/Users/cmantegna/Documents/Github/WDFWmussels/data/indices/ddt_wide.csv", row.names = FALSE)

hch <- hch %>%
  select(site_name, latitude, longitude, analyte, wet_value)  
hch_wide <- hch %>%
  pivot_wider(
    names_from = analyte,      
    values_from = wet_value    
  )
#write.csv(hch_wide, "/Users/cmantegna/Documents/Github/WDFWmussels/data/indices/hch_wide.csv", row.names = FALSE)

metal <- metal %>%
  select(site_name, latitude, longitude, analyte, wet_value)  
metal_wide <- metal %>%
  pivot_wider(
    names_from = analyte,      
    values_from = wet_value    
  )
#write.csv(metal_wide, "/Users/cmantegna/Documents/Github/WDFWmussels/data/indices/metal_wide.csv", row.names = FALSE)

pbde <- pbde %>%
  select(site_name, latitude, longitude, analyte, wet_value)  
pbde_wide <- pbde %>%
  pivot_wider(
    names_from = analyte,      
    values_from = wet_value   
  )
#write.csv(pbde_wide, "/Users/cmantegna/Documents/Github/WDFWmussels/data/indices/pbde_wide.csv", row.names = FALSE)

pcb <- pcb %>%
  select(site_name, latitude, longitude, analyte, wet_value)  
pcb_wide <- pcb %>%
  pivot_wider(
    names_from = analyte,      
    values_from = wet_value    
  )
#write.csv(pcb_wide, "/Users/cmantegna/Documents/Github/WDFWmussels/data/indices/pcb_wide.csv", row.names = FALSE)

pesticide <- pesticide %>%
  select(site_name, latitude, longitude, analyte, wet_value)  # keep only what's needed
pesticide_wide <- pesticide %>%
  pivot_wider(
    names_from = analyte,      # this becomes the new column names
    values_from = wet_value    # this fills the values
  )
#write.csv(pesticide_wide, "/Users/cmantegna/Documents/Github/WDFWmussels/data/indices/pesticide_wide.csv", row.names = FALSE)

```


## check for outliers, metrics df
```{r}

library(purrr)
library(rlang)

metrics_df<- metrics
metric_cols <- c("p450", "sod", "shell", "length_mm", "height_mm", "width_mm", 
                 "ci1", "ci2", "ci3", "weight_initial_g", "weight_final_g", "weight_change_g") #define what we're assessing

# function to assess & label 'in' or 'out'
flag_outliers <- function(x) {
  q1 <- quantile(x, 0.25, na.rm = TRUE)
  q3 <- quantile(x, 0.75, na.rm = TRUE)
  iqr <- q3 - q1
  lower <- q1 - 1.5 * iqr
  upper <- q3 + 1.5 * iqr
  ifelse(x < lower | x > upper, "out", "in")
}

# loop and add columns to df
metrics_df <- metrics_df %>%
  bind_cols(
    map_dfc(metric_cols, function(col) {
      out_flag <- flag_outliers(metrics_df[[col]])
      new_col <- paste0(col, "_quantile")
      tibble(!!new_col := out_flag)
    })
  )

# summary table
outlier_cols <- grep("_quantile$", names(metrics_df), value = TRUE) # pull the columns from metrics_df

# pivot and count
outlier_summary <- metrics_df %>%
  select(all_of(outlier_cols)) %>%
  pivot_longer(cols = everything(),
               names_to = "metric",
               values_to = "status") %>%
  mutate(metric = gsub("_quantile", "", metric)) %>%
  group_by(metric, status) %>%
  summarise(count = n(), .groups = "drop") %>%
  pivot_wider(names_from = status, values_from = count, values_fill = 0)

# view & save SAVED on 5.7.25
print(outlier_summary)
#write.csv(outlier_summary, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/metrics_outlier_summary_pre-transformation.csv", row.names = FALSE)

```

## transform, log2 based on the reference site
```{r}

metric_cols <- c("p450", "sod", "shell", "length_mm", "height_mm", "width_mm", 
                 "ci1", "ci2", "ci3", "weight_initial_g", "weight_final_g", "weight_change_g")

ref_site <- "Penn Cove Reference"

# reference site mean
ref_means <- metrics_df %>%
  filter(site_name == ref_site) %>%
  summarise(across(all_of(metric_cols), mean, na.rm = TRUE))

# log2-transformation table
log2_df <- metrics_df %>%
  mutate(across(
    all_of(metric_cols),
    .fns = ~ log2(.x / ref_means[[cur_column()]]),
    .names = "log2_{.col}"
  ))

# view & save
print(log2_df)
#write.csv(log2_df, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/metrics_outlier_summary_post-transformation.csv", row.names = FALSE)

```

## check for outliers in log2_df
```{r}

library(purrr)
library(rlang)

metric_cols <- c("log2_p450", "log2_sod", "log2_shell", "log2_length_mm", "log2_height_mm", "log2_width_mm", 
                 "log2_ci1", "log2_ci2", "log2_ci3", "log2_weight_initial_g", "log2_weight_final_g", "log2_weight_change_g") 

# function to assess & label 'in' or 'out'
flag_outliers <- function(x) {
  q1 <- quantile(x, 0.25, na.rm = TRUE)
  q3 <- quantile(x, 0.75, na.rm = TRUE)
  iqr <- q3 - q1
  lower <- q1 - 1.5 * iqr
  upper <- q3 + 1.5 * iqr
  ifelse(x < lower | x > upper, "out", "in")
}

# loop and add columns to df
log2_df <- log2_df %>%
  bind_cols(
    map_dfc(metric_cols, function(col) {
      out_flag <- flag_outliers(log2_df[[col]])
      new_col <- paste0(col, "_quantile")
      tibble(!!new_col := out_flag)
    })
  )

# summary table
outlier_cols <- grep("_quantile$", names(log2_df), value = TRUE) # pull the columns from log2_df

# pivot and count
outlier_summary <- log2_df %>%
  select(all_of(outlier_cols)) %>%
  pivot_longer(cols = everything(),
               names_to = "metric",
               values_to = "status") %>%
  mutate(metric = gsub("_quantile", "", metric)) %>%
  group_by(metric, status) %>%
  summarise(count = n(), .groups = "drop") %>%
  pivot_wider(names_from = status, values_from = count, values_fill = 0)

# view & save. Completed on 5-7-25 
print(outlier_summary)
#write.csv(outlier_summary, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/metrics_outlier_summary_post-transformation.csv", row.names = FALSE)

```

## z-score standardization, absolute sd & IBR scoring
```{r}

trans<- read.csv("../data/index_df/transformed_metrics.csv")

# Define metric groups for clarity
biomarker_metrics <- c("p450", "sod")
morphometric_metrics <- c("shell", "length_mm", "height_mm", "width_mm", 
                          "weight_initial_g", "weight_change_g", "weight_final_g")

# z-score
z_df <- trans %>%
  mutate(across(
    starts_with("log2_"),
    ~ as.numeric(scale(.x)),
    .names = "z_{.col}"
  ))

# reference means
ref_site <- "Penn Cove Reference"
z_ref_means <- z_df %>%
  filter(site_name == ref_site) %>%
  summarise(across(starts_with("z_log2_"), mean, na.rm = TRUE))

# deviation from reference
ai_df <- z_df %>%
  mutate(across(
    starts_with("z_log2_"),
    ~ abs(.x - z_ref_means[[cur_column()]]),
    .names = "ai_{.col}"
  ))

# identify absolute dev columns
ai_biomarker_cols <- paste0("ai_z_log2_", biomarker_metrics)
ai_morphometric_cols <- paste0("ai_z_log2_", morphometric_metrics)

# create ibr scores
may25_ibr <- ai_df %>%
  rowwise() %>%
  mutate(
    ibr_biomarker = sum(c_across(all_of(ai_biomarker_cols)), na.rm = TRUE),
    ibr_morphometric = sum(c_across(all_of(ai_morphometric_cols)), na.rm = TRUE),
    ibr_combined = ibr_biomarker + ibr_morphometric
  ) %>%
  ungroup()

# view & save. Completed 5-7-25.
print(may25_ibr)
#write.csv(ai_df, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/metrics_zscore_sd_may25.csv", row.names = FALSE)
#write.csv(may25_ibr, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/ibr_transformed_may25.csv", row.names = FALSE)

```

## CCI
## chlordane
```{r}

chlordane_df<- chlordane

# define variables
chlordane_analytes <- c("alpha_chlordane", "beta_chlordane", "cis_nonachlor", 
                        "heptachlor", "heptachlor_epoxide", "nonachlor3", 
                        "Oxychlordane", "trans_Nonachlor")

# z-score
chlordane_z <- chlordane_df %>%
  mutate(across(all_of(chlordane_analytes), scale, .names = "z_{.col}"))

# reference
ref_site <- "Penn Cove Baseline"
ref_z_chlordane <- chlordane_z %>%
  filter(site_name == ref_site) %>%
  select(starts_with("z_")) %>%
  slice(1)

# deviation
chlordane_ai <- chlordane_z %>%
  mutate(across(
    starts_with("z_"),
    ~ abs(.x - as.numeric(ref_z_chlordane[[cur_column()]])),
    .names = "ai_{.col}"
  ))

# create index
ai_cols <- names(chlordane_ai)[grepl("^ai_", names(chlordane_ai))] # id ai columns
chlordane_index<- chlordane_ai %>%
  rowwise() %>%
  mutate(chlordane_index = sum(c_across(all_of(ai_cols)), na.rm = TRUE)) %>%
  ungroup()

# view & save
print(chlordane_index)
#write.csv(chlordane_ai, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/chlordane_ai.csv", row.names = FALSE)
#write.csv(chlordane_index, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/chlordane_index.csv", row.names = FALSE)

```

## ddt
```{r}

ddt_df<- ddt
#colnames(ddt_df)

# define variables
ddt_analytes <- c("opDDD", "opDDE", "opDDT", "ppDDD", "ppDDT", "ppDDE")

# z-score
ddt_z <- ddt_df %>%
  mutate(across(all_of(ddt_analytes), scale, .names = "z_{.col}"))

# reference
ref_site <- "Penn Cove Baseline"
ref_z_ddt <- ddt_z %>%
  filter(site_name == ref_site) %>%
  select(starts_with("z_")) %>%
  slice(1)

# deviation
ddt_ai <- ddt_z %>%
  mutate(across(
    starts_with("z_"),
    ~ abs(.x - as.numeric(ref_z_ddt[[cur_column()]])),
    .names = "ai_{.col}"
  ))

# create index
ai_cols <- names(ddt_ai)[grepl("^ai_", names(ddt_ai))] # id ai columns
ddt_index<- ddt_ai %>%
  rowwise() %>%
  mutate(ddt_index = sum(c_across(all_of(ai_cols)), na.rm = TRUE)) %>%
  ungroup()

# view & save
print(ddt_index)
#write.csv(ddt_ai, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/ddt_ai.csv", row.names = FALSE)
#write.csv(ddt_index, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/ddt_index.csv", row.names = FALSE)

```

## hch
```{r}

hch_df<- hch
colnames(hch_df)

# define variables
hch_analytes <- c("alpha_hexachlorocyclohexane", "beta_hexachlorocyclohexane", "gamma_hexachlorocyclohexane")

# z-score
hch_z <- hch_df %>%
  mutate(across(all_of(hch_analytes), scale, .names = "z_{.col}"))

# reference
ref_site <- "Penn Cove Baseline"
ref_z_hch <- hch_z %>%
  filter(site_name == ref_site) %>%
  select(starts_with("z_")) %>%
  slice(1)

# deviation
hch_ai <- hch_z %>%
  mutate(across(
    starts_with("z_"),
    ~ abs(.x - as.numeric(ref_z_hch[[cur_column()]])),
    .names = "ai_{.col}"
  ))

# create index
ai_cols <- names(hch_ai)[grepl("^ai_", names(hch_ai))] # id ai columns
hch_index<- hch_ai %>%
  rowwise() %>%
  mutate(hch_index = sum(c_across(all_of(ai_cols)), na.rm = TRUE)) %>%
  ungroup()

# view & save
print(hch_index)
#write.csv(hch_ai, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/hch_ai.csv", row.names = FALSE)
#write.csv(hch_index, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/hch_index.csv", row.names = FALSE)

```

## metal
```{r}

metal_df<- metal

# define variables
heavy_metals <- c("arsenic", "cadmium", "mercury")
nutrient_metals <- c("copper", "lead", "zinc")

# setup complete metal index
all_metals <- c(heavy_metals, nutrient_metals)

# z-score for each analyte (site-level is not possible based on single site values)
metals_z <- metal_df %>%
  mutate(across(all_of(all_metals), scale, .names = "z_{.col}"))

# pull reference scores
ref_site <- "Penn Cove Baseline"
ref_z <- metals_z %>%
  filter(site_name == ref_site) %>%
  select(starts_with("z_")) %>%
  slice(1)

# absolute deviation from reference z-score for each metal
metals_ai <- metals_z %>%
  mutate(across(
    starts_with("z_"),
    ~ abs(.x - as.numeric(ref_z[[cur_column()]])),  # force scalar extraction
    .names = "ai_{.col}"
  ))

# create indices
ai_cols <- names(metals_ai)[grepl("^ai_z_", names(metals_ai))] # grabbing ai_z columns
metal_names <- gsub("^ai_z_", "", ai_cols) # removing the prefix

# filter columns into heavy and nutrient classes
ai_heavy <- ai_cols[metal_names %in% c("arsenic", "cadmium", "mercury")]
ai_nutrient <- ai_cols[metal_names %in% c("copper", "lead", "zinc")]

# create new index columns
metals_index <- metals_ai %>%
  rowwise() %>%
  mutate(
    heavy_metal_index = sum(c_across(all_of(ai_heavy)), na.rm = TRUE),
    nutrient_metal_index = sum(c_across(all_of(ai_nutrient)), na.rm = TRUE),
    total_metal_index = heavy_metal_index + nutrient_metal_index
  ) %>%
  ungroup()


# view & save
print(metals_index)
#write.csv(metals_ai, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/metals_ai.csv", row.names = FALSE)
#write.csv(metals_index, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/metal_index.csv", row.names = FALSE)

```

## pah, lmw
### data prep
```{r}

pah_lmw<- read.csv("../data/index_df/test_pah_lmw.csv")
# fixing site names, fixing column names, removing white space in the name changes, adjusting undetected values to zero, pivoting for index creation
pah_lmw$site_name[pah_lmw$site_name == "Blair Waterway #2"] <- "Blair Waterway Two"
pah_lmw$site_name[pah_lmw$site_name == "Comm Bay Skookum"] <- "Commencement Bay Skookum"
pah_lmw$site_name[pah_lmw$site_name == "Comm Bay, Dick Gilmur Launch"] <- "Commencement Bay, Dick Gilmur Launch"
pah_lmw$site_name[pah_lmw$site_name == "Comm Bay, Milwaukee Waterway"] <- "Commencement Bay, Milwaukee Waterway"
pah_lmw$site_name[pah_lmw$site_name == "Meyer's Point - Henderson Inlet"] <- "Meyer's Point, Henderson Inlet"
pah_lmw$site_name[pah_lmw$site_name == "Purdy - Dexters"] <- "Purdy, Dexters"
pah_lmw$site_name[pah_lmw$site_name == "S of Skunk Island"] <- "South of Skunk Island"
pah_lmw$site_name[pah_lmw$site_name == "Suquamish, Stormwater Outfall"] <- "Suquamish Stormwater Outfall"

pah_lmw <- pah_lmw %>%
  mutate(across(where(is.character), str_trim))

pah_lmw<- pah_lmw %>%
  mutate(flagged = grepl("U|B|I", qualifier),
         wet_value = ifelse(flagged, 0, wet_value))

head(pah_lmw)

#### changing analyte names with janitor ####
#install.packages("janitor")
#library("janitor")
#pah_lmw <- pah_lmw %>%
#  mutate(analyte_clean = make_clean_names(analyte))
#### end name changing ####

pah_lmw <- pah_lmw %>%
  select(site_name, latitude, longitude, analyte, wet_value)  # keep only what's needed
pah_lmw_wide <- pah_lmw %>%
  pivot_wider(
    names_from = analyte,
    values_from = wet_value
  )

print(pah_lmw_wide)
# Save the cleaned wide-format table
#write.csv(pah_lmw_wide, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/pah_lmw_wide.csv", row.names = FALSE)

```

### index creation
```{r}

pah_lmw_df<- pah_lmw_wide
colnames(pah_lmw_df)

# define variables
pah_lmw_analytes <- names(pah_lmw_df)[4:24]

# z-score
pah_lmw_z <- pah_lmw_df %>%
  mutate(across(all_of(pah_lmw_analytes), scale, .names = "z_{.col}"))

# reference
ref_site <- "Penn Cove Baseline"
ref_z_pah_lmw <- pah_lmw_z %>%
  filter(site_name == ref_site) %>%
  select(starts_with("z_")) %>%
  slice(1)

# deviation
pah_lmw_ai <- pah_lmw_z %>%
  mutate(across(
    starts_with("z_"),
    ~ abs(.x - as.numeric(ref_z_pah_lmw[[cur_column()]])),
    .names = "ai_{.col}"
  ))

# create index
ai_cols <- names(pah_lmw_ai)[grepl("^ai_", names(pah_lmw_ai))] # id ai columns
pah_lmw_index<- pah_lmw_ai %>%
  rowwise() %>%
  mutate(pah_lmw_index = sum(c_across(all_of(ai_cols)), na.rm = TRUE)) %>%
  ungroup()

# view & save
print(pah_lmw_index)
#write.csv(pah_lmw_ai, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/pah_lmw_ai.csv", row.names = FALSE)
#write.csv(pah_lmw_index, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/pah_lmw_index.csv", row.names = FALSE)

```

## pah, hmw
### data prep
```{r}

pah_hmw<- read.csv("../data/index_df/test_pah_hmw.csv")
# fixing site names, fixing column names, removing white space in the name changes, adjusting undetected values to zero, pivoting for index creation
pah_hmw$site_name[pah_hmw$site_name == "Blair Waterway #2"] <- "Blair Waterway Two"
pah_hmw$site_name[pah_hmw$site_name == "Comm Bay Skookum"] <- "Commencement Bay Skookum"
pah_hmw$site_name[pah_hmw$site_name == "Comm Bay, Dick Gilmur Launch"] <- "Commencement Bay, Dick Gilmur Launch"
pah_hmw$site_name[pah_hmw$site_name == "Comm Bay, Milwaukee Waterway"] <- "Commencement Bay, Milwaukee Waterway"
pah_hmw$site_name[pah_hmw$site_name == "Meyer's Point - Henderson Inlet"] <- "Meyer's Point, Henderson Inlet"
pah_hmw$site_name[pah_hmw$site_name == "Purdy - Dexters"] <- "Purdy, Dexters"
pah_hmw$site_name[pah_hmw$site_name == "S of Skunk Island"] <- "South of Skunk Island"
pah_hmw$site_name[pah_hmw$site_name == "Suquamish, Stormwater Outfall"] <- "Suquamish Stormwater Outfall"

pah_hmw <- pah_hmw %>%
  mutate(across(where(is.character), str_trim))

pah_hmw<- pah_hmw %>%
  mutate(flagged = grepl("U|B|I", qualifier),
         wet_value = ifelse(flagged, 0, wet_value))

#### changing analyte names with janitor - see pah_lmw block ####

pah_hmw <- pah_hmw %>%
  select(site_name, latitude, longitude, analyte, wet_value) 
pah_hmw_wide <- pah_hmw %>%
  pivot_wider(
    names_from = analyte,
    values_from = wet_value
  )

# view & save
print(pah_hmw_wide)
#write.csv(pah_hmw_wide, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/pah_hmw_wide.csv", row.names = FALSE)

```

### index creation
```{r}

pah_hmw_df<- pah_hmw_wide
colnames(pah_hmw_df)

# define variables
pah_hmw_analytes <- names(pah_hmw_df)[4:23]

# z-score
pah_hmw_z <- pah_hmw_df %>%
  mutate(across(all_of(pah_hmw_analytes), scale, .names = "z_{.col}"))

# reference
ref_site <- "Penn Cove Baseline"
ref_z_pah_hmw <- pah_hmw_z %>%
  filter(site_name == ref_site) %>%
  select(starts_with("z_")) %>%
  slice(1)

# deviation
pah_hmw_ai <- pah_hmw_z %>%
  mutate(across(
    starts_with("z_"),
    ~ abs(.x - as.numeric(ref_z_pah_hmw[[cur_column()]])),
    .names = "ai_{.col}"
  ))

# create index
ai_cols <- names(pah_hmw_ai)[grepl("^ai_", names(pah_hmw_ai))] # id ai columns
pah_hmw_index<- pah_hmw_ai %>%
  rowwise() %>%
  mutate(pah_hmw_index = sum(c_across(all_of(ai_cols)), na.rm = TRUE)) %>%
  ungroup()

# view & save
print(pah_hmw_index)
#write.csv(pah_hmw_ai, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/pah_hmw_ai.csv", row.names = FALSE)
#write.csv(pah_hmw_index, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/pah_hmw_index.csv", row.names = FALSE)

```

## pah, additional
### data prep
```{r}

pah_add<- read.csv("../data/index_df/test_pah_additional.csv")
# fixing site names, fixing column names, removing white space in the name changes, adjusting undetected values to zero, pivoting for index creation
pah_add$site_name[pah_add$site_name == "Blair Waterway #2"] <- "Blair Waterway Two"
pah_add$site_name[pah_add$site_name == "Comm Bay Skookum"] <- "Commencement Bay Skookum"
pah_add$site_name[pah_add$site_name == "Comm Bay, Dick Gilmur Launch"] <- "Commencement Bay, Dick Gilmur Launch"
pah_add$site_name[pah_add$site_name == "Comm Bay, Milwaukee Waterway"] <- "Commencement Bay, Milwaukee Waterway"
pah_add$site_name[pah_add$site_name == "Meyer's Point - Henderson Inlet"] <- "Meyer's Point, Henderson Inlet"
pah_add$site_name[pah_add$site_name == "Purdy - Dexters"] <- "Purdy, Dexters"
pah_add$site_name[pah_add$site_name == "S of Skunk Island"] <- "South of Skunk Island"
pah_add$site_name[pah_add$site_name == "Suquamish, Stormwater Outfall"] <- "Suquamish Stormwater Outfall"

pah_add <- pah_add %>%
  mutate(across(where(is.character), str_trim))

pah_add<- pah_add %>%
  mutate(flagged = grepl("U|B|I", qualifier),
         wet_value = ifelse(flagged, 0, wet_value))

#### changing analyte names with janitor - see pah_lmw block ####

pah_add <- pah_add %>%
  select(site_name, latitude, longitude, analyte, wet_value)  # keep only what's needed
pah_add_wide <- pah_add %>%
  pivot_wider(
    names_from = analyte,
    values_from = wet_value
  )

# view & save
print(pah_add_wide)
write.csv(pah_add_wide, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/pah_additional_wide.csv", row.names = FALSE)

```

### index creation
```{r}

pah_add_df<- pah_add_wide
colnames(pah_add_df)

# define variables
pah_add_analytes <- names(pah_add_df)[4:12]

# z-score
pah_add_z <- pah_add_df %>%
  mutate(across(all_of(pah_add_analytes), scale, .names = "z_{.col}"))

# reference
ref_site <- "Penn Cove Baseline"
ref_z_pah_add <- pah_add_z %>%
  filter(site_name == ref_site) %>%
  select(starts_with("z_")) %>%
  slice(1)

# deviation
pah_add_ai <- pah_add_z %>%
  mutate(across(
    starts_with("z_"),
    ~ abs(.x - as.numeric(ref_z_pah_add[[cur_column()]])),
    .names = "ai_{.col}"
  ))

# create index
ai_cols <- names(pah_add_ai)[grepl("^ai_", names(pah_add_ai))] # id ai columns
pah_add_index<- pah_add_ai %>%
  rowwise() %>%
  mutate(pah_add_index = sum(c_across(all_of(ai_cols)), na.rm = TRUE)) %>%
  ungroup()

# view & save
print(pah_add_index)
#write.csv(pah_add_ai, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/pah_add_ai.csv", row.names = FALSE)
#write.csv(pah_add_index, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/pah_additional_index.csv", row.names = FALSE)

```

## total pah index creation
```{r}

pah_df<- read.csv("../data/index_df/combined_pah_index_interim.csv")
# create new index columns
combined_pah_index <- pah_df %>%
  rowwise() %>%
  mutate(
    pah_lmw_index = sum(c_across(all_of(ai_heavy)), na.rm = TRUE),
    nutrient_metal_index = sum(c_across(all_of(ai_nutrient)), na.rm = TRUE),
    total_metal_index = heavy_metal_index + nutrient_metal_index
  ) %>%
  ungroup()


# view & save
print(metals_index)
#write.csv(metals_ai, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/metals_ai.csv", row.names = FALSE)

```

## pbde
```{r}

pbde_df<- pbde
colnames(pbde_df)

# define variables
pbde_analytes <- names(pbde_df)[4:14]

# z-score
pbde_z <- pbde_df %>%
  mutate(across(all_of(pbde_analytes), scale, .names = "z_{.col}"))

# reference
ref_site <- "Penn Cove Baseline"
ref_z_pbde <- pbde_z %>%
  filter(site_name == ref_site) %>%
  select(starts_with("z_")) %>%
  slice(1)

# deviation
pbde_ai <- pbde_z %>%
  mutate(across(
    starts_with("z_"),
    ~ abs(.x - as.numeric(ref_z_pbde[[cur_column()]])),
    .names = "ai_{.col}"
  ))

# create index
ai_cols <- names(pbde_ai)[grepl("^ai_", names(pbde_ai))] # id ai columns
pbde_index<- pbde_ai %>%
  rowwise() %>%
  mutate(pbde_index = sum(c_across(all_of(ai_cols)), na.rm = TRUE)) %>%
  ungroup()

# view & save
print(pbde_index)
#write.csv(pbde_ai, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/pbde_ai.csv", row.names = FALSE)
#write.csv(pbde_index, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/pbde_index.csv", row.names = FALSE)

```

## pcb
```{r}

pcb_df<- pcb
colnames(pcb_df)

# define variables
pcb_analytes <- names(pcb_df)[4:45]

# z-score
pcb_z <- pcb_df %>%
  mutate(across(all_of(pcb_analytes), scale, .names = "z_{.col}"))

# reference
ref_site <- "Penn Cove Baseline"
ref_z_pcb <- pcb_z %>%
  filter(site_name == ref_site) %>%
  select(starts_with("z_")) %>%
  slice(1)

# deviation
pcb_ai <- pcb_z %>%
  mutate(across(
    starts_with("z_"),
    ~ abs(.x - as.numeric(ref_z_pcb[[cur_column()]])),
    .names = "ai_{.col}"
  ))

# create index
ai_cols <- names(pcb_ai)[grepl("^ai_", names(pcb_ai))] # id ai columns
pcb_index<- pcb_ai %>%
  rowwise() %>%
  mutate(pcb_index = sum(c_across(all_of(ai_cols)), na.rm = TRUE)) %>%
  ungroup()

# view & save
print(pcb_index)
#write.csv(pcb_ai, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/pcb_ai.csv", row.names = FALSE)
#write.csv(pcb_index, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/pcb_index.csv", row.names = FALSE)

```

## pesticide
```{r}

pesticide_wide<- read.csv("../data/index_df/pesticide_wide.csv")

pesticide_df<- pesticide_wide
colnames(pesticide_df)

# define variables
pesticide_analytes <- names(pesticide_df)[4:8]

# z-score
pesticide_z <- pesticide_df %>%
  mutate(across(all_of(pesticide_analytes), scale, .names = "z_{.col}"))

# reference
ref_site <- "Penn Cove Baseline"
ref_z_pesticide <- pesticide_z %>%
  filter(site_name == ref_site) %>%
  select(starts_with("z_")) %>%
  slice(1)

# deviation
pesticide_ai <- pesticide_z %>%
  mutate(across(
    starts_with("z_"),
    ~ abs(.x - as.numeric(ref_z_pesticide[[cur_column()]])),
    .names = "ai_{.col}"
  ))

# create index
ai_cols <- names(pesticide_ai)[grepl("^ai_", names(pesticide_ai))] # id ai columns
pesticide_index<- pesticide_ai %>%
  rowwise() %>%
  mutate(pesticide_index = sum(c_across(all_of(ai_cols)), na.rm = TRUE)) %>%
  ungroup()

# view & save
print(pesticide_index)
#write.csv(pesticide_ai, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/pesticide_ai.csv", row.names = FALSE)
#write.csv(pesticide_index, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/pesticide_index.csv", row.names = FALSE)

```

## Fix the averaging after adding the IBRs and CCIs
```{r}

metrics<- read.csv("../data/index_df/ibr_for_averaging.csv")
metrics$site_name <- trimws(metrics$site_name)
#metrics <- metrics %>%
#  filter(!is.na(site_name), site_name != "")

metrics <- metrics %>%
  group_by(site_name, reporting_area) %>% 
  summarise(
    latitude= first(latitude),
    longitude= first(longitude),
    site_number= first(site_number),
    p450 = median(log2_p450, na.rm = TRUE),
    sod = median(log2_sod, na.rm = TRUE),
    shell = median(log2_shell, na.rm = TRUE),
    ci1 = median(log2_ci1, na.rm = TRUE),
    ci2 = median(log2_ci2, na.rm = TRUE),
    ci3 = median(log2_ci3, na.rm = TRUE),
    weight_initial = median(log2_weight_initial_g, na.rm = TRUE),
    weight_change = median(log2_weight_change_g, na.rm = TRUE),
    weight_final = median(log2_weight_final_g, na.rm = TRUE),
    length = median(log2_length_mm, na.rm = TRUE),
    height = median(log2_height_mm, na.rm = TRUE),
    width = median(log2_width_mm, na.rm = TRUE),
    ibr_bio = mean(ibr_biomarker, na.rm = TRUE),
    ibr_morph = mean(ibr_morphometric, na.rm = TRUE),
    ibr_combined = mean(ibr_combined, na.rm = TRUE)
  ) %>%
  ungroup()

head(metrics)
# created/ saved 5-8-2025
#write.csv(metrics, "/Users/cmantegna/Documents/Github/WDFWmussels/data/index_df/avg_ibr_with_log2_metrics.csv", row.names = FALSE)

```

# Move all of this to its own file

# Plotting
## Box plots, Separate Indices per Site
```{r}

#metrics<- read.csv("../data/cleaned/ibr_1.csv")


# pivot only the index columns - adjusted for each df
ibr3_long <- df3 %>%
  pivot_longer(cols = c(ibr3_biomarkers, ibr3_morphometrics, ibr3_overall),
               names_to = "index_type",
               values_to = "index_value") %>%
  mutate(index_type = case_when(
    index_type == "ibr3_biomarkers" ~ "Biomarkers",
    index_type == "ibr3_morphometrics" ~ "Morphometrics",
    index_type == "ibr3_overall" ~ "Overall",
    TRUE ~ index_type))  # fallback in case of unexpected names

#### plotting ibr1 with Penn Cove reference site
all_index<- ggplot(ibr1_long, aes(x = site_name, y = index_value,
                     color = site_name == "Penn Cove Reference")) +
  geom_jitter(width = 0.2, alpha = 0.7) +
  geom_boxplot(outlier.shape = NA, alpha = 0.2) +
  facet_wrap(~ index_type, ncol = 1, scales = "free_y") +
  scale_color_manual(values = c("FALSE" = "black", "TRUE" = "red")) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),legend.position = "none") +
  labs(title = "IBRv2i Indices by Site",
       x = "Site", y = "IBRv2i Value")

# save and view
#ggsave(filename= "/Users/cmantegna/Documents/GitHub/WDFWmussels/output/ibr1_all_indices.png", plot= all_index, width = 16, height = 14, dpi = 300)

print(all_index)



```
## Radars, reference overlay
## All Sites, Do Not Run
```{r}

z_scores$sample_id <- df$sample_id
z_scores$site_name <- df$site_name

# Site-averaged Z-scores
site_means <- z_scores %>%
  group_by(site_name) %>%
  summarise(across(1:8, mean, na.rm = TRUE))

# Loop through sites
for (i in 1:nrow(site_means)) {
  site_data <- site_means[i, 2:9]
  max_min <- rbind(apply(site_means[ ,2:9], 2, max),
                   apply(site_means[ ,2:9], 2, min))
  radar_data <- rbind(max_min, site_data)

  png(paste0("IBRv2i_radar_site_", gsub(" ", "_", site_means$site_name[i]), ".png"), width = 600, height = 600)
  radarchart(radar_data,
             axistype = 1,
             pcol = "darkblue", pfcol = rgb(0.2, 0.4, 0.9, 0.4),
             plwd = 2,
             title = paste("IBRv2i Radar Plot\nSite:", site_means$site_name[i]))
  dev.off()
}

```

## All Samples,Only run if spot checking
```{r}

library(fmsb)

# Loop through each sample
for (i in 1:nrow(z_scores)) {
  
  # Extract sample data
  sample_data <- z_scores[i, 1:8]
  
  # Get axis limits (min/max across all samples)
  max_min <- rbind(apply(z_scores[, 1:8], 2, max, na.rm = TRUE),
                   apply(z_scores[, 1:8], 2, min, na.rm = TRUE))
  
  # Combine for radar input
  radar_data <- rbind(max_min, sample_data)
  
  # Set output file name (in current directory)
  filename <- paste0("radar_sample_", z_scores$sample_id[i], ".png")
  
  # Save plot
  png(filename, width = 600, height = 600)
  radarchart(radar_data,
             axistype = 1,
             pcol = "darkblue", pfcol = rgb(0.8, 0.2, 0.2, 0.4),
             plwd = 2,
             title = paste("IBRv2i Radar Plot\nSample:", z_scores$sample_id[i],
                           "\nSite:", z_scores$site_name[i]))
  dev.off()
}


```

## All sites w/ reference site overlay
```{r}

#### IBR_1
# Variables to include in radar plots
vars_to_use <- c("p450_ibr1", "sod_ibr1", "shell_ibr1", "weight_initial_g_ibr1", "weight_final_g_ibr1", "weight_change_g_ibr1", "length_mm_ibr1", "height_mm_ibr1", "width_mm_ibr1")

# create the reference profile from Penn Cove 
reference_profile <- z_scores %>%
  filter(sample_id %in% 41:44) %>%
  select(all_of(vars_to_use)) %>%
  summarise(across(everything(), mean, na.rm = TRUE))

# create site-level means 
site_means <- z_scores %>%
  group_by(site_name) %>%
  summarise(across(all_of(vars_to_use), mean, na.rm = TRUE)) %>%
  ungroup()

# define radar axis limits (same across all sites)
max_vals <- apply(site_means[, vars_to_use], 2, max, na.rm = TRUE)
min_vals <- apply(site_means[, vars_to_use], 2, min, na.rm = TRUE)

# convert reference profile to a named numeric vector
ref_vec <- unlist(reference_profile[1, ], use.names = TRUE)

# loop through each site to create radar plots
for (i in 1:nrow(site_means)) {
  site <- site_means[i, ]
  site_profile <- unlist(site[, vars_to_use], use.names = TRUE)
  
  # Combine into radar data
  radar_data <- as.data.frame(rbind(max_vals, min_vals, ref_vec, site_profile))
  rownames(radar_data) <- c("Max", "Min", "Reference", as.character(site$site_name))
  
  # Save radar plot
  filename <- paste0("radar_site_with_ref_", gsub(" ", "_", site$site_name), ".png")
  png(filename, width = 600, height = 600)
  
  radarchart(radar_data,
             axistype = 1,
             pcol = c("gray40", "steelblue"),
             pfcol = c(rgb(0.4, 0.4, 0.4, 0.3), rgb(0.2, 0.5, 0.8, 0.4)),
             plwd = 2,
             plty = 1,
             title = paste("IBRv2i Radar Plot with Reference\nSite:", site$site_name))
  
  legend("topright", legend = c("Penn Cove Reference", site$site_name),
         col = c("gray40", "steelblue"), lty = 1, lwd = 2, bty = "n")
  
  dev.off()
}


```

## Sites by Reporting Areas w/ Reference
```{r}

# manually adjusting for each ibr
# Define variables to include (excluding condition indices and weight final)
vars_to_use <- c("p450_ibr3", "sod_ibr3", "shell_ibr3", "weight_initial_g_ibr3", "weight_change_g_ibr3", "length_mm_ibr3", "height_mm_ibr3", "width_mm_ibr3")

# Site-level means (if you have multiple entries per site)
site_means <- df3 %>%
  group_by(site_name, reporting_area) %>%
  summarise(across(all_of(vars_to_use), mean, na.rm = TRUE), .groups = "drop")

# Global min/max for radar chart scaling
global_max <- apply(site_means[, vars_to_use], 2, max, na.rm = TRUE)
global_min <- apply(site_means[, vars_to_use], 2, min, na.rm = TRUE)

# Reference profile from one or more reference sites
reference_sites <- c( "Penn Cove Reference", "Hood Canal Holly", "Broad Spit (Fisherman's Point)")  # or use site_number
reference_profile <- df3 %>%
  filter(site_name %in% reference_sites) %>%
  summarise(across(all_of(vars_to_use), mean, na.rm = TRUE), .groups = "drop") %>%
  unlist(use.names = TRUE)

# Proceed with the rest of the radar chart code
reporting_areas <- unique(site_means$reporting_area)

for (area in reporting_areas) {
  area_sites <- site_means %>% filter(reporting_area == area)
  n_sites <- nrow(area_sites)
  n_pages <- ceiling(n_sites / 6)

  for (page in 1:n_pages) {
    start_i <- (page - 1) * 6 + 1
    end_i <- min(start_i + 5, n_sites)
    sites_subset <- area_sites[start_i:end_i, ]

    filename <- paste0("radar_group_", gsub(" ", "_", area), "_page_", page, ".png")
    png(filename, width = 1200, height = 800)
    par(mfrow = c(2, 3), mar = c(2, 2, 4, 2), oma = c(0, 0, 4, 0))

    for (i in 1:nrow(sites_subset)) {
      site_data <- unlist(sites_subset[i, vars_to_use], use.names = TRUE)
      chart_data <- as.data.frame(rbind(global_max, global_min, reference_profile, site_data))
      rownames(chart_data) <- c("Max", "Min", "Reference", as.character(sites_subset$site_name[i]))

      radarchart(chart_data,
                 axistype = 1,
                 pcol = c("gray40", "steelblue"),
                 pfcol = c(rgb(0.4, 0.4, 0.4, 0.3), rgb(0.2, 0.5, 0.8, 0.4)),
                 plwd = 2,
                 plty = 1,
                 cglcol = "grey80",
                 title = sites_subset$site_name[i])
    }

    mtext(paste("Reporting Area:", area), side = 3, line = 1, outer = TRUE, cex = 1.0)
    dev.off()
  }
}

```





